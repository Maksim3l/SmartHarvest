/mnt/scratch/maksiml/SmartH/model_env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

Directory structure check:
Images dir exists: True
Masks dir exists: True
Semantic masks dir exists: True
Instance masks dir exists: True
Plant types found: ['cucumber', 'strawberry', 'apple', 'cherry', 'tomato']

Found existing checkpoint: fruit_detection_model_enhanced/checkpoint_epoch_010.pth
Resume from this checkpoint? (y/n): /mnt/scratch/maksiml/SmartH/model_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
  warnings.warn(warn_msg)

==================================================
FRUIT INSTANCE SEGMENTATION TRAINING
==================================================
Device: cpu
Batch size: 2
Learning rate: 0.002
Epochs: 100
Early stopping patience: 15
Dropout rate: 0.3
Weight decay: 0.0005
Gradient clipping: 10.0
==================================================

Loading datasets...
Using augmented dataset...

Dataset loading complete:
  Total samples found: 3816

Sample paths (first entry):
  Image: AugmentedDataset/images/cucumber/image (25)_aug07.jpg
  Semantic: AugmentedDataset/semantic_masks/cucumber/image (25)_aug07_semantic.png
  Instance: AugmentedDataset/instance_masks/cucumber/image (25)_aug07_instance.png
  Info: AugmentedDataset/instance_masks/cucumber/image (25)_aug07_instances.json
Dataset initialized: 3816 samples for train
Allowed fruits: apple, cherry, cucumber, strawberry, tomato
Augmentation: Enabled
Train samples: 3052
Validation samples: 764

Initializing model with dropout...

Starting training...

Epoch 1/100
----------------------------------------
  Batch [0/1526] Loss: 5.0760 Components: {'loss_classifier': 3.478078842163086, 'loss_box_reg': 0.15154269337654114, 'loss_mask': 1.2020841836929321, 'loss_objectness': 0.19488564133644104, 'loss_rpn_box_reg': 0.049437038600444794}
  Batch [120/1526] Loss: 0.5699 Components: {'loss_classifier': 0.0834636390209198, 'loss_box_reg': 0.02743665874004364, 'loss_mask': 0.2952119708061218, 'loss_objectness': 0.15001603960990906, 'loss_rpn_box_reg': 0.013797744177281857}
  Batch [150/1526] Loss: 9.9332 Components: {'loss_classifier': 0.14600196480751038, 'loss_box_reg': 0.037425484508275986, 'loss_mask': 0.7132728695869446, 'loss_objectness': 2.4440860748291016, 'loss_rpn_box_reg': 6.592434406280518}
  Batch [200/1526] Loss: 1.4495 Components: {'loss_classifier': 0.14037221670150757, 'loss_box_reg': 0.024897856637835503, 'loss_mask': 0.3746837079524994, 'loss_objectness': 0.6233941912651062, 'loss_rpn_box_reg': 0.2861092686653137}
  Batch [220/1526] Loss: 1.1834 Components: {'loss_classifier': 0.06568741053342819, 'loss_box_reg': 0.014995799399912357, 'loss_mask': 0.550929844379425, 'loss_objectness': 0.5181927680969238, 'loss_rpn_box_reg': 0.033614758402109146}
  Batch [340/1526] Loss: 1.3908 Components: {'loss_classifier': 0.24848440289497375, 'loss_box_reg': 0.03238817676901817, 'loss_mask': 0.3295360505580902, 'loss_objectness': 0.5768957138061523, 'loss_rpn_box_reg': 0.2034757137298584}
  Batch [360/1526] Loss: 1.2883 Components: {'loss_classifier': 0.07357759773731232, 'loss_box_reg': 0.0051551563665270805, 'loss_mask': 0.9511555433273315, 'loss_objectness': 0.24331477284431458, 'loss_rpn_box_reg': 0.015098758041858673}
  Batch [410/1526] Loss: 1.2517 Components: {'loss_classifier': 0.2442796379327774, 'loss_box_reg': 0.09271104633808136, 'loss_mask': 0.12392768263816833, 'loss_objectness': 0.48102355003356934, 'loss_rpn_box_reg': 0.3097890615463257}
  Batch [420/1526] Loss: 1.3676 Components: {'loss_classifier': 0.21243131160736084, 'loss_box_reg': 0.11658142507076263, 'loss_mask': 0.8148891925811768, 'loss_objectness': 0.1862964928150177, 'loss_rpn_box_reg': 0.03739128261804581}
  Batch [480/1526] Loss: 0.7563 Components: {'loss_classifier': 0.07399262487888336, 'loss_box_reg': 0.011961756274104118, 'loss_mask': 0.2430540919303894, 'loss_objectness': 0.35424351692199707, 'loss_rpn_box_reg': 0.07305710017681122}
  Batch [640/1526] Loss: 1.4962 Components: {'loss_classifier': 0.172196164727211, 'loss_box_reg': 0.06658554822206497, 'loss_mask': 1.0511586666107178, 'loss_objectness': 0.19111065566539764, 'loss_rpn_box_reg': 0.015134603716433048}
  Batch [680/1526] Loss: 0.5284 Components: {'loss_classifier': 0.1355496644973755, 'loss_box_reg': 0.046817488968372345, 'loss_mask': 0.15994711220264435, 'loss_objectness': 0.16414406895637512, 'loss_rpn_box_reg': 0.02191755175590515}
  Batch [690/1526] Loss: 2.3132 Components: {'loss_classifier': 0.12386377900838852, 'loss_box_reg': 0.050586115568876266, 'loss_mask': 1.2455456256866455, 'loss_objectness': 0.638949990272522, 'loss_rpn_box_reg': 0.25428691506385803}
  Batch [790/1526] Loss: 1.4218 Components: {'loss_classifier': 0.31306836009025574, 'loss_box_reg': 0.09317298978567123, 'loss_mask': 0.19516310095787048, 'loss_objectness': 0.6576495170593262, 'loss_rpn_box_reg': 0.16269998252391815}
  Batch [880/1526] Loss: 1.0809 Components: {'loss_classifier': 0.08473772555589676, 'loss_box_reg': 0.03293141350150108, 'loss_mask': 0.8423803448677063, 'loss_objectness': 0.1120540201663971, 'loss_rpn_box_reg': 0.008780243806540966}
  Batch [920/1526] Loss: 8.1806 Components: {'loss_classifier': 0.14832137525081635, 'loss_box_reg': 0.05610903725028038, 'loss_mask': 0.16126860678195953, 'loss_objectness': 1.147858738899231, 'loss_rpn_box_reg': 6.667043685913086}
  Batch [960/1526] Loss: 0.9301 Components: {'loss_classifier': 0.20460575819015503, 'loss_box_reg': 0.10602691024541855, 'loss_mask': 0.34421223402023315, 'loss_objectness': 0.23994509875774384, 'loss_rpn_box_reg': 0.03529379516839981}
  Batch [980/1526] Loss: 0.7119 Components: {'loss_classifier': 0.1253763735294342, 'loss_box_reg': 0.05937584489583969, 'loss_mask': 0.32999563217163086, 'loss_objectness': 0.1813907027244568, 'loss_rpn_box_reg': 0.01572394371032715}
  Batch [1150/1526] Loss: 0.4364 Components: {'loss_classifier': 0.1860222965478897, 'loss_box_reg': 0.08424632996320724, 'loss_mask': 0.05047284811735153, 'loss_objectness': 0.1073121577501297, 'loss_rpn_box_reg': 0.008368207141757011}
  Batch [1190/1526] Loss: 0.8839 Components: {'loss_classifier': 0.18743976950645447, 'loss_box_reg': 0.09702226519584656, 'loss_mask': 0.48874324560165405, 'loss_objectness': 0.10342131555080414, 'loss_rpn_box_reg': 0.007246631197631359}
  Batch [1240/1526] Loss: 0.6785 Components: {'loss_classifier': 0.20363524556159973, 'loss_box_reg': 0.12648804485797882, 'loss_mask': 0.1644037663936615, 'loss_objectness': 0.17120932042598724, 'loss_rpn_box_reg': 0.012792375870049}
  Batch [1260/1526] Loss: 1.0833 Components: {'loss_classifier': 0.18768249452114105, 'loss_box_reg': 0.07852303981781006, 'loss_mask': 0.21413594484329224, 'loss_objectness': 0.43563979864120483, 'loss_rpn_box_reg': 0.16732822358608246}
  Batch [1370/1526] Loss: 0.7904 Components: {'loss_classifier': 0.06632397323846817, 'loss_box_reg': 0.008837607689201832, 'loss_mask': 0.0026477391365915537, 'loss_objectness': 0.34344083070755005, 'loss_rpn_box_reg': 0.3691009283065796}

Epoch 1 Summary:
  Train Loss: 1.6612
  Val Loss: 1.5753
  Learning Rate: 0.000800
  Epoch Time: 2751.0s
  ✓ Saved best model (val_loss: 1.5753)
  Validation loss decreased (inf --> 1.575270). Saving model...

Epoch 2/100
----------------------------------------
  Batch [40/1526] Loss: 0.6175 Components: {'loss_classifier': 0.07935935258865356, 'loss_box_reg': 0.007756855338811874, 'loss_mask': 0.03931853547692299, 'loss_objectness': 0.4140652120113373, 'loss_rpn_box_reg': 0.0770030990242958}
  Batch [140/1526] Loss: 0.9663 Components: {'loss_classifier': 0.1861954629421234, 'loss_box_reg': 0.036487314850091934, 'loss_mask': 0.11106741428375244, 'loss_objectness': 0.4231775104999542, 'loss_rpn_box_reg': 0.20939616858959198}
  Batch [170/1526] Loss: 0.4184 Components: {'loss_classifier': 0.13460786640644073, 'loss_box_reg': 0.045000530779361725, 'loss_mask': 0.08983021974563599, 'loss_objectness': 0.13359680771827698, 'loss_rpn_box_reg': 0.015363922342658043}
  Batch [320/1526] Loss: 0.7002 Components: {'loss_classifier': 0.07651461660861969, 'loss_box_reg': 0.0047026462852954865, 'loss_mask': 0.22758731245994568, 'loss_objectness': 0.2948141098022461, 'loss_rpn_box_reg': 0.09662872552871704}
  Batch [350/1526] Loss: 1.0335 Components: {'loss_classifier': 0.07217622548341751, 'loss_box_reg': 0.006201581563800573, 'loss_mask': 0.002923880936577916, 'loss_objectness': 0.6335462927818298, 'loss_rpn_box_reg': 0.31867650151252747}
  Batch [360/1526] Loss: 0.3869 Components: {'loss_classifier': 0.11864874511957169, 'loss_box_reg': 0.03226514160633087, 'loss_mask': 0.036269016563892365, 'loss_objectness': 0.18607598543167114, 'loss_rpn_box_reg': 0.013649805448949337}
  Batch [400/1526] Loss: 0.8239 Components: {'loss_classifier': 0.06503190100193024, 'loss_box_reg': 0.005755905527621508, 'loss_mask': 0.005345608107745647, 'loss_objectness': 0.32773831486701965, 'loss_rpn_box_reg': 0.4200611114501953}
  Batch [450/1526] Loss: 0.3054 Components: {'loss_classifier': 0.03131077438592911, 'loss_box_reg': 0.003216490149497986, 'loss_mask': 0.02616545557975769, 'loss_objectness': 0.2341933697462082, 'loss_rpn_box_reg': 0.010560905560851097}
  Batch [470/1526] Loss: 0.4562 Components: {'loss_classifier': 0.03853587061166763, 'loss_box_reg': 0.02181982435286045, 'loss_mask': 0.14784328639507294, 'loss_objectness': 0.19579797983169556, 'loss_rpn_box_reg': 0.05217687413096428}
  Batch [510/1526] Loss: 1.5899 Components: {'loss_classifier': 0.4361618161201477, 'loss_box_reg': 0.08146318793296814, 'loss_mask': 0.02437131293118, 'loss_objectness': 0.4245736002922058, 'loss_rpn_box_reg': 0.6233094334602356}
  Batch [620/1526] Loss: 0.4738 Components: {'loss_classifier': 0.1414790004491806, 'loss_box_reg': 0.06448012590408325, 'loss_mask': 0.12662215530872345, 'loss_objectness': 0.1186380460858345, 'loss_rpn_box_reg': 0.02259155549108982}
  Batch [630/1526] Loss: 0.3534 Components: {'loss_classifier': 0.0742579996585846, 'loss_box_reg': 0.022078687325119972, 'loss_mask': 0.0239974707365036, 'loss_objectness': 0.20254626870155334, 'loss_rpn_box_reg': 0.03047369420528412}
  Batch [650/1526] Loss: 30.3972 Components: {'loss_classifier': 0.08907216787338257, 'loss_box_reg': 0.01022365503013134, 'loss_mask': 0.1724879890680313, 'loss_objectness': 3.0381829738616943, 'loss_rpn_box_reg': 27.087242126464844}
  Batch [780/1526] Loss: 0.9396 Components: {'loss_classifier': 0.05876859650015831, 'loss_box_reg': 0.004380495753139257, 'loss_mask': 0.046440329402685165, 'loss_objectness': 0.5988729000091553, 'loss_rpn_box_reg': 0.2311159372329712}
  Batch [860/1526] Loss: 1.1226 Components: {'loss_classifier': 0.3706184923648834, 'loss_box_reg': 0.15010207891464233, 'loss_mask': 0.005281596444547176, 'loss_objectness': 0.42614638805389404, 'loss_rpn_box_reg': 0.170461043715477}
  Batch [920/1526] Loss: 0.7863 Components: {'loss_classifier': 0.1990964561700821, 'loss_box_reg': 0.07071912288665771, 'loss_mask': 0.02939477376639843, 'loss_objectness': 0.3617338240146637, 'loss_rpn_box_reg': 0.1253407895565033}
  Batch [950/1526] Loss: 0.9286 Components: {'loss_classifier': 0.1725093573331833, 'loss_box_reg': 0.05060800909996033, 'loss_mask': 0.15346935391426086, 'loss_objectness': 0.4044712781906128, 'loss_rpn_box_reg': 0.14750540256500244}
  Batch [1030/1526] Loss: 1.9709 Components: {'loss_classifier': 0.6656321287155151, 'loss_box_reg': 0.21108530461788177, 'loss_mask': 0.011092345230281353, 'loss_objectness': 0.5530309677124023, 'loss_rpn_box_reg': 0.5300171971321106}
  Batch [1090/1526] Loss: 1.1545 Components: {'loss_classifier': 0.3751392066478729, 'loss_box_reg': 0.186224564909935, 'loss_mask': 0.39531785249710083, 'loss_objectness': 0.16472236812114716, 'loss_rpn_box_reg': 0.033095087856054306}
  Batch [1220/1526] Loss: 0.6897 Components: {'loss_classifier': 0.11395960301160812, 'loss_box_reg': 0.045437734574079514, 'loss_mask': 0.2057649791240692, 'loss_objectness': 0.2725507915019989, 'loss_rpn_box_reg': 0.05198686942458153}
  Batch [1260/1526] Loss: 0.9275 Components: {'loss_classifier': 0.13752774894237518, 'loss_box_reg': 0.0873529240489006, 'loss_mask': 0.5643909573554993, 'loss_objectness': 0.12738198041915894, 'loss_rpn_box_reg': 0.010822433978319168}
  Batch [1290/1526] Loss: 0.4934 Components: {'loss_classifier': 0.08049169927835464, 'loss_box_reg': 0.006997460965067148, 'loss_mask': 0.011019828729331493, 'loss_objectness': 0.3369033634662628, 'loss_rpn_box_reg': 0.057945895940065384}
  Batch [1300/1526] Loss: 0.7515 Components: {'loss_classifier': 0.09368247538805008, 'loss_box_reg': 0.03750287741422653, 'loss_mask': 0.47176626324653625, 'loss_objectness': 0.14414888620376587, 'loss_rpn_box_reg': 0.004436550196260214}
  Batch [1350/1526] Loss: 1.6049 Components: {'loss_classifier': 0.06075054034590721, 'loss_box_reg': 0.0059382496401667595, 'loss_mask': 0.0038580168038606644, 'loss_objectness': 0.810916543006897, 'loss_rpn_box_reg': 0.7234789133071899}
  Batch [1370/1526] Loss: 0.6662 Components: {'loss_classifier': 0.16699150204658508, 'loss_box_reg': 0.042280398309230804, 'loss_mask': 0.02806699462234974, 'loss_objectness': 0.2560262680053711, 'loss_rpn_box_reg': 0.17286887764930725}
  Batch [1380/1526] Loss: 1.0096 Components: {'loss_classifier': 0.11121191084384918, 'loss_box_reg': 0.04531393200159073, 'loss_mask': 0.4239000380039215, 'loss_objectness': 0.1979282796382904, 'loss_rpn_box_reg': 0.231275737285614}
  Batch [1420/1526] Loss: 21.0695 Components: {'loss_classifier': 0.11633908748626709, 'loss_box_reg': 0.008928608149290085, 'loss_mask': 0.03186830133199692, 'loss_objectness': 1.6845289468765259, 'loss_rpn_box_reg': 19.227840423583984}
  Batch [1430/1526] Loss: 0.4160 Components: {'loss_classifier': 0.07909923791885376, 'loss_box_reg': 0.008566763252019882, 'loss_mask': 0.05877572298049927, 'loss_objectness': 0.24159398674964905, 'loss_rpn_box_reg': 0.027941448614001274}

Epoch 2 Summary:
  Train Loss: 1.5003
  Val Loss: 1.6674
  Learning Rate: 0.001200
  Epoch Time: 2584.7s
  EarlyStopping counter: 1 out of 15

Epoch 3/100
----------------------------------------
  Batch [20/1526] Loss: 0.5168 Components: {'loss_classifier': 0.15242917835712433, 'loss_box_reg': 0.06827469915151596, 'loss_mask': 0.0028580299112945795, 'loss_objectness': 0.24700072407722473, 'loss_rpn_box_reg': 0.04627189412713051}
  Batch [170/1526] Loss: 0.9280 Components: {'loss_classifier': 0.24022276699543, 'loss_box_reg': 0.0738653689622879, 'loss_mask': 0.07695197314023972, 'loss_objectness': 0.24208375811576843, 'loss_rpn_box_reg': 0.29490751028060913}
  Batch [180/1526] Loss: 1.0494 Components: {'loss_classifier': 0.2189769446849823, 'loss_box_reg': 0.03415698558092117, 'loss_mask': 0.08217090368270874, 'loss_objectness': 0.48656874895095825, 'loss_rpn_box_reg': 0.22751037776470184}
  Batch [240/1526] Loss: 1.6420 Components: {'loss_classifier': 0.241254985332489, 'loss_box_reg': 0.1312030553817749, 'loss_mask': 1.083775520324707, 'loss_objectness': 0.1623460054397583, 'loss_rpn_box_reg': 0.02343444712460041}
  Batch [290/1526] Loss: 0.3273 Components: {'loss_classifier': 0.039884645491838455, 'loss_box_reg': 0.0035685154143720865, 'loss_mask': 0.06404637545347214, 'loss_objectness': 0.17862999439239502, 'loss_rpn_box_reg': 0.04121517762541771}
  Batch [370/1526] Loss: 0.4927 Components: {'loss_classifier': 0.13132546842098236, 'loss_box_reg': 0.06729662418365479, 'loss_mask': 0.19079448282718658, 'loss_objectness': 0.093594491481781, 'loss_rpn_box_reg': 0.009711658582091331}
  Batch [390/1526] Loss: 1.5078 Components: {'loss_classifier': 0.20526787638664246, 'loss_box_reg': 0.08003881573677063, 'loss_mask': 0.994957447052002, 'loss_objectness': 0.17786303162574768, 'loss_rpn_box_reg': 0.04970328509807587}
  Batch [430/1526] Loss: 0.7074 Components: {'loss_classifier': 0.2627539038658142, 'loss_box_reg': 0.13979887962341309, 'loss_mask': 0.019926076754927635, 'loss_objectness': 0.26247885823249817, 'loss_rpn_box_reg': 0.022410031408071518}
  Batch [460/1526] Loss: 0.8199 Components: {'loss_classifier': 0.09229777753353119, 'loss_box_reg': 0.04174081236124039, 'loss_mask': 0.3872378170490265, 'loss_objectness': 0.2707822322845459, 'loss_rpn_box_reg': 0.02787366509437561}
  Batch [510/1526] Loss: 0.5526 Components: {'loss_classifier': 0.1339152455329895, 'loss_box_reg': 0.06000209227204323, 'loss_mask': 0.30166095495224, 'loss_objectness': 0.05095444992184639, 'loss_rpn_box_reg': 0.006058074068278074}
  Batch [620/1526] Loss: 0.5590 Components: {'loss_classifier': 0.09953473508358002, 'loss_box_reg': 0.029640546068549156, 'loss_mask': 0.11996818333864212, 'loss_objectness': 0.2788008451461792, 'loss_rpn_box_reg': 0.031064258888363838}
  Batch [750/1526] Loss: 0.4371 Components: {'loss_classifier': 0.05405034124851227, 'loss_box_reg': 0.01653311774134636, 'loss_mask': 0.23579776287078857, 'loss_objectness': 0.11268959939479828, 'loss_rpn_box_reg': 0.018031522631645203}
  Batch [910/1526] Loss: 0.5831 Components: {'loss_classifier': 0.0809892863035202, 'loss_box_reg': 0.026042625308036804, 'loss_mask': 0.03746014088392258, 'loss_objectness': 0.3088677227497101, 'loss_rpn_box_reg': 0.12972044944763184}
  Batch [920/1526] Loss: 0.3123 Components: {'loss_classifier': 0.03721165657043457, 'loss_box_reg': 0.0033847622107714415, 'loss_mask': 0.01905873417854309, 'loss_objectness': 0.24324540793895721, 'loss_rpn_box_reg': 0.009414039552211761}
  Batch [950/1526] Loss: 1.5362 Components: {'loss_classifier': 0.5322493314743042, 'loss_box_reg': 0.2465716302394867, 'loss_mask': 0.0010655110236257315, 'loss_objectness': 0.5007041692733765, 'loss_rpn_box_reg': 0.255607545375824}
  Batch [1000/1526] Loss: 0.8569 Components: {'loss_classifier': 0.0630153939127922, 'loss_box_reg': 0.00511310575529933, 'loss_mask': 0.3063839375972748, 'loss_objectness': 0.35812756419181824, 'loss_rpn_box_reg': 0.12421204149723053}
  Batch [1050/1526] Loss: 1.4360 Components: {'loss_classifier': 0.3003205955028534, 'loss_box_reg': 0.10571383684873581, 'loss_mask': 0.023824086412787437, 'loss_objectness': 0.6291603446006775, 'loss_rpn_box_reg': 0.37694767117500305}
  Batch [1070/1526] Loss: 1.7772 Components: {'loss_classifier': 0.3815011978149414, 'loss_box_reg': 0.042005859315395355, 'loss_mask': 0.028715984895825386, 'loss_objectness': 0.5724562406539917, 'loss_rpn_box_reg': 0.7525098919868469}
  Batch [1080/1526] Loss: 0.4788 Components: {'loss_classifier': 0.19157373905181885, 'loss_box_reg': 0.0932755321264267, 'loss_mask': 0.04011426120996475, 'loss_objectness': 0.14659419655799866, 'loss_rpn_box_reg': 0.007209342904388905}
  Batch [1120/1526] Loss: 0.5757 Components: {'loss_classifier': 0.09240125864744186, 'loss_box_reg': 0.04007382690906525, 'loss_mask': 0.21922290325164795, 'loss_objectness': 0.19494427740573883, 'loss_rpn_box_reg': 0.029096685349941254}
  Batch [1210/1526] Loss: 0.6128 Components: {'loss_classifier': 0.1570223718881607, 'loss_box_reg': 0.04949275776743889, 'loss_mask': 0.004605933558195829, 'loss_objectness': 0.244314506649971, 'loss_rpn_box_reg': 0.15732534229755402}
  Batch [1240/1526] Loss: 0.5269 Components: {'loss_classifier': 0.25520944595336914, 'loss_box_reg': 0.08120959252119064, 'loss_mask': 0.011044234037399292, 'loss_objectness': 0.166770339012146, 'loss_rpn_box_reg': 0.012636430561542511}
  Batch [1340/1526] Loss: 1.3954 Components: {'loss_classifier': 0.2680788040161133, 'loss_box_reg': 0.053473543375730515, 'loss_mask': 0.0325547531247139, 'loss_objectness': 0.6782079339027405, 'loss_rpn_box_reg': 0.3630443811416626}
  Batch [1350/1526] Loss: 0.5016 Components: {'loss_classifier': 0.05520816892385483, 'loss_box_reg': 0.0038392290007323027, 'loss_mask': 0.05950048938393593, 'loss_objectness': 0.3638764023780823, 'loss_rpn_box_reg': 0.01917458511888981}
  Batch [1420/1526] Loss: 1.5370 Components: {'loss_classifier': 0.42365795373916626, 'loss_box_reg': 0.049727655947208405, 'loss_mask': 0.014575137756764889, 'loss_objectness': 0.4173170328140259, 'loss_rpn_box_reg': 0.6317210793495178}
  Batch [1430/1526] Loss: 7.7255 Components: {'loss_classifier': 0.13700450956821442, 'loss_box_reg': 0.03384557366371155, 'loss_mask': 0.07267170399427414, 'loss_objectness': 1.149424433708191, 'loss_rpn_box_reg': 6.332511901855469}
  Batch [1480/1526] Loss: 1.1844 Components: {'loss_classifier': 0.218304842710495, 'loss_box_reg': 0.03048328310251236, 'loss_mask': 0.2683223485946655, 'loss_objectness': 0.4888196289539337, 'loss_rpn_box_reg': 0.17845763266086578}
  Batch [1490/1526] Loss: 0.5738 Components: {'loss_classifier': 0.036595866084098816, 'loss_box_reg': 0.0019153915345668793, 'loss_mask': 0.10629807412624359, 'loss_objectness': 0.37727466225624084, 'loss_rpn_box_reg': 0.05172652378678322}
  Batch [1510/1526] Loss: 0.4292 Components: {'loss_classifier': 0.18051224946975708, 'loss_box_reg': 0.0697411596775055, 'loss_mask': 0.10822194069623947, 'loss_objectness': 0.06213393434882164, 'loss_rpn_box_reg': 0.008622655645012856}

Epoch 3 Summary:
  Train Loss: 1.3973
  Val Loss: 1.6118
  Learning Rate: 0.001600
  Epoch Time: 2731.9s
  EarlyStopping counter: 2 out of 15

Epoch 4/100
----------------------------------------
  Batch [30/1526] Loss: 1.7751 Components: {'loss_classifier': 0.4572887122631073, 'loss_box_reg': 0.09286008030176163, 'loss_mask': 0.005908715073019266, 'loss_objectness': 0.637783408164978, 'loss_rpn_box_reg': 0.581243634223938}
  Batch [200/1526] Loss: 0.7334 Components: {'loss_classifier': 0.12554676830768585, 'loss_box_reg': 0.061964232474565506, 'loss_mask': 0.4363083243370056, 'loss_objectness': 0.10604377835988998, 'loss_rpn_box_reg': 0.0035159937106072903}
  Batch [250/1526] Loss: 0.5230 Components: {'loss_classifier': 0.04848821833729744, 'loss_box_reg': 0.003200465114787221, 'loss_mask': 0.026634063571691513, 'loss_objectness': 0.2757177948951721, 'loss_rpn_box_reg': 0.1689750701189041}
  Batch [290/1526] Loss: 0.1628 Components: {'loss_classifier': 0.06235085055232048, 'loss_box_reg': 0.013985401019454002, 'loss_mask': 0.0017786449752748013, 'loss_objectness': 0.07687821239233017, 'loss_rpn_box_reg': 0.00776040181517601}
  Batch [410/1526] Loss: 0.4071 Components: {'loss_classifier': 0.11868847161531448, 'loss_box_reg': 0.046746112406253815, 'loss_mask': 0.06894846260547638, 'loss_objectness': 0.14807429909706116, 'loss_rpn_box_reg': 0.02469238080084324}
  Batch [570/1526] Loss: 1.4925 Components: {'loss_classifier': 0.23885726928710938, 'loss_box_reg': 0.0505058616399765, 'loss_mask': 0.002183131640776992, 'loss_objectness': 0.4279772639274597, 'loss_rpn_box_reg': 0.7729620337486267}
  Batch [650/1526] Loss: 0.3150 Components: {'loss_classifier': 0.07452137023210526, 'loss_box_reg': 0.022740840911865234, 'loss_mask': 0.0029743893537670374, 'loss_objectness': 0.18489335477352142, 'loss_rpn_box_reg': 0.029869256541132927}
  Batch [710/1526] Loss: 0.4429 Components: {'loss_classifier': 0.0775398537516594, 'loss_box_reg': 0.0039046178571879864, 'loss_mask': 0.008543766103684902, 'loss_objectness': 0.28595343232154846, 'loss_rpn_box_reg': 0.06700380146503448}
  Batch [800/1526] Loss: 0.7265 Components: {'loss_classifier': 0.14698661863803864, 'loss_box_reg': 0.057996802031993866, 'loss_mask': 0.003836523974314332, 'loss_objectness': 0.31918686628341675, 'loss_rpn_box_reg': 0.19851930439472198}
  Batch [880/1526] Loss: 0.7670 Components: {'loss_classifier': 0.24594438076019287, 'loss_box_reg': 0.09140587598085403, 'loss_mask': 0.07035569846630096, 'loss_objectness': 0.2315438836812973, 'loss_rpn_box_reg': 0.12770898640155792}
  Batch [890/1526] Loss: 0.8282 Components: {'loss_classifier': 0.10644025355577469, 'loss_box_reg': 0.012119526974856853, 'loss_mask': 0.0018534124828875065, 'loss_objectness': 0.37353765964508057, 'loss_rpn_box_reg': 0.33427348732948303}
  Batch [940/1526] Loss: 0.3609 Components: {'loss_classifier': 0.16504564881324768, 'loss_box_reg': 0.08621497452259064, 'loss_mask': 0.014282050542533398, 'loss_objectness': 0.07960798591375351, 'loss_rpn_box_reg': 0.01578535884618759}
  Batch [970/1526] Loss: 1.3083 Components: {'loss_classifier': 0.38218894600868225, 'loss_box_reg': 0.11545652151107788, 'loss_mask': 0.007718563079833984, 'loss_objectness': 0.47048431634902954, 'loss_rpn_box_reg': 0.3325014114379883}
  Batch [1080/1526] Loss: 1.3252 Components: {'loss_classifier': 0.453960657119751, 'loss_box_reg': 0.22999048233032227, 'loss_mask': 0.15876315534114838, 'loss_objectness': 0.246159628033638, 'loss_rpn_box_reg': 0.23637402057647705}
  Batch [1150/1526] Loss: 0.7537 Components: {'loss_classifier': 0.15800610184669495, 'loss_box_reg': 0.06945241987705231, 'loss_mask': 0.20788873732089996, 'loss_objectness': 0.2359732687473297, 'loss_rpn_box_reg': 0.08235973864793777}
  Batch [1160/1526] Loss: 1.5439 Components: {'loss_classifier': 0.14400146901607513, 'loss_box_reg': 0.07210882008075714, 'loss_mask': 1.247310757637024, 'loss_objectness': 0.07133231312036514, 'loss_rpn_box_reg': 0.009137775748968124}
  Batch [1230/1526] Loss: 1.3170 Components: {'loss_classifier': 0.5007984042167664, 'loss_box_reg': 0.3046758770942688, 'loss_mask': 0.04458659142255783, 'loss_objectness': 0.32773876190185547, 'loss_rpn_box_reg': 0.13924351334571838}
  Batch [1320/1526] Loss: 0.8027 Components: {'loss_classifier': 0.1353670358657837, 'loss_box_reg': 0.05065039172768593, 'loss_mask': 0.25023195147514343, 'loss_objectness': 0.1905844509601593, 'loss_rpn_box_reg': 0.17586037516593933}
  Batch [1360/1526] Loss: 20.6729 Components: {'loss_classifier': 0.04451920837163925, 'loss_box_reg': 0.0015412335051223636, 'loss_mask': 0.04974206164479256, 'loss_objectness': 1.4109083414077759, 'loss_rpn_box_reg': 19.16622543334961}
  Batch [1400/1526] Loss: 0.9311 Components: {'loss_classifier': 0.10686147212982178, 'loss_box_reg': 0.011742796748876572, 'loss_mask': 0.12885291874408722, 'loss_objectness': 0.4979843199253082, 'loss_rpn_box_reg': 0.1856430172920227}
  Batch [1430/1526] Loss: 12.7603 Components: {'loss_classifier': 0.14628562331199646, 'loss_box_reg': 0.03596142306923866, 'loss_mask': 0.03074161894619465, 'loss_objectness': 0.6513420939445496, 'loss_rpn_box_reg': 11.895930290222168}
  Batch [1490/1526] Loss: 0.6998 Components: {'loss_classifier': 0.07332687824964523, 'loss_box_reg': 0.012147498317062855, 'loss_mask': 0.0009380747796967626, 'loss_objectness': 0.31589117646217346, 'loss_rpn_box_reg': 0.29754480719566345}

Epoch 4 Summary:
  Train Loss: 1.3325
  Val Loss: 1.4772
  Learning Rate: 0.002000
  Epoch Time: 2501.2s
  ✓ Saved best model (val_loss: 1.4772)
  Validation loss decreased (1.575270 --> 1.477181). Saving model...

Epoch 5/100
----------------------------------------
  Batch [10/1526] Loss: 0.7329 Components: {'loss_classifier': 0.2575426697731018, 'loss_box_reg': 0.12913468480110168, 'loss_mask': 0.00624890998005867, 'loss_objectness': 0.18181730806827545, 'loss_rpn_box_reg': 0.15817119181156158}
  Batch [30/1526] Loss: 0.6937 Components: {'loss_classifier': 0.2407071739435196, 'loss_box_reg': 0.08730260282754898, 'loss_mask': 0.0018950838129967451, 'loss_objectness': 0.2683894634246826, 'loss_rpn_box_reg': 0.09543479979038239}
  Batch [190/1526] Loss: 1.3998 Components: {'loss_classifier': 0.1900629848241806, 'loss_box_reg': 0.10623319447040558, 'loss_mask': 0.18726585805416107, 'loss_objectness': 0.569826602935791, 'loss_rpn_box_reg': 0.34638646245002747}
  Batch [210/1526] Loss: 0.7848 Components: {'loss_classifier': 0.2677888572216034, 'loss_box_reg': 0.08078507333993912, 'loss_mask': 0.00037279093521647155, 'loss_objectness': 0.20912213623523712, 'loss_rpn_box_reg': 0.2266981601715088}
  Batch [340/1526] Loss: 0.9414 Components: {'loss_classifier': 0.4118380844593048, 'loss_box_reg': 0.06002996116876602, 'loss_mask': 0.013933815062046051, 'loss_objectness': 0.2920510470867157, 'loss_rpn_box_reg': 0.16352935135364532}
  Batch [380/1526] Loss: 0.9808 Components: {'loss_classifier': 0.12299543619155884, 'loss_box_reg': 0.012418704107403755, 'loss_mask': 0.15408505499362946, 'loss_objectness': 0.3873339295387268, 'loss_rpn_box_reg': 0.30401113629341125}
  Batch [500/1526] Loss: 0.8819 Components: {'loss_classifier': 0.21969272196292877, 'loss_box_reg': 0.12844692170619965, 'loss_mask': 0.3353050947189331, 'loss_objectness': 0.15320582687854767, 'loss_rpn_box_reg': 0.04526485130190849}
  Batch [530/1526] Loss: 0.8613 Components: {'loss_classifier': 0.1056593507528305, 'loss_box_reg': 0.03544766083359718, 'loss_mask': 0.5937720537185669, 'loss_objectness': 0.11725586652755737, 'loss_rpn_box_reg': 0.009201126173138618}
  Batch [560/1526] Loss: 21.6610 Components: {'loss_classifier': 0.10973943024873734, 'loss_box_reg': 0.012227946892380714, 'loss_mask': 0.013457928784191608, 'loss_objectness': 1.269281029701233, 'loss_rpn_box_reg': 20.256288528442383}
  Batch [590/1526] Loss: 0.3037 Components: {'loss_classifier': 0.08156006783246994, 'loss_box_reg': 0.05655844137072563, 'loss_mask': 0.0036294003948569298, 'loss_objectness': 0.14206425845623016, 'loss_rpn_box_reg': 0.01991226151585579}
  Batch [650/1526] Loss: 1.1541 Components: {'loss_classifier': 0.37047696113586426, 'loss_box_reg': 0.2368008941411972, 'loss_mask': 0.42433035373687744, 'loss_objectness': 0.10500685125589371, 'loss_rpn_box_reg': 0.017446240410208702}
  Batch [700/1526] Loss: 0.5494 Components: {'loss_classifier': 0.10749692469835281, 'loss_box_reg': 0.01938689313828945, 'loss_mask': 0.051332440227270126, 'loss_objectness': 0.2866978049278259, 'loss_rpn_box_reg': 0.08450540900230408}
  Batch [750/1526] Loss: 0.6077 Components: {'loss_classifier': 0.1224694475531578, 'loss_box_reg': 0.04502484202384949, 'loss_mask': 0.0233305674046278, 'loss_objectness': 0.32861918210983276, 'loss_rpn_box_reg': 0.08829272538423538}
  Batch [800/1526] Loss: 0.5403 Components: {'loss_classifier': 0.13670840859413147, 'loss_box_reg': 0.09180646389722824, 'loss_mask': 0.17982912063598633, 'loss_objectness': 0.11186771839857101, 'loss_rpn_box_reg': 0.020138056948781013}
  Batch [850/1526] Loss: 1.1983 Components: {'loss_classifier': 0.20775876939296722, 'loss_box_reg': 0.1446639597415924, 'loss_mask': 0.7254086136817932, 'loss_objectness': 0.10326896607875824, 'loss_rpn_box_reg': 0.017197929322719574}
  Batch [910/1526] Loss: 0.5956 Components: {'loss_classifier': 0.13333648443222046, 'loss_box_reg': 0.040979012846946716, 'loss_mask': 0.13501644134521484, 'loss_objectness': 0.22703205049037933, 'loss_rpn_box_reg': 0.0592343732714653}
  Batch [940/1526] Loss: 0.7742 Components: {'loss_classifier': 0.19171017408370972, 'loss_box_reg': 0.05709398165345192, 'loss_mask': 0.037273652851581573, 'loss_objectness': 0.3061910569667816, 'loss_rpn_box_reg': 0.18190594017505646}
  Batch [990/1526] Loss: 0.9173 Components: {'loss_classifier': 0.06651433557271957, 'loss_box_reg': 0.007402419578284025, 'loss_mask': 0.037711288779973984, 'loss_objectness': 0.4523937404155731, 'loss_rpn_box_reg': 0.3532736897468567}
  Batch [1020/1526] Loss: 0.6169 Components: {'loss_classifier': 0.1083722934126854, 'loss_box_reg': 0.021999193355441093, 'loss_mask': 0.0017672780668362975, 'loss_objectness': 0.20591285824775696, 'loss_rpn_box_reg': 0.27883756160736084}
  Batch [1220/1526] Loss: 0.3483 Components: {'loss_classifier': 0.1377084106206894, 'loss_box_reg': 0.05036376789212227, 'loss_mask': 0.020984971895813942, 'loss_objectness': 0.12834414839744568, 'loss_rpn_box_reg': 0.0109000438824296}
  Batch [1230/1526] Loss: 0.6397 Components: {'loss_classifier': 0.20427079498767853, 'loss_box_reg': 0.09504763036966324, 'loss_mask': 0.13885487616062164, 'loss_objectness': 0.16004201769828796, 'loss_rpn_box_reg': 0.04144953191280365}
  Batch [1240/1526] Loss: 1.0464 Components: {'loss_classifier': 0.3159150183200836, 'loss_box_reg': 0.17243342101573944, 'loss_mask': 0.06507225334644318, 'loss_objectness': 0.1958344429731369, 'loss_rpn_box_reg': 0.2971530556678772}
  Batch [1430/1526] Loss: 1.5032 Components: {'loss_classifier': 0.1596830189228058, 'loss_box_reg': 0.0910995826125145, 'loss_mask': 1.0928972959518433, 'loss_objectness': 0.1313716024160385, 'loss_rpn_box_reg': 0.02818039432168007}
  Batch [1510/1526] Loss: 2.3043 Components: {'loss_classifier': 0.10694224387407303, 'loss_box_reg': 0.007203820627182722, 'loss_mask': 0.011787621304392815, 'loss_objectness': 0.6520627737045288, 'loss_rpn_box_reg': 1.5263398885726929}

Epoch 5 Summary:
  Train Loss: 1.6535
  Val Loss: 1.5133
  Learning Rate: 0.002000
  Epoch Time: 2487.4s
  EarlyStopping counter: 1 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 6/100
----------------------------------------
  Batch [30/1526] Loss: 0.5481 Components: {'loss_classifier': 0.05702345445752144, 'loss_box_reg': 0.00242793932557106, 'loss_mask': 0.049658581614494324, 'loss_objectness': 0.3748711943626404, 'loss_rpn_box_reg': 0.0641547366976738}
  Batch [90/1526] Loss: 0.3653 Components: {'loss_classifier': 0.06133337691426277, 'loss_box_reg': 0.028094802051782608, 'loss_mask': 0.08350399136543274, 'loss_objectness': 0.18227125704288483, 'loss_rpn_box_reg': 0.010136542841792107}
  Batch [280/1526] Loss: 0.5824 Components: {'loss_classifier': 0.08575030416250229, 'loss_box_reg': 0.04308784008026123, 'loss_mask': 0.24940142035484314, 'loss_objectness': 0.1471603363752365, 'loss_rpn_box_reg': 0.057005204260349274}
  Batch [310/1526] Loss: 0.3213 Components: {'loss_classifier': 0.1343504786491394, 'loss_box_reg': 0.04987848177552223, 'loss_mask': 0.018939141184091568, 'loss_objectness': 0.10079751163721085, 'loss_rpn_box_reg': 0.017351316288113594}
  Batch [320/1526] Loss: 0.7443 Components: {'loss_classifier': 0.11223303526639938, 'loss_box_reg': 0.03472030907869339, 'loss_mask': 0.01062909048050642, 'loss_objectness': 0.16273285448551178, 'loss_rpn_box_reg': 0.4239893853664398}
  Batch [370/1526] Loss: 0.7855 Components: {'loss_classifier': 0.22774359583854675, 'loss_box_reg': 0.11455146968364716, 'loss_mask': 0.27887505292892456, 'loss_objectness': 0.1407431811094284, 'loss_rpn_box_reg': 0.023578619584441185}
  Batch [480/1526] Loss: 0.5961 Components: {'loss_classifier': 0.2272045761346817, 'loss_box_reg': 0.11323157697916031, 'loss_mask': 0.14659905433654785, 'loss_objectness': 0.09924241155385971, 'loss_rpn_box_reg': 0.009807057678699493}
  Batch [610/1526] Loss: 0.3192 Components: {'loss_classifier': 0.08786117285490036, 'loss_box_reg': 0.04164254665374756, 'loss_mask': 0.019271735101938248, 'loss_objectness': 0.15981045365333557, 'loss_rpn_box_reg': 0.0105736730620265}
  Batch [640/1526] Loss: 0.6067 Components: {'loss_classifier': 0.30092278122901917, 'loss_box_reg': 0.1475818008184433, 'loss_mask': 0.039138052612543106, 'loss_objectness': 0.09633342921733856, 'loss_rpn_box_reg': 0.022680968046188354}
  Batch [650/1526] Loss: 0.6874 Components: {'loss_classifier': 0.18438930809497833, 'loss_box_reg': 0.03437952697277069, 'loss_mask': 0.018489455804228783, 'loss_objectness': 0.26022592186927795, 'loss_rpn_box_reg': 0.1899339109659195}
  Batch [700/1526] Loss: 0.7912 Components: {'loss_classifier': 0.23614123463630676, 'loss_box_reg': 0.07228411734104156, 'loss_mask': 0.006382612511515617, 'loss_objectness': 0.30989253520965576, 'loss_rpn_box_reg': 0.16645410656929016}
  Batch [720/1526] Loss: 0.8101 Components: {'loss_classifier': 0.16962432861328125, 'loss_box_reg': 0.03217390179634094, 'loss_mask': 0.12933392822742462, 'loss_objectness': 0.22087626159191132, 'loss_rpn_box_reg': 0.25812095403671265}
  Batch [730/1526] Loss: 0.5715 Components: {'loss_classifier': 0.10792554914951324, 'loss_box_reg': 0.06870286166667938, 'loss_mask': 0.24926386773586273, 'loss_objectness': 0.13226105272769928, 'loss_rpn_box_reg': 0.013382885605096817}
  Batch [810/1526] Loss: 0.6056 Components: {'loss_classifier': 0.14998026192188263, 'loss_box_reg': 0.06002184376120567, 'loss_mask': 0.003577603492885828, 'loss_objectness': 0.21997348964214325, 'loss_rpn_box_reg': 0.1720418483018875}
  Batch [820/1526] Loss: 0.3151 Components: {'loss_classifier': 0.09726044535636902, 'loss_box_reg': 0.032617244869470596, 'loss_mask': 0.0534401535987854, 'loss_objectness': 0.11077076941728592, 'loss_rpn_box_reg': 0.020992957055568695}
  Batch [830/1526] Loss: 0.2382 Components: {'loss_classifier': 0.09279556572437286, 'loss_box_reg': 0.02674485556781292, 'loss_mask': 0.0016352321254089475, 'loss_objectness': 0.10694961249828339, 'loss_rpn_box_reg': 0.01003078743815422}
  Batch [880/1526] Loss: 0.3264 Components: {'loss_classifier': 0.07267357409000397, 'loss_box_reg': 0.03141729161143303, 'loss_mask': 0.11454740911722183, 'loss_objectness': 0.0875522643327713, 'loss_rpn_box_reg': 0.020178060978651047}
  Batch [1000/1526] Loss: 0.7226 Components: {'loss_classifier': 0.11097729206085205, 'loss_box_reg': 0.03244563564658165, 'loss_mask': 0.23128026723861694, 'loss_objectness': 0.20314668118953705, 'loss_rpn_box_reg': 0.1447950005531311}
  Batch [1120/1526] Loss: 0.3667 Components: {'loss_classifier': 0.1573183536529541, 'loss_box_reg': 0.06437955051660538, 'loss_mask': 0.01563454419374466, 'loss_objectness': 0.11978105455636978, 'loss_rpn_box_reg': 0.009576731361448765}
  Batch [1230/1526] Loss: 0.8535 Components: {'loss_classifier': 0.14211179316043854, 'loss_box_reg': 0.019176119938492775, 'loss_mask': 0.010663371533155441, 'loss_objectness': 0.43822726607322693, 'loss_rpn_box_reg': 0.24335409700870514}
  Batch [1240/1526] Loss: 0.5497 Components: {'loss_classifier': 0.18740567564964294, 'loss_box_reg': 0.11473503708839417, 'loss_mask': 0.1350170224905014, 'loss_objectness': 0.10796227306127548, 'loss_rpn_box_reg': 0.00460406020283699}
  Batch [1280/1526] Loss: 12.0069 Components: {'loss_classifier': 0.3309724032878876, 'loss_box_reg': 0.11190943419933319, 'loss_mask': 0.37309086322784424, 'loss_objectness': 0.7008821964263916, 'loss_rpn_box_reg': 10.490044593811035}
  Batch [1340/1526] Loss: 0.7838 Components: {'loss_classifier': 0.09131328016519547, 'loss_box_reg': 0.0279301255941391, 'loss_mask': 0.269060343503952, 'loss_objectness': 0.24281905591487885, 'loss_rpn_box_reg': 0.15271495282649994}
  Batch [1450/1526] Loss: 0.4928 Components: {'loss_classifier': 0.08377610146999359, 'loss_box_reg': 0.03471066802740097, 'loss_mask': 0.009679063223302364, 'loss_objectness': 0.21615929901599884, 'loss_rpn_box_reg': 0.14846214652061462}
  Batch [1470/1526] Loss: 1.7522 Components: {'loss_classifier': 0.76549232006073, 'loss_box_reg': 0.32128214836120605, 'loss_mask': 0.0004531412268988788, 'loss_objectness': 0.36155399680137634, 'loss_rpn_box_reg': 0.30336955189704895}

Epoch 6 Summary:
  Train Loss: 1.2258
  Val Loss: 1.3371
  Learning Rate: 0.002000
  Epoch Time: 2556.5s
  ✓ Saved best model (val_loss: 1.3371)
  Validation loss decreased (1.477181 --> 1.337097). Saving model...

Epoch 7/100
----------------------------------------
  Batch [160/1526] Loss: 1.2702 Components: {'loss_classifier': 0.369203120470047, 'loss_box_reg': 0.201624795794487, 'loss_mask': 0.5205055475234985, 'loss_objectness': 0.15854719281196594, 'loss_rpn_box_reg': 0.02030239626765251}
  Batch [180/1526] Loss: 0.6144 Components: {'loss_classifier': 0.19878257811069489, 'loss_box_reg': 0.05215387046337128, 'loss_mask': 0.0015253248857334256, 'loss_objectness': 0.3093329071998596, 'loss_rpn_box_reg': 0.05262181907892227}
  Batch [240/1526] Loss: 0.8346 Components: {'loss_classifier': 0.18908141553401947, 'loss_box_reg': 0.0979066789150238, 'loss_mask': 0.283719927072525, 'loss_objectness': 0.19935007393360138, 'loss_rpn_box_reg': 0.06452183425426483}
  Batch [330/1526] Loss: 1.4538 Components: {'loss_classifier': 0.05484369024634361, 'loss_box_reg': 0.012242831289768219, 'loss_mask': 1.230575680732727, 'loss_objectness': 0.10181687772274017, 'loss_rpn_box_reg': 0.054357901215553284}
  Batch [350/1526] Loss: 0.9394 Components: {'loss_classifier': 0.25397980213165283, 'loss_box_reg': 0.11974320560693741, 'loss_mask': 0.01264103688299656, 'loss_objectness': 0.14277398586273193, 'loss_rpn_box_reg': 0.41021695733070374}
  Batch [450/1526] Loss: 0.6012 Components: {'loss_classifier': 0.0788191482424736, 'loss_box_reg': 0.022516723722219467, 'loss_mask': 0.30383914709091187, 'loss_objectness': 0.19154901802539825, 'loss_rpn_box_reg': 0.004491964355111122}
  Batch [460/1526] Loss: 0.1960 Components: {'loss_classifier': 0.08548514544963837, 'loss_box_reg': 0.03394744172692299, 'loss_mask': 0.006600812077522278, 'loss_objectness': 0.057317476719617844, 'loss_rpn_box_reg': 0.01266010943800211}
  Batch [520/1526] Loss: 0.3893 Components: {'loss_classifier': 0.13291297852993011, 'loss_box_reg': 0.05649925768375397, 'loss_mask': 0.06685909628868103, 'loss_objectness': 0.11806848645210266, 'loss_rpn_box_reg': 0.014927122741937637}
  Batch [680/1526] Loss: 0.5737 Components: {'loss_classifier': 0.07202858477830887, 'loss_box_reg': 0.027687422931194305, 'loss_mask': 0.2683098316192627, 'loss_objectness': 0.1737232506275177, 'loss_rpn_box_reg': 0.03197444602847099}
  Batch [740/1526] Loss: 0.9020 Components: {'loss_classifier': 0.30947017669677734, 'loss_box_reg': 0.08408412337303162, 'loss_mask': 0.0009104241617023945, 'loss_objectness': 0.29463091492652893, 'loss_rpn_box_reg': 0.21289698779582977}
  Batch [830/1526] Loss: 0.9301 Components: {'loss_classifier': 0.2577947974205017, 'loss_box_reg': 0.14140242338180542, 'loss_mask': 0.41968250274658203, 'loss_objectness': 0.10289964079856873, 'loss_rpn_box_reg': 0.008272831328213215}
  Batch [870/1526] Loss: 0.6605 Components: {'loss_classifier': 0.16574044525623322, 'loss_box_reg': 0.0647181048989296, 'loss_mask': 0.0002740694035310298, 'loss_objectness': 0.24074490368366241, 'loss_rpn_box_reg': 0.18907243013381958}
  Batch [1060/1526] Loss: 0.5049 Components: {'loss_classifier': 0.2147289663553238, 'loss_box_reg': 0.08533577620983124, 'loss_mask': 0.053131356835365295, 'loss_objectness': 0.1379086971282959, 'loss_rpn_box_reg': 0.013810301199555397}
  Batch [1170/1526] Loss: 0.5301 Components: {'loss_classifier': 0.1957017332315445, 'loss_box_reg': 0.11339374631643295, 'loss_mask': 0.046494338661432266, 'loss_objectness': 0.15065190196037292, 'loss_rpn_box_reg': 0.023876704275608063}
  Batch [1180/1526] Loss: 6.2876 Components: {'loss_classifier': 0.14551973342895508, 'loss_box_reg': 0.04675997793674469, 'loss_mask': 0.03248690441250801, 'loss_objectness': 1.1820565462112427, 'loss_rpn_box_reg': 4.880727291107178}
  Batch [1190/1526] Loss: 0.2784 Components: {'loss_classifier': 0.06725402176380157, 'loss_box_reg': 0.023894285783171654, 'loss_mask': 0.06030891090631485, 'loss_objectness': 0.10471101850271225, 'loss_rpn_box_reg': 0.022205274552106857}
  Batch [1200/1526] Loss: 0.4364 Components: {'loss_classifier': 0.12867015600204468, 'loss_box_reg': 0.07459457218647003, 'loss_mask': 0.08678650110960007, 'loss_objectness': 0.11745653301477432, 'loss_rpn_box_reg': 0.02885780856013298}
  Batch [1250/1526] Loss: 0.4975 Components: {'loss_classifier': 0.10049324482679367, 'loss_box_reg': 0.035054419189691544, 'loss_mask': 0.005036709830164909, 'loss_objectness': 0.2337140589952469, 'loss_rpn_box_reg': 0.12315195053815842}
  Batch [1370/1526] Loss: 1.2361 Components: {'loss_classifier': 0.382752001285553, 'loss_box_reg': 0.08655912429094315, 'loss_mask': 0.03067370131611824, 'loss_objectness': 0.28520309925079346, 'loss_rpn_box_reg': 0.4509085416793823}
  Batch [1420/1526] Loss: 0.8463 Components: {'loss_classifier': 0.20363064110279083, 'loss_box_reg': 0.03151525557041168, 'loss_mask': 0.0009945235215127468, 'loss_objectness': 0.3727184534072876, 'loss_rpn_box_reg': 0.2374838888645172}
  Batch [1470/1526] Loss: 0.4162 Components: {'loss_classifier': 0.06202787160873413, 'loss_box_reg': 0.019547585397958755, 'loss_mask': 0.13318447768688202, 'loss_objectness': 0.11356506496667862, 'loss_rpn_box_reg': 0.0878644734621048}
  Batch [1520/1526] Loss: 1.1654 Components: {'loss_classifier': 0.09703008085489273, 'loss_box_reg': 0.045896586030721664, 'loss_mask': 0.9683301448822021, 'loss_objectness': 0.05143404379487038, 'loss_rpn_box_reg': 0.0027291537262499332}

Epoch 7 Summary:
  Train Loss: 1.4855
  Val Loss: 1.3923
  Learning Rate: 0.002000
  Epoch Time: 2426.6s
  EarlyStopping counter: 1 out of 15

Epoch 8/100
----------------------------------------
  Batch [0/1526] Loss: 0.3399 Components: {'loss_classifier': 0.137703537940979, 'loss_box_reg': 0.056455112993717194, 'loss_mask': 0.0033731553703546524, 'loss_objectness': 0.11660012602806091, 'loss_rpn_box_reg': 0.02575613558292389}
  Batch [60/1526] Loss: 1.2176 Components: {'loss_classifier': 0.17812010645866394, 'loss_box_reg': 0.10007631778717041, 'loss_mask': 0.00034465070348232985, 'loss_objectness': 0.3991504907608032, 'loss_rpn_box_reg': 0.5398959517478943}
  Batch [110/1526] Loss: 0.1650 Components: {'loss_classifier': 0.05712718889117241, 'loss_box_reg': 0.005810498259961605, 'loss_mask': 0.0035485317930579185, 'loss_objectness': 0.09291782975196838, 'loss_rpn_box_reg': 0.005592211615294218}
  Batch [180/1526] Loss: 1.0828 Components: {'loss_classifier': 0.4067518711090088, 'loss_box_reg': 0.2429782897233963, 'loss_mask': 0.287789911031723, 'loss_objectness': 0.12422768026590347, 'loss_rpn_box_reg': 0.02106739766895771}
  Batch [320/1526] Loss: 0.1445 Components: {'loss_classifier': 0.03154145926237106, 'loss_box_reg': 0.0009103430202230811, 'loss_mask': 0.02472316473722458, 'loss_objectness': 0.0706079825758934, 'loss_rpn_box_reg': 0.016728602349758148}
  Batch [380/1526] Loss: 0.8886 Components: {'loss_classifier': 0.31364235281944275, 'loss_box_reg': 0.09790562838315964, 'loss_mask': 0.01633898913860321, 'loss_objectness': 0.2857452630996704, 'loss_rpn_box_reg': 0.17497046291828156}
  Batch [400/1526] Loss: 0.3559 Components: {'loss_classifier': 0.16708427667617798, 'loss_box_reg': 0.09202444553375244, 'loss_mask': 0.010564127005636692, 'loss_objectness': 0.07274109125137329, 'loss_rpn_box_reg': 0.013497129082679749}
  Batch [410/1526] Loss: 0.5391 Components: {'loss_classifier': 0.17471012473106384, 'loss_box_reg': 0.09387508779764175, 'loss_mask': 0.14662159979343414, 'loss_objectness': 0.11594107002019882, 'loss_rpn_box_reg': 0.00796708557754755}
  Batch [420/1526] Loss: 0.4212 Components: {'loss_classifier': 0.06988764554262161, 'loss_box_reg': 0.0034520598128437996, 'loss_mask': 0.002968579763546586, 'loss_objectness': 0.25286856293678284, 'loss_rpn_box_reg': 0.09204357862472534}
  Batch [720/1526] Loss: 0.7488 Components: {'loss_classifier': 0.36564168334007263, 'loss_box_reg': 0.16967493295669556, 'loss_mask': 0.0866510421037674, 'loss_objectness': 0.11336278915405273, 'loss_rpn_box_reg': 0.013448638841509819}
  Batch [760/1526] Loss: 0.4702 Components: {'loss_classifier': 0.22318346798419952, 'loss_box_reg': 0.10244011133909225, 'loss_mask': 0.0002468976017553359, 'loss_objectness': 0.11471513658761978, 'loss_rpn_box_reg': 0.029582936316728592}
  Batch [1050/1526] Loss: 0.2966 Components: {'loss_classifier': 0.08953843265771866, 'loss_box_reg': 0.03170686960220337, 'loss_mask': 0.02205945923924446, 'loss_objectness': 0.1290072202682495, 'loss_rpn_box_reg': 0.02424415573477745}
  Batch [1080/1526] Loss: 12.2760 Components: {'loss_classifier': 0.24113158881664276, 'loss_box_reg': 0.05591381713747978, 'loss_mask': 0.036751601845026016, 'loss_objectness': 0.8409481048583984, 'loss_rpn_box_reg': 11.10126781463623}
  Batch [1130/1526] Loss: 0.3805 Components: {'loss_classifier': 0.06050446256995201, 'loss_box_reg': 0.03561270982027054, 'loss_mask': 0.15203244984149933, 'loss_objectness': 0.12449976801872253, 'loss_rpn_box_reg': 0.007888680323958397}
  Batch [1140/1526] Loss: 0.3001 Components: {'loss_classifier': 0.09548360109329224, 'loss_box_reg': 0.027695240452885628, 'loss_mask': 0.012350260280072689, 'loss_objectness': 0.14585162699222565, 'loss_rpn_box_reg': 0.01873137801885605}
  Batch [1260/1526] Loss: 17.5702 Components: {'loss_classifier': 0.18455572426319122, 'loss_box_reg': 0.1401396095752716, 'loss_mask': 0.10650886595249176, 'loss_objectness': 1.3331636190414429, 'loss_rpn_box_reg': 15.805842399597168}
  Batch [1270/1526] Loss: 16.7259 Components: {'loss_classifier': 0.11137835681438446, 'loss_box_reg': 0.03591480478644371, 'loss_mask': 0.005026439670473337, 'loss_objectness': 1.1668511629104614, 'loss_rpn_box_reg': 15.406765937805176}
  Batch [1310/1526] Loss: 1.0650 Components: {'loss_classifier': 0.18903304636478424, 'loss_box_reg': 0.06620047241449356, 'loss_mask': 0.4951328635215759, 'loss_objectness': 0.2586912214756012, 'loss_rpn_box_reg': 0.05593205988407135}
  Batch [1360/1526] Loss: 0.7000 Components: {'loss_classifier': 0.10404860973358154, 'loss_box_reg': 0.04351513460278511, 'loss_mask': 0.004988138098269701, 'loss_objectness': 0.24794527888298035, 'loss_rpn_box_reg': 0.2995184659957886}
  Batch [1370/1526] Loss: 0.8375 Components: {'loss_classifier': 0.2997191250324249, 'loss_box_reg': 0.1461896151304245, 'loss_mask': 0.0025435681454837322, 'loss_objectness': 0.21137483417987823, 'loss_rpn_box_reg': 0.1776943802833557}
  Batch [1400/1526] Loss: 0.9553 Components: {'loss_classifier': 0.2163964807987213, 'loss_box_reg': 0.055930882692337036, 'loss_mask': 0.00032017045305110514, 'loss_objectness': 0.3481038808822632, 'loss_rpn_box_reg': 0.33455097675323486}
  Batch [1440/1526] Loss: 1.4921 Components: {'loss_classifier': 0.200508251786232, 'loss_box_reg': 0.08392747491598129, 'loss_mask': 0.23919238150119781, 'loss_objectness': 0.4224499464035034, 'loss_rpn_box_reg': 0.5459948182106018}
  Batch [1510/1526] Loss: 0.5271 Components: {'loss_classifier': 0.19948583841323853, 'loss_box_reg': 0.09315900504589081, 'loss_mask': 0.13852451741695404, 'loss_objectness': 0.08375234156847, 'loss_rpn_box_reg': 0.0122178690508008}

Epoch 8 Summary:
  Train Loss: 1.4050
  Val Loss: 1.3596
  Learning Rate: 0.002000
  Epoch Time: 2649.3s
  EarlyStopping counter: 2 out of 15

Epoch 9/100
----------------------------------------
  Batch [20/1526] Loss: 0.6536 Components: {'loss_classifier': 0.284192830324173, 'loss_box_reg': 0.1322845071554184, 'loss_mask': 0.1281002312898636, 'loss_objectness': 0.09318523854017258, 'loss_rpn_box_reg': 0.015872253105044365}
  Batch [30/1526] Loss: 0.7987 Components: {'loss_classifier': 0.14302101731300354, 'loss_box_reg': 0.0673549473285675, 'loss_mask': 0.2998568117618561, 'loss_objectness': 0.24245889484882355, 'loss_rpn_box_reg': 0.0460449680685997}
  Batch [70/1526] Loss: 11.9580 Components: {'loss_classifier': 0.0905103012919426, 'loss_box_reg': 0.01750655099749565, 'loss_mask': 0.04767763614654541, 'loss_objectness': 0.509725034236908, 'loss_rpn_box_reg': 11.292606353759766}
  Batch [110/1526] Loss: 0.2951 Components: {'loss_classifier': 0.10145305097103119, 'loss_box_reg': 0.039525195956230164, 'loss_mask': 0.022157402709126472, 'loss_objectness': 0.09603098034858704, 'loss_rpn_box_reg': 0.03594440966844559}
  Batch [130/1526] Loss: 0.5528 Components: {'loss_classifier': 0.07538776844739914, 'loss_box_reg': 0.017836790531873703, 'loss_mask': 0.30147963762283325, 'loss_objectness': 0.12506411969661713, 'loss_rpn_box_reg': 0.03301340714097023}
  Batch [200/1526] Loss: 0.3973 Components: {'loss_classifier': 0.10783510655164719, 'loss_box_reg': 0.05152463912963867, 'loss_mask': 0.06121122092008591, 'loss_objectness': 0.15859003365039825, 'loss_rpn_box_reg': 0.01813722960650921}
  Batch [250/1526] Loss: 0.6279 Components: {'loss_classifier': 0.10815141350030899, 'loss_box_reg': 0.018003199249505997, 'loss_mask': 0.00265627377666533, 'loss_objectness': 0.24971835315227509, 'loss_rpn_box_reg': 0.24936600029468536}
  Batch [260/1526] Loss: 0.8432 Components: {'loss_classifier': 0.11953938007354736, 'loss_box_reg': 0.03714022785425186, 'loss_mask': 0.224636971950531, 'loss_objectness': 0.15786144137382507, 'loss_rpn_box_reg': 0.304015576839447}
  Batch [290/1526] Loss: 0.3901 Components: {'loss_classifier': 0.06685377657413483, 'loss_box_reg': 0.022051293402910233, 'loss_mask': 0.1610180139541626, 'loss_objectness': 0.09674197435379028, 'loss_rpn_box_reg': 0.043427105993032455}
  Batch [360/1526] Loss: 0.1523 Components: {'loss_classifier': 0.04980238899588585, 'loss_box_reg': 0.009098044596612453, 'loss_mask': 0.007838597521185875, 'loss_objectness': 0.08172573894262314, 'loss_rpn_box_reg': 0.0038070769514888525}
  Batch [400/1526] Loss: 0.5893 Components: {'loss_classifier': 0.16181527078151703, 'loss_box_reg': 0.1245773583650589, 'loss_mask': 0.07214329391717911, 'loss_objectness': 0.21301285922527313, 'loss_rpn_box_reg': 0.017715975642204285}
  Batch [480/1526] Loss: 0.7354 Components: {'loss_classifier': 0.2440757304430008, 'loss_box_reg': 0.09691759198904037, 'loss_mask': 0.026013074442744255, 'loss_objectness': 0.13235221803188324, 'loss_rpn_box_reg': 0.23602010309696198}
  Batch [680/1526] Loss: 0.1501 Components: {'loss_classifier': 0.03521738201379776, 'loss_box_reg': 0.0005295793525874615, 'loss_mask': 0.0017551465425640345, 'loss_objectness': 0.10256021469831467, 'loss_rpn_box_reg': 0.010007727891206741}
  Batch [830/1526] Loss: 0.2666 Components: {'loss_classifier': 0.06106696277856827, 'loss_box_reg': 0.010953819379210472, 'loss_mask': 0.10337400436401367, 'loss_objectness': 0.08026759326457977, 'loss_rpn_box_reg': 0.010980270802974701}
  Batch [860/1526] Loss: 1.0968 Components: {'loss_classifier': 0.1549815982580185, 'loss_box_reg': 0.13249936699867249, 'loss_mask': 0.322826623916626, 'loss_objectness': 0.16039475798606873, 'loss_rpn_box_reg': 0.3261130452156067}
  Batch [870/1526] Loss: 0.3325 Components: {'loss_classifier': 0.1023482084274292, 'loss_box_reg': 0.032534051686525345, 'loss_mask': 0.07647494971752167, 'loss_objectness': 0.10669156163930893, 'loss_rpn_box_reg': 0.014489555731415749}
  Batch [900/1526] Loss: 0.8352 Components: {'loss_classifier': 0.09528331458568573, 'loss_box_reg': 0.050908301025629044, 'loss_mask': 0.069613017141819, 'loss_objectness': 0.07701244950294495, 'loss_rpn_box_reg': 0.5423483848571777}
  Batch [950/1526] Loss: 0.3445 Components: {'loss_classifier': 0.1747284084558487, 'loss_box_reg': 0.08969497680664062, 'loss_mask': 0.0007385284407064319, 'loss_objectness': 0.07085929811000824, 'loss_rpn_box_reg': 0.008443371392786503}
  Batch [960/1526] Loss: 0.4454 Components: {'loss_classifier': 0.11290008574724197, 'loss_box_reg': 0.037234481424093246, 'loss_mask': 0.049522195011377335, 'loss_objectness': 0.18429355323314667, 'loss_rpn_box_reg': 0.061402179300785065}
  Batch [970/1526] Loss: 0.7517 Components: {'loss_classifier': 0.25859731435775757, 'loss_box_reg': 0.22535598278045654, 'loss_mask': 0.0035091559402644634, 'loss_objectness': 0.14700652658939362, 'loss_rpn_box_reg': 0.11720700562000275}
  Batch [990/1526] Loss: 1.0433 Components: {'loss_classifier': 0.12437312304973602, 'loss_box_reg': 0.11413849890232086, 'loss_mask': 0.42671632766723633, 'loss_objectness': 0.06930406391620636, 'loss_rpn_box_reg': 0.30872592329978943}
  Batch [1010/1526] Loss: 0.4268 Components: {'loss_classifier': 0.07457278668880463, 'loss_box_reg': 0.0013650537002831697, 'loss_mask': 0.01821937784552574, 'loss_objectness': 0.2432759404182434, 'loss_rpn_box_reg': 0.08934784680604935}
  Batch [1030/1526] Loss: 0.3743 Components: {'loss_classifier': 0.06620530784130096, 'loss_box_reg': 0.015297171659767628, 'loss_mask': 7.999597437446937e-05, 'loss_objectness': 0.12531597912311554, 'loss_rpn_box_reg': 0.16741536557674408}
  Batch [1060/1526] Loss: 0.4691 Components: {'loss_classifier': 0.1403958797454834, 'loss_box_reg': 0.07138378918170929, 'loss_mask': 0.0013104256941005588, 'loss_objectness': 0.14848491549491882, 'loss_rpn_box_reg': 0.10756771266460419}
  Batch [1080/1526] Loss: 0.8865 Components: {'loss_classifier': 0.1775117963552475, 'loss_box_reg': 0.10900861769914627, 'loss_mask': 0.3169878125190735, 'loss_objectness': 0.1302928626537323, 'loss_rpn_box_reg': 0.1527170091867447}
  Batch [1090/1526] Loss: 0.4826 Components: {'loss_classifier': 0.09610743820667267, 'loss_box_reg': 0.09442116320133209, 'loss_mask': 0.24959371984004974, 'loss_objectness': 0.039076805114746094, 'loss_rpn_box_reg': 0.003415078856050968}
  Batch [1140/1526] Loss: 0.9352 Components: {'loss_classifier': 0.27041497826576233, 'loss_box_reg': 0.12547069787979126, 'loss_mask': 0.0004584451671689749, 'loss_objectness': 0.2367875576019287, 'loss_rpn_box_reg': 0.3021164536476135}
  Batch [1320/1526] Loss: 0.5277 Components: {'loss_classifier': 0.10510390996932983, 'loss_box_reg': 0.043338842689991, 'loss_mask': 0.24353332817554474, 'loss_objectness': 0.10078724473714828, 'loss_rpn_box_reg': 0.034964822232723236}
  Batch [1350/1526] Loss: 0.8943 Components: {'loss_classifier': 0.16689284145832062, 'loss_box_reg': 0.17196375131607056, 'loss_mask': 0.4084338843822479, 'loss_objectness': 0.10160212963819504, 'loss_rpn_box_reg': 0.045398302376270294}
  Batch [1380/1526] Loss: 0.9395 Components: {'loss_classifier': 0.21642178297042847, 'loss_box_reg': 0.12249195575714111, 'loss_mask': 0.5436179041862488, 'loss_objectness': 0.040665026754140854, 'loss_rpn_box_reg': 0.016289405524730682}
  Batch [1450/1526] Loss: 0.7390 Components: {'loss_classifier': 0.3007335960865021, 'loss_box_reg': 0.17540854215621948, 'loss_mask': 0.05520147457718849, 'loss_objectness': 0.14213493466377258, 'loss_rpn_box_reg': 0.06550367921590805}
  Batch [1460/1526] Loss: 0.6003 Components: {'loss_classifier': 0.20884643495082855, 'loss_box_reg': 0.09912115335464478, 'loss_mask': 0.042092014104127884, 'loss_objectness': 0.20711250603199005, 'loss_rpn_box_reg': 0.04317115992307663}
  Batch [1500/1526] Loss: 0.8076 Components: {'loss_classifier': 0.3755304515361786, 'loss_box_reg': 0.143683061003685, 'loss_mask': 0.036100540310144424, 'loss_objectness': 0.12940546870231628, 'loss_rpn_box_reg': 0.12285163253545761}
  Batch [1520/1526] Loss: 11.4946 Components: {'loss_classifier': 0.19044585525989532, 'loss_box_reg': 0.045275866985321045, 'loss_mask': 0.14679235219955444, 'loss_objectness': 0.7056552767753601, 'loss_rpn_box_reg': 10.406460762023926}

Epoch 9 Summary:
  Train Loss: 1.2011
  Val Loss: 1.5205
  Learning Rate: 0.002000
  Epoch Time: 2574.1s
  EarlyStopping counter: 3 out of 15

Epoch 10/100
----------------------------------------
  Batch [30/1526] Loss: 1.4615 Components: {'loss_classifier': 0.3096037209033966, 'loss_box_reg': 0.26063302159309387, 'loss_mask': 0.7904117107391357, 'loss_objectness': 0.0858941376209259, 'loss_rpn_box_reg': 0.01500266045331955}
  Batch [50/1526] Loss: 0.7394 Components: {'loss_classifier': 0.2946152091026306, 'loss_box_reg': 0.13572853803634644, 'loss_mask': 0.022024013102054596, 'loss_objectness': 0.144643172621727, 'loss_rpn_box_reg': 0.14233946800231934}
  Batch [100/1526] Loss: 0.6027 Components: {'loss_classifier': 0.23258398473262787, 'loss_box_reg': 0.11100874841213226, 'loss_mask': 0.11796659976243973, 'loss_objectness': 0.11147581785917282, 'loss_rpn_box_reg': 0.029644832015037537}
  Batch [110/1526] Loss: 0.5535 Components: {'loss_classifier': 0.2024916708469391, 'loss_box_reg': 0.13530640304088593, 'loss_mask': 0.08771055191755295, 'loss_objectness': 0.11309397965669632, 'loss_rpn_box_reg': 0.014886235818266869}
  Batch [200/1526] Loss: 0.3804 Components: {'loss_classifier': 0.17133300006389618, 'loss_box_reg': 0.06011662632226944, 'loss_mask': 0.0004476027679629624, 'loss_objectness': 0.1234792023897171, 'loss_rpn_box_reg': 0.025016557425260544}
  Batch [240/1526] Loss: 0.6207 Components: {'loss_classifier': 0.1534227877855301, 'loss_box_reg': 0.0487000048160553, 'loss_mask': 0.0019419477321207523, 'loss_objectness': 0.25288817286491394, 'loss_rpn_box_reg': 0.1637178510427475}
  Batch [250/1526] Loss: 0.5131 Components: {'loss_classifier': 0.14099256694316864, 'loss_box_reg': 0.06660500168800354, 'loss_mask': 0.17978990077972412, 'loss_objectness': 0.11104697734117508, 'loss_rpn_box_reg': 0.014699121937155724}
  Batch [360/1526] Loss: 0.2512 Components: {'loss_classifier': 0.11021700501441956, 'loss_box_reg': 0.0647861436009407, 'loss_mask': 0.022403467446565628, 'loss_objectness': 0.048469480127096176, 'loss_rpn_box_reg': 0.0052781058475375175}
  Batch [380/1526] Loss: 0.4804 Components: {'loss_classifier': 0.2539839446544647, 'loss_box_reg': 0.1286877989768982, 'loss_mask': 0.00019769264326896518, 'loss_objectness': 0.08876847475767136, 'loss_rpn_box_reg': 0.008724738843739033}
  Batch [400/1526] Loss: 0.2388 Components: {'loss_classifier': 0.10461984574794769, 'loss_box_reg': 0.03629773482680321, 'loss_mask': 0.03143959119915962, 'loss_objectness': 0.05993742495775223, 'loss_rpn_box_reg': 0.0064794630743563175}
  Batch [570/1526] Loss: 0.7090 Components: {'loss_classifier': 0.3122979998588562, 'loss_box_reg': 0.11713125556707382, 'loss_mask': 0.0011428396683186293, 'loss_objectness': 0.19027696549892426, 'loss_rpn_box_reg': 0.0881085991859436}
  Batch [580/1526] Loss: 0.3284 Components: {'loss_classifier': 0.09852663427591324, 'loss_box_reg': 0.03460327535867691, 'loss_mask': 0.01847206801176071, 'loss_objectness': 0.14757245779037476, 'loss_rpn_box_reg': 0.029229149222373962}
  Batch [590/1526] Loss: 0.4520 Components: {'loss_classifier': 0.1410796195268631, 'loss_box_reg': 0.03813726454973221, 'loss_mask': 0.0018049547215923667, 'loss_objectness': 0.14566053450107574, 'loss_rpn_box_reg': 0.12530869245529175}
  Batch [620/1526] Loss: 0.6849 Components: {'loss_classifier': 0.17706848680973053, 'loss_box_reg': 0.11169536411762238, 'loss_mask': 0.025168202817440033, 'loss_objectness': 0.20808854699134827, 'loss_rpn_box_reg': 0.1628742814064026}
  Batch [650/1526] Loss: 0.3683 Components: {'loss_classifier': 0.1569567322731018, 'loss_box_reg': 0.08857981860637665, 'loss_mask': 0.06745781004428864, 'loss_objectness': 0.04724668711423874, 'loss_rpn_box_reg': 0.008067747578024864}
  Batch [810/1526] Loss: 1.3437 Components: {'loss_classifier': 0.42590853571891785, 'loss_box_reg': 0.28703251481056213, 'loss_mask': 0.25887933373451233, 'loss_objectness': 0.2818622589111328, 'loss_rpn_box_reg': 0.09006264805793762}
  Batch [820/1526] Loss: 1.2979 Components: {'loss_classifier': 0.4627874195575714, 'loss_box_reg': 0.2529744803905487, 'loss_mask': 0.04237459599971771, 'loss_objectness': 0.37999963760375977, 'loss_rpn_box_reg': 0.15980182588100433}
  Batch [840/1526] Loss: 6.7269 Components: {'loss_classifier': 0.14069800078868866, 'loss_box_reg': 0.02866019494831562, 'loss_mask': 0.07742325961589813, 'loss_objectness': 0.8133373260498047, 'loss_rpn_box_reg': 5.666799068450928}
  Batch [890/1526] Loss: 1.1281 Components: {'loss_classifier': 0.24928483366966248, 'loss_box_reg': 0.12280895560979843, 'loss_mask': 0.11532216519117355, 'loss_objectness': 0.2983973026275635, 'loss_rpn_box_reg': 0.3422923684120178}
  Batch [920/1526] Loss: 0.6304 Components: {'loss_classifier': 0.1550026535987854, 'loss_box_reg': 0.05004546418786049, 'loss_mask': 0.21329759061336517, 'loss_objectness': 0.17127063870429993, 'loss_rpn_box_reg': 0.04080342501401901}
  Batch [940/1526] Loss: 0.4170 Components: {'loss_classifier': 0.09558044373989105, 'loss_box_reg': 0.06273043155670166, 'loss_mask': 0.13492567837238312, 'loss_objectness': 0.0974072515964508, 'loss_rpn_box_reg': 0.02631077542901039}
  Batch [960/1526] Loss: 0.4161 Components: {'loss_classifier': 0.12208380550146103, 'loss_box_reg': 0.05147992819547653, 'loss_mask': 0.14978517591953278, 'loss_objectness': 0.07311105728149414, 'loss_rpn_box_reg': 0.019665056839585304}
  Batch [1070/1526] Loss: 15.7915 Components: {'loss_classifier': 0.05210232734680176, 'loss_box_reg': 0.0033931704238057137, 'loss_mask': 0.059951018542051315, 'loss_objectness': 1.5618029832839966, 'loss_rpn_box_reg': 14.114227294921875}
  Batch [1140/1526] Loss: 0.8765 Components: {'loss_classifier': 0.35706332325935364, 'loss_box_reg': 0.1646779626607895, 'loss_mask': 0.0021949170622974634, 'loss_objectness': 0.22152121365070343, 'loss_rpn_box_reg': 0.13103936612606049}
  Batch [1190/1526] Loss: 0.5775 Components: {'loss_classifier': 0.2505055069923401, 'loss_box_reg': 0.13211704790592194, 'loss_mask': 0.03539683669805527, 'loss_objectness': 0.14497922360897064, 'loss_rpn_box_reg': 0.014476223848760128}
  Batch [1210/1526] Loss: 0.3287 Components: {'loss_classifier': 0.15415890514850616, 'loss_box_reg': 0.054101262241601944, 'loss_mask': 0.005966171622276306, 'loss_objectness': 0.10188725590705872, 'loss_rpn_box_reg': 0.012538386508822441}
  Batch [1240/1526] Loss: 0.3922 Components: {'loss_classifier': 0.15877197682857513, 'loss_box_reg': 0.0748310387134552, 'loss_mask': 0.05698328837752342, 'loss_objectness': 0.09315042197704315, 'loss_rpn_box_reg': 0.00843261182308197}
  Batch [1250/1526] Loss: 0.2774 Components: {'loss_classifier': 0.07089611887931824, 'loss_box_reg': 0.028924310579895973, 'loss_mask': 0.001555677386932075, 'loss_objectness': 0.1518779695034027, 'loss_rpn_box_reg': 0.024151818826794624}
  Batch [1290/1526] Loss: 0.1525 Components: {'loss_classifier': 0.04903952777385712, 'loss_box_reg': 0.004438119009137154, 'loss_mask': 0.0014191294321790338, 'loss_objectness': 0.08306878805160522, 'loss_rpn_box_reg': 0.014501111581921577}
  Batch [1320/1526] Loss: 0.6494 Components: {'loss_classifier': 0.061180971562862396, 'loss_box_reg': 0.022572005167603493, 'loss_mask': 0.29207539558410645, 'loss_objectness': 0.17142914235591888, 'loss_rpn_box_reg': 0.10212147235870361}
  Batch [1400/1526] Loss: 0.6415 Components: {'loss_classifier': 0.21996358036994934, 'loss_box_reg': 0.053231943398714066, 'loss_mask': 0.002858333755284548, 'loss_objectness': 0.1877346932888031, 'loss_rpn_box_reg': 0.17772988975048065}
  Batch [1430/1526] Loss: 0.3514 Components: {'loss_classifier': 0.10647331178188324, 'loss_box_reg': 0.04973738640546799, 'loss_mask': 0.05841683968901634, 'loss_objectness': 0.11621097475290298, 'loss_rpn_box_reg': 0.02053532563149929}

Epoch 10 Summary:
  Train Loss: 1.1287
  Val Loss: 1.3871
  Learning Rate: 0.002000
  Epoch Time: 2745.8s
  EarlyStopping counter: 4 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 11/100
----------------------------------------
  Batch [40/1526] Loss: 0.7147 Components: {'loss_classifier': 0.21969768404960632, 'loss_box_reg': 0.16360574960708618, 'loss_mask': 0.2403426617383957, 'loss_objectness': 0.0774703249335289, 'loss_rpn_box_reg': 0.013534260913729668}
  Batch [90/1526] Loss: 0.8787 Components: {'loss_classifier': 0.27049657702445984, 'loss_box_reg': 0.2497727870941162, 'loss_mask': 0.01082015410065651, 'loss_objectness': 0.22347116470336914, 'loss_rpn_box_reg': 0.12411925196647644}
  Batch [130/1526] Loss: 1.3250 Components: {'loss_classifier': 0.3898650109767914, 'loss_box_reg': 0.16754043102264404, 'loss_mask': 0.05686487630009651, 'loss_objectness': 0.2587267756462097, 'loss_rpn_box_reg': 0.45201197266578674}
  Batch [180/1526] Loss: 0.7297 Components: {'loss_classifier': 0.34664902091026306, 'loss_box_reg': 0.12951990962028503, 'loss_mask': 0.005140414461493492, 'loss_objectness': 0.19247953593730927, 'loss_rpn_box_reg': 0.05586744844913483}
  Batch [190/1526] Loss: 0.5472 Components: {'loss_classifier': 0.11814069747924805, 'loss_box_reg': 0.055773403495550156, 'loss_mask': 0.10518952459096909, 'loss_objectness': 0.21691501140594482, 'loss_rpn_box_reg': 0.05114181712269783}
  Batch [260/1526] Loss: 0.5968 Components: {'loss_classifier': 0.15900473296642303, 'loss_box_reg': 0.11944864690303802, 'loss_mask': 0.2354981005191803, 'loss_objectness': 0.06951414048671722, 'loss_rpn_box_reg': 0.013321638107299805}
  Batch [270/1526] Loss: 0.8249 Components: {'loss_classifier': 0.16826993227005005, 'loss_box_reg': 0.11341763287782669, 'loss_mask': 0.37505996227264404, 'loss_objectness': 0.10802304744720459, 'loss_rpn_box_reg': 0.06017822027206421}
  Batch [300/1526] Loss: 0.6111 Components: {'loss_classifier': 0.0911027044057846, 'loss_box_reg': 0.037161242216825485, 'loss_mask': 0.26437312364578247, 'loss_objectness': 0.12454285472631454, 'loss_rpn_box_reg': 0.09394428879022598}
  Batch [340/1526] Loss: 7.6744 Components: {'loss_classifier': 0.2055046558380127, 'loss_box_reg': 0.03072977624833584, 'loss_mask': 0.011838067322969437, 'loss_objectness': 1.0758252143859863, 'loss_rpn_box_reg': 6.35047721862793}
  Batch [400/1526] Loss: 0.9307 Components: {'loss_classifier': 0.2506103515625, 'loss_box_reg': 0.108286552131176, 'loss_mask': 0.21767574548721313, 'loss_objectness': 0.15676334500312805, 'loss_rpn_box_reg': 0.19737789034843445}
  Batch [410/1526] Loss: 0.7436 Components: {'loss_classifier': 0.21940390765666962, 'loss_box_reg': 0.15731799602508545, 'loss_mask': 0.28456830978393555, 'loss_objectness': 0.07383725792169571, 'loss_rpn_box_reg': 0.008496193215250969}
  Batch [450/1526] Loss: 0.9407 Components: {'loss_classifier': 0.20397041738033295, 'loss_box_reg': 0.05714362487196922, 'loss_mask': 0.13548991084098816, 'loss_objectness': 0.19243362545967102, 'loss_rpn_box_reg': 0.3516537845134735}
  Batch [510/1526] Loss: 0.8387 Components: {'loss_classifier': 0.16965414583683014, 'loss_box_reg': 0.07810502499341965, 'loss_mask': 0.00917405541986227, 'loss_objectness': 0.17251673340797424, 'loss_rpn_box_reg': 0.40921998023986816}
  Batch [590/1526] Loss: 0.8039 Components: {'loss_classifier': 0.2614941895008087, 'loss_box_reg': 0.09026279300451279, 'loss_mask': 0.007070587947964668, 'loss_objectness': 0.23564784228801727, 'loss_rpn_box_reg': 0.2093922197818756}
  Batch [600/1526] Loss: 11.5368 Components: {'loss_classifier': 0.20679044723510742, 'loss_box_reg': 0.1179814264178276, 'loss_mask': 0.01299586333334446, 'loss_objectness': 1.2126001119613647, 'loss_rpn_box_reg': 9.986462593078613}
  Batch [640/1526] Loss: 0.9071 Components: {'loss_classifier': 0.23566779494285583, 'loss_box_reg': 0.09674473851919174, 'loss_mask': 0.024206828325986862, 'loss_objectness': 0.2780243754386902, 'loss_rpn_box_reg': 0.272493839263916}
  Batch [700/1526] Loss: 1.6393 Components: {'loss_classifier': 0.2200441211462021, 'loss_box_reg': 0.12395641207695007, 'loss_mask': 0.25132930278778076, 'loss_objectness': 0.4952528774738312, 'loss_rpn_box_reg': 0.548764169216156}
  Batch [780/1526] Loss: 1.1386 Components: {'loss_classifier': 0.4748120605945587, 'loss_box_reg': 0.048814237117767334, 'loss_mask': 0.0012631691060960293, 'loss_objectness': 0.347863107919693, 'loss_rpn_box_reg': 0.26588723063468933}
  Batch [810/1526] Loss: 13.1586 Components: {'loss_classifier': 0.07667774707078934, 'loss_box_reg': 0.02104782685637474, 'loss_mask': 0.031110389158129692, 'loss_objectness': 1.7297204732894897, 'loss_rpn_box_reg': 11.300060272216797}
  Batch [850/1526] Loss: 0.8429 Components: {'loss_classifier': 0.09033288061618805, 'loss_box_reg': 0.01234014704823494, 'loss_mask': 0.0003887553175445646, 'loss_objectness': 0.3588351905345917, 'loss_rpn_box_reg': 0.38095512986183167}
  Batch [960/1526] Loss: 0.3161 Components: {'loss_classifier': 0.058437280356884, 'loss_box_reg': 0.020857486873865128, 'loss_mask': 0.13474194705486298, 'loss_objectness': 0.0861118882894516, 'loss_rpn_box_reg': 0.015989212319254875}
  Batch [970/1526] Loss: 0.2536 Components: {'loss_classifier': 0.10424352437257767, 'loss_box_reg': 0.06047797575592995, 'loss_mask': 0.002448527840897441, 'loss_objectness': 0.07078125327825546, 'loss_rpn_box_reg': 0.015640752390027046}
  Batch [1030/1526] Loss: 0.3279 Components: {'loss_classifier': 0.1575191617012024, 'loss_box_reg': 0.07520069181919098, 'loss_mask': 0.004271590616554022, 'loss_objectness': 0.07992570847272873, 'loss_rpn_box_reg': 0.011012153699994087}
  Batch [1070/1526] Loss: 0.5164 Components: {'loss_classifier': 0.20400908589363098, 'loss_box_reg': 0.12439689040184021, 'loss_mask': 0.0881563127040863, 'loss_objectness': 0.08758179843425751, 'loss_rpn_box_reg': 0.01221385970711708}
  Batch [1130/1526] Loss: 1.0274 Components: {'loss_classifier': 0.33326831459999084, 'loss_box_reg': 0.12022887915372849, 'loss_mask': 0.02659633941948414, 'loss_objectness': 0.20384415984153748, 'loss_rpn_box_reg': 0.3434959053993225}
  Batch [1220/1526] Loss: 0.5011 Components: {'loss_classifier': 0.16143369674682617, 'loss_box_reg': 0.10018514841794968, 'loss_mask': 0.14278191328048706, 'loss_objectness': 0.08422057330608368, 'loss_rpn_box_reg': 0.012432336807250977}
  Batch [1280/1526] Loss: 0.2649 Components: {'loss_classifier': 0.08186665177345276, 'loss_box_reg': 0.05101289227604866, 'loss_mask': 0.048731230199337006, 'loss_objectness': 0.0802762433886528, 'loss_rpn_box_reg': 0.0030335139017552137}
  Batch [1320/1526] Loss: 0.5855 Components: {'loss_classifier': 0.19383159279823303, 'loss_box_reg': 0.18117061257362366, 'loss_mask': 0.04805454984307289, 'loss_objectness': 0.12982864677906036, 'loss_rpn_box_reg': 0.03263397514820099}
  Batch [1390/1526] Loss: 0.4366 Components: {'loss_classifier': 0.16862721741199493, 'loss_box_reg': 0.09501838684082031, 'loss_mask': 0.02000654861330986, 'loss_objectness': 0.1231091320514679, 'loss_rpn_box_reg': 0.029872527346014977}
  Batch [1450/1526] Loss: 0.3997 Components: {'loss_classifier': 0.15178079903125763, 'loss_box_reg': 0.12317405641078949, 'loss_mask': 0.07998277992010117, 'loss_objectness': 0.036337535828351974, 'loss_rpn_box_reg': 0.008414189331233501}
  Batch [1520/1526] Loss: 0.2006 Components: {'loss_classifier': 0.07981041818857193, 'loss_box_reg': 0.015406428836286068, 'loss_mask': 0.0051677655428647995, 'loss_objectness': 0.08739100396633148, 'loss_rpn_box_reg': 0.012786226347088814}

Epoch 11 Summary:
  Train Loss: 1.2725
  Val Loss: 1.4086
  Learning Rate: 0.002000
  Epoch Time: 2518.7s
  EarlyStopping counter: 5 out of 15

Epoch 12/100
----------------------------------------
  Batch [20/1526] Loss: 0.4289 Components: {'loss_classifier': 0.12801556289196014, 'loss_box_reg': 0.0767972469329834, 'loss_mask': 0.11051809042692184, 'loss_objectness': 0.10459680110216141, 'loss_rpn_box_reg': 0.009017611853778362}
  Batch [60/1526] Loss: 0.8250 Components: {'loss_classifier': 0.2016330361366272, 'loss_box_reg': 0.09433262050151825, 'loss_mask': 0.0019563306123018265, 'loss_objectness': 0.2322346568107605, 'loss_rpn_box_reg': 0.29483088850975037}
  Batch [130/1526] Loss: 0.8134 Components: {'loss_classifier': 0.11415435373783112, 'loss_box_reg': 0.07767946273088455, 'loss_mask': 0.48967570066452026, 'loss_objectness': 0.08972284197807312, 'loss_rpn_box_reg': 0.042215920984745026}
  Batch [310/1526] Loss: 0.5149 Components: {'loss_classifier': 0.14616428315639496, 'loss_box_reg': 0.08687189966440201, 'loss_mask': 0.09253868460655212, 'loss_objectness': 0.16334843635559082, 'loss_rpn_box_reg': 0.025939222425222397}
  Batch [500/1526] Loss: 7.0690 Components: {'loss_classifier': 0.09845542907714844, 'loss_box_reg': 0.001197037287056446, 'loss_mask': 0.01492168940603733, 'loss_objectness': 1.0168486833572388, 'loss_rpn_box_reg': 5.9375386238098145}
  Batch [530/1526] Loss: 0.9142 Components: {'loss_classifier': 0.2226826548576355, 'loss_box_reg': 0.0585789680480957, 'loss_mask': 0.04243597760796547, 'loss_objectness': 0.2119848132133484, 'loss_rpn_box_reg': 0.37847697734832764}
  Batch [650/1526] Loss: 0.6543 Components: {'loss_classifier': 0.21351312100887299, 'loss_box_reg': 0.08090422302484512, 'loss_mask': 0.0014058289816603065, 'loss_objectness': 0.16453073918819427, 'loss_rpn_box_reg': 0.19399498403072357}
  Batch [660/1526] Loss: 0.9421 Components: {'loss_classifier': 0.2870044708251953, 'loss_box_reg': 0.05469883605837822, 'loss_mask': 0.0007455201121047139, 'loss_objectness': 0.33030563592910767, 'loss_rpn_box_reg': 0.26939406991004944}
  Batch [730/1526] Loss: 0.7835 Components: {'loss_classifier': 0.11028046905994415, 'loss_box_reg': 0.03639049082994461, 'loss_mask': 0.008416315540671349, 'loss_objectness': 0.10989993810653687, 'loss_rpn_box_reg': 0.5184786319732666}
  Batch [740/1526] Loss: 0.5742 Components: {'loss_classifier': 0.16570423543453217, 'loss_box_reg': 0.03915306180715561, 'loss_mask': 0.002301349537447095, 'loss_objectness': 0.2238295078277588, 'loss_rpn_box_reg': 0.14324936270713806}
  Batch [930/1526] Loss: 0.5581 Components: {'loss_classifier': 0.23441441357135773, 'loss_box_reg': 0.11453771591186523, 'loss_mask': 0.007623939774930477, 'loss_objectness': 0.15580210089683533, 'loss_rpn_box_reg': 0.04569534212350845}
  Batch [960/1526] Loss: 0.8277 Components: {'loss_classifier': 0.26021191477775574, 'loss_box_reg': 0.15125276148319244, 'loss_mask': 0.13728198409080505, 'loss_objectness': 0.1267615556716919, 'loss_rpn_box_reg': 0.15219922363758087}
  Batch [1010/1526] Loss: 0.6764 Components: {'loss_classifier': 0.1178012415766716, 'loss_box_reg': 0.0647406280040741, 'loss_mask': 0.25566428899765015, 'loss_objectness': 0.20730555057525635, 'loss_rpn_box_reg': 0.03092346154153347}
  Batch [1050/1526] Loss: 0.3769 Components: {'loss_classifier': 0.13447321951389313, 'loss_box_reg': 0.0852980762720108, 'loss_mask': 0.06940395385026932, 'loss_objectness': 0.0725678950548172, 'loss_rpn_box_reg': 0.01518198661506176}
  Batch [1080/1526] Loss: 0.9812 Components: {'loss_classifier': 0.36721083521842957, 'loss_box_reg': 0.3727302551269531, 'loss_mask': 0.04710559919476509, 'loss_objectness': 0.09549238532781601, 'loss_rpn_box_reg': 0.09865181893110275}
  Batch [1090/1526] Loss: 0.5187 Components: {'loss_classifier': 0.19879671931266785, 'loss_box_reg': 0.07224973291158676, 'loss_mask': 0.009371357969939709, 'loss_objectness': 0.15396682918071747, 'loss_rpn_box_reg': 0.08433715254068375}
  Batch [1140/1526] Loss: 0.7330 Components: {'loss_classifier': 0.15353363752365112, 'loss_box_reg': 0.09868878126144409, 'loss_mask': 0.23175635933876038, 'loss_objectness': 0.18315446376800537, 'loss_rpn_box_reg': 0.06588361412286758}
  Batch [1160/1526] Loss: 1.0203 Components: {'loss_classifier': 0.34702861309051514, 'loss_box_reg': 0.1600819081068039, 'loss_mask': 0.13970080018043518, 'loss_objectness': 0.25710564851760864, 'loss_rpn_box_reg': 0.11641502380371094}
  Batch [1240/1526] Loss: 0.6736 Components: {'loss_classifier': 0.22313928604125977, 'loss_box_reg': 0.05212491750717163, 'loss_mask': 0.0009482079185545444, 'loss_objectness': 0.19218681752681732, 'loss_rpn_box_reg': 0.20519109070301056}
  Batch [1360/1526] Loss: 0.4248 Components: {'loss_classifier': 0.06057068333029747, 'loss_box_reg': 0.004961332771927118, 'loss_mask': 0.0008732176502235234, 'loss_objectness': 0.2215513288974762, 'loss_rpn_box_reg': 0.1368325650691986}
  Batch [1470/1526] Loss: 0.4134 Components: {'loss_classifier': 0.0849585011601448, 'loss_box_reg': 0.026038751006126404, 'loss_mask': 0.004205435048788786, 'loss_objectness': 0.17725764214992523, 'loss_rpn_box_reg': 0.12089407444000244}

Epoch 12 Summary:
  Train Loss: 1.1296
  Val Loss: 1.3696
  Learning Rate: 0.002000
  Epoch Time: 2567.8s
  EarlyStopping counter: 6 out of 15

Epoch 13/100
----------------------------------------
  Batch [10/1526] Loss: 1.0325 Components: {'loss_classifier': 0.4735989570617676, 'loss_box_reg': 0.38023844361305237, 'loss_mask': 0.00047526368871331215, 'loss_objectness': 0.09804943948984146, 'loss_rpn_box_reg': 0.08016014844179153}
  Batch [50/1526] Loss: 0.5907 Components: {'loss_classifier': 0.21352654695510864, 'loss_box_reg': 0.10580809414386749, 'loss_mask': 0.06131184473633766, 'loss_objectness': 0.15924125909805298, 'loss_rpn_box_reg': 0.05080666020512581}
  Batch [80/1526] Loss: 0.4346 Components: {'loss_classifier': 0.17891955375671387, 'loss_box_reg': 0.07713416963815689, 'loss_mask': 0.012450006790459156, 'loss_objectness': 0.10954321920871735, 'loss_rpn_box_reg': 0.056534767150878906}
  Batch [140/1526] Loss: 0.3099 Components: {'loss_classifier': 0.12749668955802917, 'loss_box_reg': 0.05260346457362175, 'loss_mask': 0.00013141830277163535, 'loss_objectness': 0.08111687004566193, 'loss_rpn_box_reg': 0.048541609197854996}
  Batch [200/1526] Loss: 0.3959 Components: {'loss_classifier': 0.14096052944660187, 'loss_box_reg': 0.09878242760896683, 'loss_mask': 0.08125974982976913, 'loss_objectness': 0.06936424225568771, 'loss_rpn_box_reg': 0.00553252873942256}
  Batch [230/1526] Loss: 0.9097 Components: {'loss_classifier': 0.3838472068309784, 'loss_box_reg': 0.059610515832901, 'loss_mask': 0.0010615484789013863, 'loss_objectness': 0.21448960900306702, 'loss_rpn_box_reg': 0.25065481662750244}
  Batch [270/1526] Loss: 0.8922 Components: {'loss_classifier': 0.2783616781234741, 'loss_box_reg': 0.13006086647510529, 'loss_mask': 0.06316544115543365, 'loss_objectness': 0.14476126432418823, 'loss_rpn_box_reg': 0.27581149339675903}
  Batch [290/1526] Loss: 0.4732 Components: {'loss_classifier': 0.20264726877212524, 'loss_box_reg': 0.08077135682106018, 'loss_mask': 0.00864870473742485, 'loss_objectness': 0.14838266372680664, 'loss_rpn_box_reg': 0.03276310861110687}
  Batch [340/1526] Loss: 0.7484 Components: {'loss_classifier': 0.25910231471061707, 'loss_box_reg': 0.17911428213119507, 'loss_mask': 0.23166385293006897, 'loss_objectness': 0.06212248653173447, 'loss_rpn_box_reg': 0.01637132838368416}
  Batch [390/1526] Loss: 0.5751 Components: {'loss_classifier': 0.1592986285686493, 'loss_box_reg': 0.11519043892621994, 'loss_mask': 0.17254364490509033, 'loss_objectness': 0.11532911658287048, 'loss_rpn_box_reg': 0.012712182477116585}
  Batch [430/1526] Loss: 0.4723 Components: {'loss_classifier': 0.2133581042289734, 'loss_box_reg': 0.12202055752277374, 'loss_mask': 0.0003095789288636297, 'loss_objectness': 0.12357001006603241, 'loss_rpn_box_reg': 0.013020826503634453}
  Batch [460/1526] Loss: 0.8458 Components: {'loss_classifier': 0.2739432752132416, 'loss_box_reg': 0.20173214375972748, 'loss_mask': 0.0012003465089946985, 'loss_objectness': 0.10002834349870682, 'loss_rpn_box_reg': 0.2688717842102051}
  Batch [560/1526] Loss: 0.9604 Components: {'loss_classifier': 0.13745729625225067, 'loss_box_reg': 0.03527434170246124, 'loss_mask': 0.005733673460781574, 'loss_objectness': 0.33024832606315613, 'loss_rpn_box_reg': 0.45165807008743286}
  Batch [600/1526] Loss: 0.7871 Components: {'loss_classifier': 0.2630701959133148, 'loss_box_reg': 0.30003949999809265, 'loss_mask': 0.054307978600263596, 'loss_objectness': 0.14171963930130005, 'loss_rpn_box_reg': 0.02796018123626709}
  Batch [640/1526] Loss: 0.9469 Components: {'loss_classifier': 0.3330119550228119, 'loss_box_reg': 0.2490490972995758, 'loss_mask': 0.14029499888420105, 'loss_objectness': 0.1681065410375595, 'loss_rpn_box_reg': 0.05640251934528351}
  Batch [740/1526] Loss: 0.7823 Components: {'loss_classifier': 0.22877027094364166, 'loss_box_reg': 0.060387469828128815, 'loss_mask': 0.12903103232383728, 'loss_objectness': 0.18253633379936218, 'loss_rpn_box_reg': 0.18158897757530212}
  Batch [750/1526] Loss: 1.0400 Components: {'loss_classifier': 0.3065350353717804, 'loss_box_reg': 0.16904081404209137, 'loss_mask': 0.033294785767793655, 'loss_objectness': 0.15358999371528625, 'loss_rpn_box_reg': 0.37750503420829773}
  Batch [760/1526] Loss: 0.1469 Components: {'loss_classifier': 0.04760322719812393, 'loss_box_reg': 0.008298740722239017, 'loss_mask': 0.0068750809878110886, 'loss_objectness': 0.05530693754553795, 'loss_rpn_box_reg': 0.028805643320083618}
  Batch [850/1526] Loss: 6.4812 Components: {'loss_classifier': 0.1712413877248764, 'loss_box_reg': 0.11080551147460938, 'loss_mask': 0.03421902656555176, 'loss_objectness': 0.848675549030304, 'loss_rpn_box_reg': 5.316286087036133}
  Batch [940/1526] Loss: 0.7595 Components: {'loss_classifier': 0.3486582636833191, 'loss_box_reg': 0.2235478162765503, 'loss_mask': 0.035486992448568344, 'loss_objectness': 0.10997462272644043, 'loss_rpn_box_reg': 0.04181307926774025}
  Batch [1000/1526] Loss: 0.4757 Components: {'loss_classifier': 0.24147376418113708, 'loss_box_reg': 0.14517244696617126, 'loss_mask': 0.013135764747858047, 'loss_objectness': 0.06634095311164856, 'loss_rpn_box_reg': 0.009625965729355812}
  Batch [1050/1526] Loss: 0.3943 Components: {'loss_classifier': 0.1835048496723175, 'loss_box_reg': 0.1076899915933609, 'loss_mask': 0.0003922976611647755, 'loss_objectness': 0.0879315733909607, 'loss_rpn_box_reg': 0.014760449528694153}
  Batch [1070/1526] Loss: 0.6696 Components: {'loss_classifier': 0.2516458034515381, 'loss_box_reg': 0.2047058641910553, 'loss_mask': 0.15868684649467468, 'loss_objectness': 0.04213689640164375, 'loss_rpn_box_reg': 0.012462588027119637}
  Batch [1190/1526] Loss: 0.2559 Components: {'loss_classifier': 0.07212688773870468, 'loss_box_reg': 0.01688225008547306, 'loss_mask': 0.006058193743228912, 'loss_objectness': 0.14681026339530945, 'loss_rpn_box_reg': 0.014025629498064518}
  Batch [1220/1526] Loss: 0.4664 Components: {'loss_classifier': 0.15359412133693695, 'loss_box_reg': 0.12868353724479675, 'loss_mask': 0.117768794298172, 'loss_objectness': 0.03900759667158127, 'loss_rpn_box_reg': 0.027311081066727638}
  Batch [1260/1526] Loss: 0.3768 Components: {'loss_classifier': 0.09617534279823303, 'loss_box_reg': 0.06296028196811676, 'loss_mask': 0.07450144737958908, 'loss_objectness': 0.07872635871171951, 'loss_rpn_box_reg': 0.06446576118469238}
  Batch [1270/1526] Loss: 0.9234 Components: {'loss_classifier': 0.23800697922706604, 'loss_box_reg': 0.20031726360321045, 'loss_mask': 0.1099434494972229, 'loss_objectness': 0.17791372537612915, 'loss_rpn_box_reg': 0.19718636572360992}
  Batch [1280/1526] Loss: 0.2927 Components: {'loss_classifier': 0.1344963014125824, 'loss_box_reg': 0.08456970006227493, 'loss_mask': 0.03338471055030823, 'loss_objectness': 0.033893685787916183, 'loss_rpn_box_reg': 0.006311705335974693}

Epoch 13 Summary:
  Train Loss: 0.9985
  Val Loss: 1.3559
  Learning Rate: 0.002000
  Epoch Time: 2570.0s
  EarlyStopping counter: 7 out of 15

Epoch 14/100
----------------------------------------
  Batch [50/1526] Loss: 0.8750 Components: {'loss_classifier': 0.2810380160808563, 'loss_box_reg': 0.2924802601337433, 'loss_mask': 0.008343474939465523, 'loss_objectness': 0.1146099865436554, 'loss_rpn_box_reg': 0.17849840223789215}
  Batch [110/1526] Loss: 0.2947 Components: {'loss_classifier': 0.11421826481819153, 'loss_box_reg': 0.07419724017381668, 'loss_mask': 0.08138454705476761, 'loss_objectness': 0.016878606751561165, 'loss_rpn_box_reg': 0.008034640923142433}
  Batch [190/1526] Loss: 0.4494 Components: {'loss_classifier': 0.11517206579446793, 'loss_box_reg': 0.10078487545251846, 'loss_mask': 0.1522282361984253, 'loss_objectness': 0.05298198014497757, 'loss_rpn_box_reg': 0.028210360556840897}
  Batch [250/1526] Loss: 0.3807 Components: {'loss_classifier': 0.16018228232860565, 'loss_box_reg': 0.0853566974401474, 'loss_mask': 0.04894199222326279, 'loss_objectness': 0.05687284469604492, 'loss_rpn_box_reg': 0.029335035011172295}
  Batch [270/1526] Loss: 0.6844 Components: {'loss_classifier': 0.3425396680831909, 'loss_box_reg': 0.17977261543273926, 'loss_mask': 0.02406049706041813, 'loss_objectness': 0.10208640992641449, 'loss_rpn_box_reg': 0.03597891330718994}
  Batch [290/1526] Loss: 0.8566 Components: {'loss_classifier': 0.3802439570426941, 'loss_box_reg': 0.12157218903303146, 'loss_mask': 0.025958701968193054, 'loss_objectness': 0.2752184271812439, 'loss_rpn_box_reg': 0.05358259007334709}
  Batch [300/1526] Loss: 0.6090 Components: {'loss_classifier': 0.17745985090732574, 'loss_box_reg': 0.16452573239803314, 'loss_mask': 0.1679348349571228, 'loss_objectness': 0.08285260945558548, 'loss_rpn_box_reg': 0.01626221276819706}
  Batch [320/1526] Loss: 0.5915 Components: {'loss_classifier': 0.2062901109457016, 'loss_box_reg': 0.22823424637317657, 'loss_mask': 0.08962785452604294, 'loss_objectness': 0.05642115697264671, 'loss_rpn_box_reg': 0.010916031897068024}
  Batch [330/1526] Loss: 0.6092 Components: {'loss_classifier': 0.22814248502254486, 'loss_box_reg': 0.14245836436748505, 'loss_mask': 0.11921481043100357, 'loss_objectness': 0.09908811002969742, 'loss_rpn_box_reg': 0.02033686824142933}
  Batch [340/1526] Loss: 0.4832 Components: {'loss_classifier': 0.2040451020002365, 'loss_box_reg': 0.11233575642108917, 'loss_mask': 0.015250944532454014, 'loss_objectness': 0.13289320468902588, 'loss_rpn_box_reg': 0.018696654587984085}
  Batch [360/1526] Loss: 0.7812 Components: {'loss_classifier': 0.32822397351264954, 'loss_box_reg': 0.1321491003036499, 'loss_mask': 0.04005487263202667, 'loss_objectness': 0.18274174630641937, 'loss_rpn_box_reg': 0.09806256741285324}
  Batch [370/1526] Loss: 0.8056 Components: {'loss_classifier': 0.17539778351783752, 'loss_box_reg': 0.06390654295682907, 'loss_mask': 0.005539450328797102, 'loss_objectness': 0.19588033854961395, 'loss_rpn_box_reg': 0.3649081587791443}
  Batch [440/1526] Loss: 0.4681 Components: {'loss_classifier': 0.16350308060646057, 'loss_box_reg': 0.11332304030656815, 'loss_mask': 0.14142248034477234, 'loss_objectness': 0.0396045483648777, 'loss_rpn_box_reg': 0.010242991149425507}
  Batch [450/1526] Loss: 0.4622 Components: {'loss_classifier': 0.12163540720939636, 'loss_box_reg': 0.07272294163703918, 'loss_mask': 0.10555901378393173, 'loss_objectness': 0.13161113858222961, 'loss_rpn_box_reg': 0.030697733163833618}
  Batch [690/1526] Loss: 0.3603 Components: {'loss_classifier': 0.10633981972932816, 'loss_box_reg': 0.09737833589315414, 'loss_mask': 0.11608794331550598, 'loss_objectness': 0.03304293006658554, 'loss_rpn_box_reg': 0.007500052452087402}
  Batch [700/1526] Loss: 0.7246 Components: {'loss_classifier': 0.3036893606185913, 'loss_box_reg': 0.26375266909599304, 'loss_mask': 0.10674624890089035, 'loss_objectness': 0.043379947543144226, 'loss_rpn_box_reg': 0.007048584055155516}
  Batch [710/1526] Loss: 0.8499 Components: {'loss_classifier': 0.3717834949493408, 'loss_box_reg': 0.21520715951919556, 'loss_mask': 0.016119373962283134, 'loss_objectness': 0.14917892217636108, 'loss_rpn_box_reg': 0.09756822884082794}
  Batch [720/1526] Loss: 0.7873 Components: {'loss_classifier': 0.2182651162147522, 'loss_box_reg': 0.17223086953163147, 'loss_mask': 0.001434256904758513, 'loss_objectness': 0.13708865642547607, 'loss_rpn_box_reg': 0.2582749128341675}
  Batch [730/1526] Loss: 1.2035 Components: {'loss_classifier': 0.5745440721511841, 'loss_box_reg': 0.5009607672691345, 'loss_mask': 0.0003865393518935889, 'loss_objectness': 0.10044962167739868, 'loss_rpn_box_reg': 0.027169853448867798}
  Batch [770/1526] Loss: 0.3688 Components: {'loss_classifier': 0.12940888106822968, 'loss_box_reg': 0.06451056897640228, 'loss_mask': 0.007877550087869167, 'loss_objectness': 0.12094143033027649, 'loss_rpn_box_reg': 0.04610744118690491}
  Batch [830/1526] Loss: 0.7399 Components: {'loss_classifier': 0.2197074592113495, 'loss_box_reg': 0.28584593534469604, 'loss_mask': 0.17670470476150513, 'loss_objectness': 0.0384010411798954, 'loss_rpn_box_reg': 0.019220121204853058}
  Batch [890/1526] Loss: 1.0567 Components: {'loss_classifier': 0.3167976438999176, 'loss_box_reg': 0.17108497023582458, 'loss_mask': 0.007757476065307856, 'loss_objectness': 0.12281068414449692, 'loss_rpn_box_reg': 0.4382973313331604}
  Batch [1010/1526] Loss: 0.9133 Components: {'loss_classifier': 0.3176504969596863, 'loss_box_reg': 0.2666521966457367, 'loss_mask': 0.20991012454032898, 'loss_objectness': 0.0987456738948822, 'loss_rpn_box_reg': 0.02032334730029106}
  Batch [1050/1526] Loss: 0.3876 Components: {'loss_classifier': 0.14919352531433105, 'loss_box_reg': 0.0738200768828392, 'loss_mask': 0.003396489890292287, 'loss_objectness': 0.14848291873931885, 'loss_rpn_box_reg': 0.012675583362579346}
  Batch [1060/1526] Loss: 0.9873 Components: {'loss_classifier': 0.3350885510444641, 'loss_box_reg': 0.3028934597969055, 'loss_mask': 0.03287732973694801, 'loss_objectness': 0.27945974469184875, 'loss_rpn_box_reg': 0.03694841265678406}
  Batch [1150/1526] Loss: 1.0898 Components: {'loss_classifier': 0.3868345320224762, 'loss_box_reg': 0.3834782838821411, 'loss_mask': 0.16947489976882935, 'loss_objectness': 0.0547381266951561, 'loss_rpn_box_reg': 0.09531289339065552}
  Batch [1160/1526] Loss: 0.8278 Components: {'loss_classifier': 0.16068607568740845, 'loss_box_reg': 0.0856260284781456, 'loss_mask': 0.5475301146507263, 'loss_objectness': 0.02816741354763508, 'loss_rpn_box_reg': 0.0058350954204797745}
  Batch [1230/1526] Loss: 0.6618 Components: {'loss_classifier': 0.14746904373168945, 'loss_box_reg': 0.022217528894543648, 'loss_mask': 0.0018087063217535615, 'loss_objectness': 0.14192309975624084, 'loss_rpn_box_reg': 0.34838172793388367}
  Batch [1270/1526] Loss: 0.8954 Components: {'loss_classifier': 0.4173445701599121, 'loss_box_reg': 0.3219977021217346, 'loss_mask': 0.0009024819009937346, 'loss_objectness': 0.11787794530391693, 'loss_rpn_box_reg': 0.0372454971075058}
  Batch [1310/1526] Loss: 1.3202 Components: {'loss_classifier': 0.574208676815033, 'loss_box_reg': 0.4759613275527954, 'loss_mask': 0.0006587671232409775, 'loss_objectness': 0.15259365737438202, 'loss_rpn_box_reg': 0.11681616306304932}
  Batch [1350/1526] Loss: 0.7224 Components: {'loss_classifier': 0.2629402279853821, 'loss_box_reg': 0.10329287499189377, 'loss_mask': 0.006866041570901871, 'loss_objectness': 0.20894554257392883, 'loss_rpn_box_reg': 0.14035272598266602}
  Batch [1490/1526] Loss: 0.8177 Components: {'loss_classifier': 0.16052380204200745, 'loss_box_reg': 0.12094771862030029, 'loss_mask': 0.30865272879600525, 'loss_objectness': 0.19711369276046753, 'loss_rpn_box_reg': 0.0304282084107399}
  Batch [1510/1526] Loss: 0.8393 Components: {'loss_classifier': 0.3690072000026703, 'loss_box_reg': 0.26663535833358765, 'loss_mask': 0.0058549270033836365, 'loss_objectness': 0.16643087565898895, 'loss_rpn_box_reg': 0.0313866063952446}

Epoch 14 Summary:
  Train Loss: 1.3068
  Val Loss: 1.4399
  Learning Rate: 0.002000
  Epoch Time: 2708.7s
  EarlyStopping counter: 8 out of 15

Epoch 15/100
----------------------------------------
  Batch [0/1526] Loss: 0.6592 Components: {'loss_classifier': 0.24679768085479736, 'loss_box_reg': 0.05049338564276695, 'loss_mask': 0.0014192613307386637, 'loss_objectness': 0.2019183337688446, 'loss_rpn_box_reg': 0.15854987502098083}
  Batch [90/1526] Loss: 0.4159 Components: {'loss_classifier': 0.18385101854801178, 'loss_box_reg': 0.10858339816331863, 'loss_mask': 0.05163230746984482, 'loss_objectness': 0.05829470604658127, 'loss_rpn_box_reg': 0.013506397604942322}
  Batch [190/1526] Loss: 0.3273 Components: {'loss_classifier': 0.14230841398239136, 'loss_box_reg': 0.08419764041900635, 'loss_mask': 0.035413239151239395, 'loss_objectness': 0.05766143277287483, 'loss_rpn_box_reg': 0.007684888783842325}
  Batch [260/1526] Loss: 1.2724 Components: {'loss_classifier': 0.27057093381881714, 'loss_box_reg': 0.26646509766578674, 'loss_mask': 0.018602367490530014, 'loss_objectness': 0.19375067949295044, 'loss_rpn_box_reg': 0.5229955315589905}
  Batch [360/1526] Loss: 0.4352 Components: {'loss_classifier': 0.09046074748039246, 'loss_box_reg': 0.066290482878685, 'loss_mask': 0.18872259557247162, 'loss_objectness': 0.06117658317089081, 'loss_rpn_box_reg': 0.028573427349328995}
  Batch [380/1526] Loss: 11.0971 Components: {'loss_classifier': 0.28779086470603943, 'loss_box_reg': 0.09897081553936005, 'loss_mask': 0.006634710822254419, 'loss_objectness': 0.5177534222602844, 'loss_rpn_box_reg': 10.185992240905762}
  Batch [490/1526] Loss: 0.5365 Components: {'loss_classifier': 0.24265031516551971, 'loss_box_reg': 0.1577257513999939, 'loss_mask': 0.02310951240360737, 'loss_objectness': 0.05049082636833191, 'loss_rpn_box_reg': 0.06252259016036987}
  Batch [500/1526] Loss: 0.4756 Components: {'loss_classifier': 0.13392090797424316, 'loss_box_reg': 0.11614427715539932, 'loss_mask': 0.1185724064707756, 'loss_objectness': 0.0831504762172699, 'loss_rpn_box_reg': 0.023764178156852722}
  Batch [520/1526] Loss: 0.2916 Components: {'loss_classifier': 0.13935677707195282, 'loss_box_reg': 0.09638580679893494, 'loss_mask': 0.00607686024159193, 'loss_objectness': 0.04011938348412514, 'loss_rpn_box_reg': 0.00962879229336977}
  Batch [700/1526] Loss: 0.4048 Components: {'loss_classifier': 0.12153997272253036, 'loss_box_reg': 0.0915442705154419, 'loss_mask': 0.04948889836668968, 'loss_objectness': 0.0486733540892601, 'loss_rpn_box_reg': 0.0935961902141571}
  Batch [740/1526] Loss: 1.3128 Components: {'loss_classifier': 0.5240349769592285, 'loss_box_reg': 0.5318756699562073, 'loss_mask': 0.008767064660787582, 'loss_objectness': 0.11954807490110397, 'loss_rpn_box_reg': 0.12859654426574707}
  Batch [840/1526] Loss: 0.6294 Components: {'loss_classifier': 0.18619920313358307, 'loss_box_reg': 0.0849895030260086, 'loss_mask': 9.46944928728044e-05, 'loss_objectness': 0.09875815361738205, 'loss_rpn_box_reg': 0.2594071328639984}
  Batch [900/1526] Loss: 0.2467 Components: {'loss_classifier': 0.1152699887752533, 'loss_box_reg': 0.07962080091238022, 'loss_mask': 7.751099474262446e-05, 'loss_objectness': 0.03126998990774155, 'loss_rpn_box_reg': 0.02048639766871929}
  Batch [950/1526] Loss: 0.2929 Components: {'loss_classifier': 0.08906067907810211, 'loss_box_reg': 0.038473065942525864, 'loss_mask': 0.00025366852059960365, 'loss_objectness': 0.10092523694038391, 'loss_rpn_box_reg': 0.06413883715867996}
  Batch [1080/1526] Loss: 0.4966 Components: {'loss_classifier': 0.0773572102189064, 'loss_box_reg': 0.025178013369441032, 'loss_mask': 0.18704654276371002, 'loss_objectness': 0.1287594586610794, 'loss_rpn_box_reg': 0.07826962321996689}
  Batch [1180/1526] Loss: 0.4426 Components: {'loss_classifier': 0.15690092742443085, 'loss_box_reg': 0.16912013292312622, 'loss_mask': 0.05111328884959221, 'loss_objectness': 0.05979832634329796, 'loss_rpn_box_reg': 0.0056267837062478065}
  Batch [1230/1526] Loss: 0.6424 Components: {'loss_classifier': 0.2569678723812103, 'loss_box_reg': 0.14000989496707916, 'loss_mask': 0.0026114366482943296, 'loss_objectness': 0.06852979958057404, 'loss_rpn_box_reg': 0.17424172163009644}
  Batch [1260/1526] Loss: 0.5834 Components: {'loss_classifier': 0.27109256386756897, 'loss_box_reg': 0.22132113575935364, 'loss_mask': 0.0008058352395892143, 'loss_objectness': 0.05296119675040245, 'loss_rpn_box_reg': 0.037229713052511215}
  Batch [1310/1526] Loss: 0.6043 Components: {'loss_classifier': 0.18844686448574066, 'loss_box_reg': 0.16109412908554077, 'loss_mask': 0.00018676428589969873, 'loss_objectness': 0.1732357293367386, 'loss_rpn_box_reg': 0.08137338608503342}
  Batch [1340/1526] Loss: 0.3896 Components: {'loss_classifier': 0.18614561855793, 'loss_box_reg': 0.12725305557250977, 'loss_mask': 0.0006221443181857467, 'loss_objectness': 0.06228003278374672, 'loss_rpn_box_reg': 0.0132808992639184}
  Batch [1430/1526] Loss: 0.5430 Components: {'loss_classifier': 0.2901087701320648, 'loss_box_reg': 0.14595328271389008, 'loss_mask': 0.0008898836094886065, 'loss_objectness': 0.0829351544380188, 'loss_rpn_box_reg': 0.023086844012141228}
  Batch [1450/1526] Loss: 1.0542 Components: {'loss_classifier': 0.49259817600250244, 'loss_box_reg': 0.27574169635772705, 'loss_mask': 0.0022380107548087835, 'loss_objectness': 0.16991616785526276, 'loss_rpn_box_reg': 0.1136721670627594}
  Batch [1510/1526] Loss: 0.5286 Components: {'loss_classifier': 0.15434587001800537, 'loss_box_reg': 0.14656303822994232, 'loss_mask': 0.16890549659729004, 'loss_objectness': 0.050874657928943634, 'loss_rpn_box_reg': 0.007918448187410831}

Epoch 15 Summary:
  Train Loss: 1.3440
  Val Loss: 1.7774
  Learning Rate: 0.002000
  Epoch Time: 2541.4s
  EarlyStopping counter: 9 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 16/100
----------------------------------------
  Batch [70/1526] Loss: 5.0008 Components: {'loss_classifier': 0.11579868942499161, 'loss_box_reg': 0.0702294409275055, 'loss_mask': 0.03429225832223892, 'loss_objectness': 0.7729375958442688, 'loss_rpn_box_reg': 4.0075602531433105}
  Batch [80/1526] Loss: 0.2551 Components: {'loss_classifier': 0.11463265120983124, 'loss_box_reg': 0.04906727746129036, 'loss_mask': 0.0002307756367372349, 'loss_objectness': 0.08505558222532272, 'loss_rpn_box_reg': 0.006084759719669819}
  Batch [90/1526] Loss: 0.5933 Components: {'loss_classifier': 0.2595309019088745, 'loss_box_reg': 0.14902351796627045, 'loss_mask': 0.000792776292655617, 'loss_objectness': 0.11641307175159454, 'loss_rpn_box_reg': 0.06756912171840668}
  Batch [200/1526] Loss: 0.6446 Components: {'loss_classifier': 0.2203122228384018, 'loss_box_reg': 0.11925509572029114, 'loss_mask': 0.12482459098100662, 'loss_objectness': 0.15440014004707336, 'loss_rpn_box_reg': 0.02578197792172432}
  Batch [280/1526] Loss: 0.5968 Components: {'loss_classifier': 0.27421844005584717, 'loss_box_reg': 0.2192901074886322, 'loss_mask': 0.009792814031243324, 'loss_objectness': 0.0704941675066948, 'loss_rpn_box_reg': 0.022972477599978447}
  Batch [400/1526] Loss: 0.6041 Components: {'loss_classifier': 0.17206953465938568, 'loss_box_reg': 0.10219535231590271, 'loss_mask': 0.28067901730537415, 'loss_objectness': 0.046111732721328735, 'loss_rpn_box_reg': 0.0030144304037094116}
  Batch [430/1526] Loss: 0.7946 Components: {'loss_classifier': 0.24221311509609222, 'loss_box_reg': 0.1858610361814499, 'loss_mask': 0.3197675347328186, 'loss_objectness': 0.04169803112745285, 'loss_rpn_box_reg': 0.0050601596012711525}
  Batch [450/1526] Loss: 0.3393 Components: {'loss_classifier': 0.12217158079147339, 'loss_box_reg': 0.0925544798374176, 'loss_mask': 0.05480362847447395, 'loss_objectness': 0.05827369540929794, 'loss_rpn_box_reg': 0.01150577049702406}
  Batch [460/1526] Loss: 0.6921 Components: {'loss_classifier': 0.23449701070785522, 'loss_box_reg': 0.2637726664543152, 'loss_mask': 0.16025950014591217, 'loss_objectness': 0.020648833364248276, 'loss_rpn_box_reg': 0.012886492535471916}
  Batch [480/1526] Loss: 0.8872 Components: {'loss_classifier': 0.3510845899581909, 'loss_box_reg': 0.30111193656921387, 'loss_mask': 9.393671643920243e-05, 'loss_objectness': 0.0760626345872879, 'loss_rpn_box_reg': 0.15882007777690887}
  Batch [490/1526] Loss: 0.3963 Components: {'loss_classifier': 0.21091744303703308, 'loss_box_reg': 0.16540849208831787, 'loss_mask': 0.0009082407341338694, 'loss_objectness': 0.011401466093957424, 'loss_rpn_box_reg': 0.0076273782178759575}
  Batch [510/1526] Loss: 0.8274 Components: {'loss_classifier': 0.23159947991371155, 'loss_box_reg': 0.09636954963207245, 'loss_mask': 7.70743572502397e-05, 'loss_objectness': 0.2613787353038788, 'loss_rpn_box_reg': 0.2380022257566452}
  Batch [540/1526] Loss: 0.7609 Components: {'loss_classifier': 0.2419234961271286, 'loss_box_reg': 0.07264774292707443, 'loss_mask': 0.03517620265483856, 'loss_objectness': 0.20477363467216492, 'loss_rpn_box_reg': 0.20635484158992767}
  Batch [600/1526] Loss: 0.8670 Components: {'loss_classifier': 0.1889343410730362, 'loss_box_reg': 0.13566923141479492, 'loss_mask': 0.25044316053390503, 'loss_objectness': 0.13139796257019043, 'loss_rpn_box_reg': 0.16054731607437134}
  Batch [650/1526] Loss: 0.8555 Components: {'loss_classifier': 0.3545099198818207, 'loss_box_reg': 0.32058224081993103, 'loss_mask': 0.021834757179021835, 'loss_objectness': 0.12156964838504791, 'loss_rpn_box_reg': 0.037017498165369034}
  Batch [690/1526] Loss: 0.6773 Components: {'loss_classifier': 0.2847011387348175, 'loss_box_reg': 0.16522350907325745, 'loss_mask': 0.03521635755896568, 'loss_objectness': 0.14504659175872803, 'loss_rpn_box_reg': 0.04714855179190636}
  Batch [700/1526] Loss: 1.1733 Components: {'loss_classifier': 0.5761608481407166, 'loss_box_reg': 0.3728964030742645, 'loss_mask': 0.0017946005100384355, 'loss_objectness': 0.15334491431713104, 'loss_rpn_box_reg': 0.06912876665592194}
  Batch [790/1526] Loss: 0.5241 Components: {'loss_classifier': 0.11055824905633926, 'loss_box_reg': 0.06826949864625931, 'loss_mask': 0.24421988427639008, 'loss_objectness': 0.05480450764298439, 'loss_rpn_box_reg': 0.046237532049417496}
  Batch [1010/1526] Loss: 1.3283 Components: {'loss_classifier': 0.4287799596786499, 'loss_box_reg': 0.35363397002220154, 'loss_mask': 0.20622897148132324, 'loss_objectness': 0.22141480445861816, 'loss_rpn_box_reg': 0.11827656626701355}
  Batch [1050/1526] Loss: 0.5368 Components: {'loss_classifier': 0.2113872468471527, 'loss_box_reg': 0.1445765197277069, 'loss_mask': 0.011703354306519032, 'loss_objectness': 0.12440292537212372, 'loss_rpn_box_reg': 0.044756822288036346}
  Batch [1280/1526] Loss: 0.5686 Components: {'loss_classifier': 0.22464673221111298, 'loss_box_reg': 0.14407169818878174, 'loss_mask': 0.06478182971477509, 'loss_objectness': 0.09822860360145569, 'loss_rpn_box_reg': 0.036822255700826645}
  Batch [1300/1526] Loss: 0.5690 Components: {'loss_classifier': 0.20167900621891022, 'loss_box_reg': 0.21424271166324615, 'loss_mask': 0.08925824612379074, 'loss_objectness': 0.05845692381262779, 'loss_rpn_box_reg': 0.0053671011701226234}
  Batch [1440/1526] Loss: 0.4211 Components: {'loss_classifier': 0.19310800731182098, 'loss_box_reg': 0.12768301367759705, 'loss_mask': 4.768077269545756e-05, 'loss_objectness': 0.08493400365114212, 'loss_rpn_box_reg': 0.015324931591749191}

Epoch 16 Summary:
  Train Loss: 1.0063
  Val Loss: 1.4316
  Learning Rate: 0.002000
  Epoch Time: 2471.8s
  EarlyStopping counter: 10 out of 15

Epoch 17/100
----------------------------------------
  Batch [10/1526] Loss: 0.5592 Components: {'loss_classifier': 0.1493048369884491, 'loss_box_reg': 0.07638201862573624, 'loss_mask': 0.0004980475059710443, 'loss_objectness': 0.09531853348016739, 'loss_rpn_box_reg': 0.23770946264266968}
  Batch [140/1526] Loss: 0.3079 Components: {'loss_classifier': 0.138228178024292, 'loss_box_reg': 0.07678065448999405, 'loss_mask': 0.04701317846775055, 'loss_objectness': 0.04357776790857315, 'loss_rpn_box_reg': 0.0022704857401549816}
  Batch [200/1526] Loss: 0.6288 Components: {'loss_classifier': 0.19772329926490784, 'loss_box_reg': 0.2641984820365906, 'loss_mask': 0.0769425556063652, 'loss_objectness': 0.07300280779600143, 'loss_rpn_box_reg': 0.016945289447903633}
  Batch [360/1526] Loss: 0.8834 Components: {'loss_classifier': 0.2146056890487671, 'loss_box_reg': 0.19692157208919525, 'loss_mask': 0.27407997846603394, 'loss_objectness': 0.11243804544210434, 'loss_rpn_box_reg': 0.0853559821844101}
  Batch [430/1526] Loss: 5.9688 Components: {'loss_classifier': 0.12434472888708115, 'loss_box_reg': 0.011166330426931381, 'loss_mask': 0.01102328859269619, 'loss_objectness': 0.8176073431968689, 'loss_rpn_box_reg': 5.004636764526367}
  Batch [530/1526] Loss: 0.5516 Components: {'loss_classifier': 0.23151849210262299, 'loss_box_reg': 0.19955524802207947, 'loss_mask': 0.03280884772539139, 'loss_objectness': 0.06893833726644516, 'loss_rpn_box_reg': 0.018731245771050453}
  Batch [570/1526] Loss: 0.4221 Components: {'loss_classifier': 0.13153678178787231, 'loss_box_reg': 0.09115439653396606, 'loss_mask': 6.794693763367832e-05, 'loss_objectness': 0.029250526800751686, 'loss_rpn_box_reg': 0.17008492350578308}
  Batch [610/1526] Loss: 0.6254 Components: {'loss_classifier': 0.21110637485980988, 'loss_box_reg': 0.25228172540664673, 'loss_mask': 0.0736112967133522, 'loss_objectness': 0.049712467938661575, 'loss_rpn_box_reg': 0.03865247592329979}
  Batch [630/1526] Loss: 1.1923 Components: {'loss_classifier': 0.5482931137084961, 'loss_box_reg': 0.37275487184524536, 'loss_mask': 0.09972640126943588, 'loss_objectness': 0.11517016589641571, 'loss_rpn_box_reg': 0.05633848160505295}
  Batch [650/1526] Loss: 0.5032 Components: {'loss_classifier': 0.20854710042476654, 'loss_box_reg': 0.10340981185436249, 'loss_mask': 0.029851464554667473, 'loss_objectness': 0.14350391924381256, 'loss_rpn_box_reg': 0.017936522141098976}
  Batch [680/1526] Loss: 0.3650 Components: {'loss_classifier': 0.11360733956098557, 'loss_box_reg': 0.09717072546482086, 'loss_mask': 0.002195806009694934, 'loss_objectness': 0.12019170820713043, 'loss_rpn_box_reg': 0.031828440725803375}
  Batch [710/1526] Loss: 0.7183 Components: {'loss_classifier': 0.19497959315776825, 'loss_box_reg': 0.21063902974128723, 'loss_mask': 0.19704043865203857, 'loss_objectness': 0.08324402570724487, 'loss_rpn_box_reg': 0.03238818421959877}
  Batch [750/1526] Loss: 0.3519 Components: {'loss_classifier': 0.1658775806427002, 'loss_box_reg': 0.07554303854703903, 'loss_mask': 0.013999450020492077, 'loss_objectness': 0.06776438653469086, 'loss_rpn_box_reg': 0.028677456080913544}
  Batch [780/1526] Loss: 11.4181 Components: {'loss_classifier': 0.159465029835701, 'loss_box_reg': 0.04864995554089546, 'loss_mask': 0.0024817425291985273, 'loss_objectness': 0.5430346131324768, 'loss_rpn_box_reg': 10.664460182189941}
  Batch [800/1526] Loss: 1.0011 Components: {'loss_classifier': 0.3719041645526886, 'loss_box_reg': 0.21800240874290466, 'loss_mask': 0.11728021502494812, 'loss_objectness': 0.17174965143203735, 'loss_rpn_box_reg': 0.12212974578142166}
  Batch [830/1526] Loss: 0.3051 Components: {'loss_classifier': 0.09143070131540298, 'loss_box_reg': 0.06801427155733109, 'loss_mask': 0.0013906728709116578, 'loss_objectness': 0.13854411244392395, 'loss_rpn_box_reg': 0.0057404241524636745}
  Batch [950/1526] Loss: 0.4106 Components: {'loss_classifier': 0.12102432548999786, 'loss_box_reg': 0.08472395688295364, 'loss_mask': 0.0003323710698168725, 'loss_objectness': 0.03272624313831329, 'loss_rpn_box_reg': 0.1718304455280304}
  Batch [980/1526] Loss: 0.3906 Components: {'loss_classifier': 0.1539909541606903, 'loss_box_reg': 0.07237280905246735, 'loss_mask': 0.0012124155182391405, 'loss_objectness': 0.05811847001314163, 'loss_rpn_box_reg': 0.10494454950094223}
  Batch [1010/1526] Loss: 0.1999 Components: {'loss_classifier': 0.06564929336309433, 'loss_box_reg': 0.0011957018868997693, 'loss_mask': 0.01575087197124958, 'loss_objectness': 0.07019713521003723, 'loss_rpn_box_reg': 0.047131653875112534}
  Batch [1030/1526] Loss: 0.9933 Components: {'loss_classifier': 0.4036766290664673, 'loss_box_reg': 0.46872061491012573, 'loss_mask': 0.05130282789468765, 'loss_objectness': 0.04797804355621338, 'loss_rpn_box_reg': 0.021639429032802582}
  Batch [1080/1526] Loss: 0.3799 Components: {'loss_classifier': 0.14412689208984375, 'loss_box_reg': 0.05238177254796028, 'loss_mask': 0.031835321336984634, 'loss_objectness': 0.08709725737571716, 'loss_rpn_box_reg': 0.06446579098701477}
  Batch [1100/1526] Loss: 1.2322 Components: {'loss_classifier': 0.5361426472663879, 'loss_box_reg': 0.4778156280517578, 'loss_mask': 0.0012507665669545531, 'loss_objectness': 0.11967448145151138, 'loss_rpn_box_reg': 0.09735090285539627}
  Batch [1120/1526] Loss: 0.7465 Components: {'loss_classifier': 0.2537381052970886, 'loss_box_reg': 0.1999020129442215, 'loss_mask': 0.031923841685056686, 'loss_objectness': 0.09882032871246338, 'loss_rpn_box_reg': 0.16215795278549194}
  Batch [1130/1526] Loss: 0.2120 Components: {'loss_classifier': 0.07401325553655624, 'loss_box_reg': 0.05524274706840515, 'loss_mask': 0.03195009380578995, 'loss_objectness': 0.04846206679940224, 'loss_rpn_box_reg': 0.0023546130396425724}
  Batch [1140/1526] Loss: 0.6403 Components: {'loss_classifier': 0.27807262539863586, 'loss_box_reg': 0.2503942847251892, 'loss_mask': 0.010138471610844135, 'loss_objectness': 0.0647018700838089, 'loss_rpn_box_reg': 0.037036508321762085}
  Batch [1230/1526] Loss: 0.5015 Components: {'loss_classifier': 0.1100231185555458, 'loss_box_reg': 0.0045350282453000546, 'loss_mask': 0.015221080742776394, 'loss_objectness': 0.2446325719356537, 'loss_rpn_box_reg': 0.12707370519638062}
  Batch [1380/1526] Loss: 0.8053 Components: {'loss_classifier': 0.38108503818511963, 'loss_box_reg': 0.1715870499610901, 'loss_mask': 0.004597383085638285, 'loss_objectness': 0.19564329087734222, 'loss_rpn_box_reg': 0.05242704972624779}

Epoch 17 Summary:
  Train Loss: 0.9684
  Val Loss: 1.3514
  Learning Rate: 0.002000
  Epoch Time: 2434.3s
  EarlyStopping counter: 11 out of 15

Epoch 18/100
----------------------------------------
  Batch [10/1526] Loss: 0.4644 Components: {'loss_classifier': 0.21113425493240356, 'loss_box_reg': 0.17106372117996216, 'loss_mask': 0.0003749192110262811, 'loss_objectness': 0.060748085379600525, 'loss_rpn_box_reg': 0.02112058736383915}
  Batch [30/1526] Loss: 0.4101 Components: {'loss_classifier': 0.11891617625951767, 'loss_box_reg': 0.06391123682260513, 'loss_mask': 0.06980590522289276, 'loss_objectness': 0.13884186744689941, 'loss_rpn_box_reg': 0.01861385814845562}
  Batch [60/1526] Loss: 1.3467 Components: {'loss_classifier': 0.49212974309921265, 'loss_box_reg': 0.187818706035614, 'loss_mask': 0.0009669907740317285, 'loss_objectness': 0.3840098977088928, 'loss_rpn_box_reg': 0.28181958198547363}
  Batch [70/1526] Loss: 0.5577 Components: {'loss_classifier': 0.24489688873291016, 'loss_box_reg': 0.17799347639083862, 'loss_mask': 0.001208278234116733, 'loss_objectness': 0.09068609774112701, 'loss_rpn_box_reg': 0.04294215887784958}
  Batch [90/1526] Loss: 0.2359 Components: {'loss_classifier': 0.1105864867568016, 'loss_box_reg': 0.0517391562461853, 'loss_mask': 0.003043406642973423, 'loss_objectness': 0.05199627950787544, 'loss_rpn_box_reg': 0.01850971207022667}
  Batch [120/1526] Loss: 0.4096 Components: {'loss_classifier': 0.20941877365112305, 'loss_box_reg': 0.12178804725408554, 'loss_mask': 0.007823145017027855, 'loss_objectness': 0.05984274297952652, 'loss_rpn_box_reg': 0.010732031427323818}
  Batch [190/1526] Loss: 0.1501 Components: {'loss_classifier': 0.08004563301801682, 'loss_box_reg': 0.013816728256642818, 'loss_mask': 0.006526951678097248, 'loss_objectness': 0.036833256483078, 'loss_rpn_box_reg': 0.012903607450425625}
  Batch [280/1526] Loss: 1.0943 Components: {'loss_classifier': 0.40033334493637085, 'loss_box_reg': 0.6078683733940125, 'loss_mask': 0.021650228649377823, 'loss_objectness': 0.04111597687005997, 'loss_rpn_box_reg': 0.023364759981632233}
  Batch [290/1526] Loss: 0.7979 Components: {'loss_classifier': 0.2852599322795868, 'loss_box_reg': 0.33097004890441895, 'loss_mask': 0.003173450008034706, 'loss_objectness': 0.09617134928703308, 'loss_rpn_box_reg': 0.08232351392507553}
  Batch [320/1526] Loss: 0.2209 Components: {'loss_classifier': 0.09347229450941086, 'loss_box_reg': 0.07709044218063354, 'loss_mask': 0.0006853163940832019, 'loss_objectness': 0.041016001254320145, 'loss_rpn_box_reg': 0.008608870208263397}
  Batch [370/1526] Loss: 0.9326 Components: {'loss_classifier': 0.32274654507637024, 'loss_box_reg': 0.28847962617874146, 'loss_mask': 0.0004587712755892426, 'loss_objectness': 0.09506598860025406, 'loss_rpn_box_reg': 0.22588461637496948}
  Batch [410/1526] Loss: 0.4358 Components: {'loss_classifier': 0.20232675969600677, 'loss_box_reg': 0.14248085021972656, 'loss_mask': 0.0023032561875879765, 'loss_objectness': 0.07659176737070084, 'loss_rpn_box_reg': 0.012052197009325027}
  Batch [450/1526] Loss: 1.0191 Components: {'loss_classifier': 0.16807430982589722, 'loss_box_reg': 0.10711675882339478, 'loss_mask': 0.0013969551073387265, 'loss_objectness': 0.3836749494075775, 'loss_rpn_box_reg': 0.3588285446166992}
  Batch [470/1526] Loss: 1.8009 Components: {'loss_classifier': 0.574908435344696, 'loss_box_reg': 0.4709104597568512, 'loss_mask': 0.00262029399164021, 'loss_objectness': 0.24280445277690887, 'loss_rpn_box_reg': 0.5096567273139954}
  Batch [520/1526] Loss: 1.1238 Components: {'loss_classifier': 0.4801934063434601, 'loss_box_reg': 0.20004120469093323, 'loss_mask': 0.0019192821346223354, 'loss_objectness': 0.23938611149787903, 'loss_rpn_box_reg': 0.20229780673980713}
  Batch [570/1526] Loss: 0.5473 Components: {'loss_classifier': 0.2225227952003479, 'loss_box_reg': 0.23855720460414886, 'loss_mask': 0.04432349279522896, 'loss_objectness': 0.029874755069613457, 'loss_rpn_box_reg': 0.012002075091004372}
  Batch [600/1526] Loss: 0.4200 Components: {'loss_classifier': 0.166134312748909, 'loss_box_reg': 0.1260184794664383, 'loss_mask': 0.02855636738240719, 'loss_objectness': 0.06773486733436584, 'loss_rpn_box_reg': 0.03155456483364105}
  Batch [610/1526] Loss: 1.0469 Components: {'loss_classifier': 0.3690143823623657, 'loss_box_reg': 0.4474581182003021, 'loss_mask': 0.1315370798110962, 'loss_objectness': 0.0779917985200882, 'loss_rpn_box_reg': 0.020897196605801582}
  Batch [710/1526] Loss: 0.6722 Components: {'loss_classifier': 0.18445232510566711, 'loss_box_reg': 0.20390188694000244, 'loss_mask': 0.24763230979442596, 'loss_objectness': 0.03228910267353058, 'loss_rpn_box_reg': 0.003948368597775698}
  Batch [720/1526] Loss: 0.7886 Components: {'loss_classifier': 0.29977256059646606, 'loss_box_reg': 0.3257000148296356, 'loss_mask': 0.03440864384174347, 'loss_objectness': 0.08838367462158203, 'loss_rpn_box_reg': 0.040384840220212936}
  Batch [760/1526] Loss: 0.3725 Components: {'loss_classifier': 0.18543951213359833, 'loss_box_reg': 0.10212358832359314, 'loss_mask': 0.0007352298125624657, 'loss_objectness': 0.05854681134223938, 'loss_rpn_box_reg': 0.025648292154073715}
  Batch [790/1526] Loss: 0.3262 Components: {'loss_classifier': 0.14519308507442474, 'loss_box_reg': 0.1312745064496994, 'loss_mask': 0.00038618341204710305, 'loss_objectness': 0.03967384248971939, 'loss_rpn_box_reg': 0.009720834903419018}
  Batch [830/1526] Loss: 0.1756 Components: {'loss_classifier': 0.08781454712152481, 'loss_box_reg': 0.029578939080238342, 'loss_mask': 0.0031746721360832453, 'loss_objectness': 0.05252457037568092, 'loss_rpn_box_reg': 0.0025448433589190245}
  Batch [850/1526] Loss: 0.4913 Components: {'loss_classifier': 0.17226457595825195, 'loss_box_reg': 0.16052816808223724, 'loss_mask': 0.117510586977005, 'loss_objectness': 0.03600834310054779, 'loss_rpn_box_reg': 0.005002396181225777}
  Batch [880/1526] Loss: 0.3349 Components: {'loss_classifier': 0.09599511325359344, 'loss_box_reg': 0.05491575971245766, 'loss_mask': 0.00471695838496089, 'loss_objectness': 0.054287903010845184, 'loss_rpn_box_reg': 0.125011146068573}
  Batch [940/1526] Loss: 0.6562 Components: {'loss_classifier': 0.1938096135854721, 'loss_box_reg': 0.15044865012168884, 'loss_mask': 0.1906328946352005, 'loss_objectness': 0.07121531665325165, 'loss_rpn_box_reg': 0.05009078234434128}
  Batch [980/1526] Loss: 0.8245 Components: {'loss_classifier': 0.33022457361221313, 'loss_box_reg': 0.16449999809265137, 'loss_mask': 0.0014598005218431354, 'loss_objectness': 0.18146668374538422, 'loss_rpn_box_reg': 0.14683091640472412}
  Batch [1020/1526] Loss: 0.3734 Components: {'loss_classifier': 0.11619129776954651, 'loss_box_reg': 0.1481495350599289, 'loss_mask': 0.06974472850561142, 'loss_objectness': 0.030468352138996124, 'loss_rpn_box_reg': 0.008887293748557568}
  Batch [1040/1526] Loss: 0.4661 Components: {'loss_classifier': 0.19840362668037415, 'loss_box_reg': 0.17979329824447632, 'loss_mask': 0.019548306241631508, 'loss_objectness': 0.05421871319413185, 'loss_rpn_box_reg': 0.014145982451736927}
  Batch [1080/1526] Loss: 0.9548 Components: {'loss_classifier': 0.26463449001312256, 'loss_box_reg': 0.13376116752624512, 'loss_mask': 0.008109454065561295, 'loss_objectness': 0.3833647668361664, 'loss_rpn_box_reg': 0.1648818701505661}
  Batch [1100/1526] Loss: 0.8965 Components: {'loss_classifier': 0.35561898350715637, 'loss_box_reg': 0.2050488293170929, 'loss_mask': 0.00022473892022389919, 'loss_objectness': 0.153286412358284, 'loss_rpn_box_reg': 0.18229034543037415}
  Batch [1150/1526] Loss: 0.2965 Components: {'loss_classifier': 0.08164826035499573, 'loss_box_reg': 0.0862993597984314, 'loss_mask': 0.09989522397518158, 'loss_objectness': 0.024434490129351616, 'loss_rpn_box_reg': 0.004225783981382847}
  Batch [1170/1526] Loss: 0.3529 Components: {'loss_classifier': 0.1626308262348175, 'loss_box_reg': 0.1348508596420288, 'loss_mask': 0.0008011588361114264, 'loss_objectness': 0.04557115584611893, 'loss_rpn_box_reg': 0.009021696634590626}
  Batch [1190/1526] Loss: 0.7089 Components: {'loss_classifier': 0.290579617023468, 'loss_box_reg': 0.21802359819412231, 'loss_mask': 0.08113425225019455, 'loss_objectness': 0.07926574349403381, 'loss_rpn_box_reg': 0.03987529128789902}
  Batch [1260/1526] Loss: 0.3529 Components: {'loss_classifier': 0.1276712864637375, 'loss_box_reg': 0.1494647115468979, 'loss_mask': 0.026557553559541702, 'loss_objectness': 0.03526371344923973, 'loss_rpn_box_reg': 0.013937802985310555}
  Batch [1390/1526] Loss: 0.4217 Components: {'loss_classifier': 0.10483089834451675, 'loss_box_reg': 0.13373567163944244, 'loss_mask': 0.11764650046825409, 'loss_objectness': 0.05547141283750534, 'loss_rpn_box_reg': 0.010036079213023186}
  Batch [1410/1526] Loss: 0.3981 Components: {'loss_classifier': 0.17138023674488068, 'loss_box_reg': 0.11817459762096405, 'loss_mask': 0.0014974665828049183, 'loss_objectness': 0.05116179585456848, 'loss_rpn_box_reg': 0.05592803284525871}
  Batch [1420/1526] Loss: 0.5375 Components: {'loss_classifier': 0.10955478996038437, 'loss_box_reg': 0.06731949746608734, 'loss_mask': 0.31704026460647583, 'loss_objectness': 0.03858857601881027, 'loss_rpn_box_reg': 0.005022149998694658}
  Batch [1430/1526] Loss: 0.3886 Components: {'loss_classifier': 0.16702379286289215, 'loss_box_reg': 0.15789757668972015, 'loss_mask': 0.0005037514492869377, 'loss_objectness': 0.04343341290950775, 'loss_rpn_box_reg': 0.01976992003619671}
  Batch [1440/1526] Loss: 0.4528 Components: {'loss_classifier': 0.24045497179031372, 'loss_box_reg': 0.17872533202171326, 'loss_mask': 0.005675231572240591, 'loss_objectness': 0.021918606013059616, 'loss_rpn_box_reg': 0.006060821004211903}
  Batch [1450/1526] Loss: 11.4765 Components: {'loss_classifier': 0.2237653285264969, 'loss_box_reg': 0.08023371547460556, 'loss_mask': 0.00605052663013339, 'loss_objectness': 0.2765447199344635, 'loss_rpn_box_reg': 10.889887809753418}
  Batch [1470/1526] Loss: 0.9590 Components: {'loss_classifier': 0.4242527186870575, 'loss_box_reg': 0.3655545711517334, 'loss_mask': 0.05987897887825966, 'loss_objectness': 0.07870329916477203, 'loss_rpn_box_reg': 0.030598927289247513}
  Batch [1510/1526] Loss: 0.4471 Components: {'loss_classifier': 0.1890021562576294, 'loss_box_reg': 0.16276851296424866, 'loss_mask': 0.03511631116271019, 'loss_objectness': 0.03773252293467522, 'loss_rpn_box_reg': 0.02248752862215042}

Epoch 18 Summary:
  Train Loss: 1.1743
  Val Loss: 1.7712
  Learning Rate: 0.002000
  Epoch Time: 2598.8s
  EarlyStopping counter: 12 out of 15

Epoch 19/100
----------------------------------------
  Batch [60/1526] Loss: 0.7954 Components: {'loss_classifier': 0.35055509209632874, 'loss_box_reg': 0.28029870986938477, 'loss_mask': 0.08573456853628159, 'loss_objectness': 0.044849518686532974, 'loss_rpn_box_reg': 0.03391962870955467}
  Batch [90/1526] Loss: 0.5272 Components: {'loss_classifier': 0.25570768117904663, 'loss_box_reg': 0.16415998339653015, 'loss_mask': 0.0029948540031909943, 'loss_objectness': 0.04450290650129318, 'loss_rpn_box_reg': 0.059821147471666336}
  Batch [150/1526] Loss: 6.5734 Components: {'loss_classifier': 0.16366887092590332, 'loss_box_reg': 0.09225638955831528, 'loss_mask': 0.07613563537597656, 'loss_objectness': 1.3651008605957031, 'loss_rpn_box_reg': 4.876201629638672}
  Batch [230/1526] Loss: 0.5121 Components: {'loss_classifier': 0.23323357105255127, 'loss_box_reg': 0.19697923958301544, 'loss_mask': 0.02053714171051979, 'loss_objectness': 0.04854652285575867, 'loss_rpn_box_reg': 0.012784084305167198}
  Batch [290/1526] Loss: 0.4854 Components: {'loss_classifier': 0.22842055559158325, 'loss_box_reg': 0.19092845916748047, 'loss_mask': 0.004249600227922201, 'loss_objectness': 0.04230982065200806, 'loss_rpn_box_reg': 0.019474543631076813}
  Batch [330/1526] Loss: 8.6441 Components: {'loss_classifier': 0.15498241782188416, 'loss_box_reg': 0.15010619163513184, 'loss_mask': 0.04998423904180527, 'loss_objectness': 0.368733674287796, 'loss_rpn_box_reg': 7.9202799797058105}
  Batch [340/1526] Loss: 0.4869 Components: {'loss_classifier': 0.18839478492736816, 'loss_box_reg': 0.10461492836475372, 'loss_mask': 0.03719954937696457, 'loss_objectness': 0.09160605072975159, 'loss_rpn_box_reg': 0.06512416154146194}
  Batch [450/1526] Loss: 0.4730 Components: {'loss_classifier': 0.11123678833246231, 'loss_box_reg': 0.14473488926887512, 'loss_mask': 0.1872469186782837, 'loss_objectness': 0.023006856441497803, 'loss_rpn_box_reg': 0.006780484691262245}
  Batch [510/1526] Loss: 0.4114 Components: {'loss_classifier': 0.16828127205371857, 'loss_box_reg': 0.13251551985740662, 'loss_mask': 0.0034946342930197716, 'loss_objectness': 0.09313464164733887, 'loss_rpn_box_reg': 0.013992534950375557}
  Batch [620/1526] Loss: 0.2529 Components: {'loss_classifier': 0.06827184557914734, 'loss_box_reg': 0.03295557200908661, 'loss_mask': 0.0033881408162415028, 'loss_objectness': 0.04372042044997215, 'loss_rpn_box_reg': 0.10461302846670151}
  Batch [720/1526] Loss: 0.5717 Components: {'loss_classifier': 0.21721433103084564, 'loss_box_reg': 0.19669950008392334, 'loss_mask': 0.10170193761587143, 'loss_objectness': 0.03792712837457657, 'loss_rpn_box_reg': 0.018151724711060524}
  Batch [790/1526] Loss: 0.3122 Components: {'loss_classifier': 0.077121302485466, 'loss_box_reg': 0.06484554708003998, 'loss_mask': 0.02685508318245411, 'loss_objectness': 0.12275977432727814, 'loss_rpn_box_reg': 0.020636573433876038}
  Batch [820/1526] Loss: 0.7145 Components: {'loss_classifier': 0.25063610076904297, 'loss_box_reg': 0.12720125913619995, 'loss_mask': 4.4547727156896144e-05, 'loss_objectness': 0.147005096077919, 'loss_rpn_box_reg': 0.1895742118358612}
  Batch [830/1526] Loss: 1.1387 Components: {'loss_classifier': 0.3409142792224884, 'loss_box_reg': 0.5030632615089417, 'loss_mask': 0.16153185069561005, 'loss_objectness': 0.09514119476079941, 'loss_rpn_box_reg': 0.03805055096745491}
  Batch [860/1526] Loss: 1.0521 Components: {'loss_classifier': 0.4759451150894165, 'loss_box_reg': 0.3398773968219757, 'loss_mask': 4.6435321564786136e-05, 'loss_objectness': 0.12155187129974365, 'loss_rpn_box_reg': 0.11470411717891693}
  Batch [870/1526] Loss: 0.5971 Components: {'loss_classifier': 0.2538587749004364, 'loss_box_reg': 0.15897084772586823, 'loss_mask': 0.002726500853896141, 'loss_objectness': 0.12850697338581085, 'loss_rpn_box_reg': 0.053084928542375565}
  Batch [880/1526] Loss: 0.5028 Components: {'loss_classifier': 0.17468006908893585, 'loss_box_reg': 0.1422608345746994, 'loss_mask': 0.05547957494854927, 'loss_objectness': 0.09775987267494202, 'loss_rpn_box_reg': 0.03266146034002304}
  Batch [920/1526] Loss: 1.2560 Components: {'loss_classifier': 0.40820688009262085, 'loss_box_reg': 0.6523646116256714, 'loss_mask': 0.055726949125528336, 'loss_objectness': 0.09402596205472946, 'loss_rpn_box_reg': 0.04562965780496597}
  Batch [1040/1526] Loss: 1.0694 Components: {'loss_classifier': 0.35855168104171753, 'loss_box_reg': 0.3585871458053589, 'loss_mask': 0.13512328267097473, 'loss_objectness': 0.12176258116960526, 'loss_rpn_box_reg': 0.09540773928165436}
  Batch [1050/1526] Loss: 0.3155 Components: {'loss_classifier': 0.1581944227218628, 'loss_box_reg': 0.11924054473638535, 'loss_mask': 0.0003329018072690815, 'loss_objectness': 0.031123967841267586, 'loss_rpn_box_reg': 0.006639179307967424}
  Batch [1070/1526] Loss: 0.8221 Components: {'loss_classifier': 0.36670392751693726, 'loss_box_reg': 0.21145318448543549, 'loss_mask': 0.0008109966292977333, 'loss_objectness': 0.14855332672595978, 'loss_rpn_box_reg': 0.0946006029844284}
  Batch [1120/1526] Loss: 0.2753 Components: {'loss_classifier': 0.1274406909942627, 'loss_box_reg': 0.10148446261882782, 'loss_mask': 0.0032102458644658327, 'loss_objectness': 0.037695206701755524, 'loss_rpn_box_reg': 0.005447353236377239}
  Batch [1160/1526] Loss: 0.4300 Components: {'loss_classifier': 0.18744660913944244, 'loss_box_reg': 0.16716985404491425, 'loss_mask': 0.0020775552839040756, 'loss_objectness': 0.05150971561670303, 'loss_rpn_box_reg': 0.021751049906015396}
  Batch [1170/1526] Loss: 0.6840 Components: {'loss_classifier': 0.1916484832763672, 'loss_box_reg': 0.3992413580417633, 'loss_mask': 0.06631086021661758, 'loss_objectness': 0.020328957587480545, 'loss_rpn_box_reg': 0.006466140504926443}
  Batch [1240/1526] Loss: 0.2603 Components: {'loss_classifier': 0.12031541764736176, 'loss_box_reg': 0.07793296128511429, 'loss_mask': 0.023670582100749016, 'loss_objectness': 0.03562347590923309, 'loss_rpn_box_reg': 0.00271870126016438}
  Batch [1250/1526] Loss: 0.3416 Components: {'loss_classifier': 0.15018756687641144, 'loss_box_reg': 0.09996818006038666, 'loss_mask': 0.0003644020762294531, 'loss_objectness': 0.07371164113283157, 'loss_rpn_box_reg': 0.017324689775705338}
  Batch [1460/1526] Loss: 7.0276 Components: {'loss_classifier': 0.2989368736743927, 'loss_box_reg': 0.24285122752189636, 'loss_mask': 0.05387027934193611, 'loss_objectness': 1.4482747316360474, 'loss_rpn_box_reg': 4.98364782333374}
  Batch [1480/1526] Loss: 0.9782 Components: {'loss_classifier': 0.26666146516799927, 'loss_box_reg': 0.045282382518053055, 'loss_mask': 0.09867197275161743, 'loss_objectness': 0.3069821000099182, 'loss_rpn_box_reg': 0.26059192419052124}

Epoch 19 Summary:
  Train Loss: 1.0867
  Val Loss: 1.2654
  Learning Rate: 0.002000
  Epoch Time: 2608.8s
  ✓ Saved best model (val_loss: 1.2654)
  Validation loss decreased (1.337097 --> 1.265431). Saving model...

Epoch 20/100
----------------------------------------
  Batch [20/1526] Loss: 0.7152 Components: {'loss_classifier': 0.20102570950984955, 'loss_box_reg': 0.27480828762054443, 'loss_mask': 0.1722019463777542, 'loss_objectness': 0.05230235680937767, 'loss_rpn_box_reg': 0.014847112819552422}
  Batch [90/1526] Loss: 0.5544 Components: {'loss_classifier': 0.2485213428735733, 'loss_box_reg': 0.1817297637462616, 'loss_mask': 0.002206047298386693, 'loss_objectness': 0.10694770514965057, 'loss_rpn_box_reg': 0.014958186075091362}
  Batch [180/1526] Loss: 0.7954 Components: {'loss_classifier': 0.19474740326404572, 'loss_box_reg': 0.09542173147201538, 'loss_mask': 0.0006869617500342429, 'loss_objectness': 0.3362203538417816, 'loss_rpn_box_reg': 0.16831034421920776}
  Batch [270/1526] Loss: 0.5026 Components: {'loss_classifier': 0.2644263207912445, 'loss_box_reg': 0.1939440369606018, 'loss_mask': 0.002934593940153718, 'loss_objectness': 0.021444791927933693, 'loss_rpn_box_reg': 0.019846253097057343}
  Batch [290/1526] Loss: 0.4396 Components: {'loss_classifier': 0.19108958542346954, 'loss_box_reg': 0.13902629911899567, 'loss_mask': 0.02511136420071125, 'loss_objectness': 0.06162770837545395, 'loss_rpn_box_reg': 0.02278115041553974}
  Batch [460/1526] Loss: 0.5465 Components: {'loss_classifier': 0.2506486773490906, 'loss_box_reg': 0.14218252897262573, 'loss_mask': 0.0007836971781216562, 'loss_objectness': 0.04667007178068161, 'loss_rpn_box_reg': 0.10626257210969925}
  Batch [470/1526] Loss: 0.2555 Components: {'loss_classifier': 0.07630466669797897, 'loss_box_reg': 0.049090947955846786, 'loss_mask': 0.019105514511466026, 'loss_objectness': 0.08238273113965988, 'loss_rpn_box_reg': 0.028598256409168243}
  Batch [490/1526] Loss: 0.6825 Components: {'loss_classifier': 0.1382741779088974, 'loss_box_reg': 0.16611722111701965, 'loss_mask': 0.352902352809906, 'loss_objectness': 0.017708146944642067, 'loss_rpn_box_reg': 0.007471012882888317}
  Batch [540/1526] Loss: 1.0374 Components: {'loss_classifier': 0.3813358545303345, 'loss_box_reg': 0.46442198753356934, 'loss_mask': 0.0004843106435146183, 'loss_objectness': 0.11024241149425507, 'loss_rpn_box_reg': 0.08091802895069122}
  Batch [580/1526] Loss: 0.3250 Components: {'loss_classifier': 0.13444240391254425, 'loss_box_reg': 0.0895870178937912, 'loss_mask': 0.0006023803725838661, 'loss_objectness': 0.05842924863100052, 'loss_rpn_box_reg': 0.04194514453411102}
  Batch [620/1526] Loss: 0.4160 Components: {'loss_classifier': 0.12364048510789871, 'loss_box_reg': 0.13134390115737915, 'loss_mask': 0.10802742838859558, 'loss_objectness': 0.03377489745616913, 'loss_rpn_box_reg': 0.01917247101664543}
  Batch [760/1526] Loss: 0.6297 Components: {'loss_classifier': 0.16965526342391968, 'loss_box_reg': 0.05889356508851051, 'loss_mask': 0.023184429854154587, 'loss_objectness': 0.149147629737854, 'loss_rpn_box_reg': 0.2287990003824234}
  Batch [780/1526] Loss: 0.2190 Components: {'loss_classifier': 0.07335734367370605, 'loss_box_reg': 0.03419290855526924, 'loss_mask': 0.0077553801238536835, 'loss_objectness': 0.08843833208084106, 'loss_rpn_box_reg': 0.01525832712650299}
  Batch [800/1526] Loss: 0.5139 Components: {'loss_classifier': 0.18475095927715302, 'loss_box_reg': 0.2699227035045624, 'loss_mask': 0.006369014736264944, 'loss_objectness': 0.03488999977707863, 'loss_rpn_box_reg': 0.017925674095749855}
  Batch [810/1526] Loss: 0.2986 Components: {'loss_classifier': 0.08649640530347824, 'loss_box_reg': 0.043749090284109116, 'loss_mask': 0.0941140279173851, 'loss_objectness': 0.06831395626068115, 'loss_rpn_box_reg': 0.00594264967367053}
  Batch [820/1526] Loss: 0.2434 Components: {'loss_classifier': 0.06089332699775696, 'loss_box_reg': 0.05705671384930611, 'loss_mask': 0.08747043460607529, 'loss_objectness': 0.029523940756917, 'loss_rpn_box_reg': 0.008413787931203842}
  Batch [920/1526] Loss: 0.9864 Components: {'loss_classifier': 0.37725260853767395, 'loss_box_reg': 0.5164107084274292, 'loss_mask': 0.03701171651482582, 'loss_objectness': 0.0379040502011776, 'loss_rpn_box_reg': 0.017847763374447823}
  Batch [990/1526] Loss: 0.9113 Components: {'loss_classifier': 0.3493638336658478, 'loss_box_reg': 0.39253324270248413, 'loss_mask': 0.07346861064434052, 'loss_objectness': 0.06563965976238251, 'loss_rpn_box_reg': 0.03028513863682747}
  Batch [1010/1526] Loss: 0.3686 Components: {'loss_classifier': 0.16527822613716125, 'loss_box_reg': 0.10355819761753082, 'loss_mask': 0.00758335180580616, 'loss_objectness': 0.060534339398145676, 'loss_rpn_box_reg': 0.031637489795684814}
  Batch [1030/1526] Loss: 0.8036 Components: {'loss_classifier': 0.34202080965042114, 'loss_box_reg': 0.32166972756385803, 'loss_mask': 0.008228270336985588, 'loss_objectness': 0.09876126050949097, 'loss_rpn_box_reg': 0.0329168476164341}
  Batch [1060/1526] Loss: 0.4790 Components: {'loss_classifier': 0.2599017322063446, 'loss_box_reg': 0.15901046991348267, 'loss_mask': 6.891216617077589e-05, 'loss_objectness': 0.04681072756648064, 'loss_rpn_box_reg': 0.013235717080533504}
  Batch [1140/1526] Loss: 0.4368 Components: {'loss_classifier': 0.20186439156532288, 'loss_box_reg': 0.1387287974357605, 'loss_mask': 0.003974612336605787, 'loss_objectness': 0.0712662786245346, 'loss_rpn_box_reg': 0.020967816933989525}
  Batch [1150/1526] Loss: 0.4964 Components: {'loss_classifier': 0.18708382546901703, 'loss_box_reg': 0.2068779170513153, 'loss_mask': 0.07309802621603012, 'loss_objectness': 0.020555077120661736, 'loss_rpn_box_reg': 0.008826155215501785}
  Batch [1210/1526] Loss: 0.7320 Components: {'loss_classifier': 0.23643526434898376, 'loss_box_reg': 0.23946140706539154, 'loss_mask': 0.13305015861988068, 'loss_objectness': 0.06341297179460526, 'loss_rpn_box_reg': 0.059668343514204025}
  Batch [1220/1526] Loss: 0.6871 Components: {'loss_classifier': 0.22872357070446014, 'loss_box_reg': 0.2878965735435486, 'loss_mask': 0.07678569853305817, 'loss_objectness': 0.06535116583108902, 'loss_rpn_box_reg': 0.02832442708313465}
  Batch [1240/1526] Loss: 0.4519 Components: {'loss_classifier': 0.16174542903900146, 'loss_box_reg': 0.15367454290390015, 'loss_mask': 0.09851007908582687, 'loss_objectness': 0.030171459540724754, 'loss_rpn_box_reg': 0.007840787060558796}
  Batch [1250/1526] Loss: 0.3157 Components: {'loss_classifier': 0.14635467529296875, 'loss_box_reg': 0.06945405900478363, 'loss_mask': 0.00011539142724359408, 'loss_objectness': 0.05129901319742203, 'loss_rpn_box_reg': 0.04846950247883797}
  Batch [1280/1526] Loss: 0.1843 Components: {'loss_classifier': 0.07466533780097961, 'loss_box_reg': 0.03627725690603256, 'loss_mask': 0.037869490683078766, 'loss_objectness': 0.031235814094543457, 'loss_rpn_box_reg': 0.004294780548661947}
  Batch [1390/1526] Loss: 0.3173 Components: {'loss_classifier': 0.11602932214736938, 'loss_box_reg': 0.06859701871871948, 'loss_mask': 0.0002370231377426535, 'loss_objectness': 0.07419442385435104, 'loss_rpn_box_reg': 0.05825604498386383}
  Batch [1420/1526] Loss: 0.6171 Components: {'loss_classifier': 0.14012199640274048, 'loss_box_reg': 0.09488455951213837, 'loss_mask': 0.059365496039390564, 'loss_objectness': 0.15453718602657318, 'loss_rpn_box_reg': 0.1682107150554657}
  Batch [1500/1526] Loss: 0.9826 Components: {'loss_classifier': 0.29488325119018555, 'loss_box_reg': 0.03481132537126541, 'loss_mask': 0.0003905766934622079, 'loss_objectness': 0.2685723602771759, 'loss_rpn_box_reg': 0.3839000463485718}

Epoch 20 Summary:
  Train Loss: 1.1450
  Val Loss: 1.4676
  Learning Rate: 0.002000
  Epoch Time: 2692.4s
  EarlyStopping counter: 1 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 21/100
----------------------------------------
  Batch [70/1526] Loss: 0.2417 Components: {'loss_classifier': 0.1014600396156311, 'loss_box_reg': 0.09897606819868088, 'loss_mask': 0.0013480541529133916, 'loss_objectness': 0.027190320193767548, 'loss_rpn_box_reg': 0.012679104693233967}
  Batch [80/1526] Loss: 0.9208 Components: {'loss_classifier': 0.2921215891838074, 'loss_box_reg': 0.49726611375808716, 'loss_mask': 0.05569221451878548, 'loss_objectness': 0.043478257954120636, 'loss_rpn_box_reg': 0.032227762043476105}
  Batch [280/1526] Loss: 0.4543 Components: {'loss_classifier': 0.2042597234249115, 'loss_box_reg': 0.14509861171245575, 'loss_mask': 0.030558614060282707, 'loss_objectness': 0.040949612855911255, 'loss_rpn_box_reg': 0.03341313451528549}
  Batch [320/1526] Loss: 1.1357 Components: {'loss_classifier': 0.4234870672225952, 'loss_box_reg': 0.5997456312179565, 'loss_mask': 0.005453596357256174, 'loss_objectness': 0.05065386742353439, 'loss_rpn_box_reg': 0.056330710649490356}
  Batch [330/1526] Loss: 0.7391 Components: {'loss_classifier': 0.22439517080783844, 'loss_box_reg': 0.14400441944599152, 'loss_mask': 0.000940027239266783, 'loss_objectness': 0.025545813143253326, 'loss_rpn_box_reg': 0.3442421853542328}
  Batch [370/1526] Loss: 0.4662 Components: {'loss_classifier': 0.2428998202085495, 'loss_box_reg': 0.16585218906402588, 'loss_mask': 0.0004675957025028765, 'loss_objectness': 0.03889825567603111, 'loss_rpn_box_reg': 0.018038377165794373}
  Batch [400/1526] Loss: 0.4635 Components: {'loss_classifier': 0.17966331541538239, 'loss_box_reg': 0.205681711435318, 'loss_mask': 0.01648125983774662, 'loss_objectness': 0.049582596868276596, 'loss_rpn_box_reg': 0.01210290938615799}
  Batch [420/1526] Loss: 0.4617 Components: {'loss_classifier': 0.12080241739749908, 'loss_box_reg': 0.05390453338623047, 'loss_mask': 0.039783041924238205, 'loss_objectness': 0.03825649619102478, 'loss_rpn_box_reg': 0.2089119404554367}
  Batch [460/1526] Loss: 0.3963 Components: {'loss_classifier': 0.17481201887130737, 'loss_box_reg': 0.15858499705791473, 'loss_mask': 0.003472785232588649, 'loss_objectness': 0.03654750436544418, 'loss_rpn_box_reg': 0.022874023765325546}
  Batch [480/1526] Loss: 0.8491 Components: {'loss_classifier': 0.3380001187324524, 'loss_box_reg': 0.33442753553390503, 'loss_mask': 0.0514945425093174, 'loss_objectness': 0.08324006199836731, 'loss_rpn_box_reg': 0.041947536170482635}
  Batch [520/1526] Loss: 0.6525 Components: {'loss_classifier': 0.16680923104286194, 'loss_box_reg': 0.3262839615345001, 'loss_mask': 0.09257879108190536, 'loss_objectness': 0.055313434451818466, 'loss_rpn_box_reg': 0.011561105959117413}
  Batch [620/1526] Loss: 0.7477 Components: {'loss_classifier': 0.27362585067749023, 'loss_box_reg': 0.28428125381469727, 'loss_mask': 0.09448064118623734, 'loss_objectness': 0.06548982113599777, 'loss_rpn_box_reg': 0.029843155294656754}
  Batch [650/1526] Loss: 0.4755 Components: {'loss_classifier': 0.12856891751289368, 'loss_box_reg': 0.052590660750865936, 'loss_mask': 0.0017032223986461759, 'loss_objectness': 0.13360589742660522, 'loss_rpn_box_reg': 0.1590101569890976}
  Batch [710/1526] Loss: 0.6530 Components: {'loss_classifier': 0.19943012297153473, 'loss_box_reg': 0.3102889358997345, 'loss_mask': 0.06247498467564583, 'loss_objectness': 0.04912963882088661, 'loss_rpn_box_reg': 0.031700510531663895}
  Batch [720/1526] Loss: 0.4780 Components: {'loss_classifier': 0.11979864537715912, 'loss_box_reg': 0.17930909991264343, 'loss_mask': 0.06580240279436111, 'loss_objectness': 0.06840753555297852, 'loss_rpn_box_reg': 0.0446523018181324}
  Batch [730/1526] Loss: 0.6603 Components: {'loss_classifier': 0.16255085170269012, 'loss_box_reg': 0.2006525993347168, 'loss_mask': 0.12433351576328278, 'loss_objectness': 0.06482214480638504, 'loss_rpn_box_reg': 0.10796962678432465}
  Batch [870/1526] Loss: 0.6236 Components: {'loss_classifier': 0.2983163297176361, 'loss_box_reg': 0.2177351713180542, 'loss_mask': 0.00026394406449981034, 'loss_objectness': 0.0863807275891304, 'loss_rpn_box_reg': 0.020907390862703323}
  Batch [890/1526] Loss: 0.9558 Components: {'loss_classifier': 0.2568201720714569, 'loss_box_reg': 0.22584643959999084, 'loss_mask': 0.038464684039354324, 'loss_objectness': 0.30097541213035583, 'loss_rpn_box_reg': 0.13371481001377106}
  Batch [910/1526] Loss: 0.4590 Components: {'loss_classifier': 0.18001997470855713, 'loss_box_reg': 0.10734135657548904, 'loss_mask': 0.015889577567577362, 'loss_objectness': 0.021545497700572014, 'loss_rpn_box_reg': 0.13418090343475342}
  Batch [970/1526] Loss: 0.3505 Components: {'loss_classifier': 0.16011157631874084, 'loss_box_reg': 0.09319329261779785, 'loss_mask': 0.03188658878207207, 'loss_objectness': 0.03713004291057587, 'loss_rpn_box_reg': 0.028218969702720642}
  Batch [1020/1526] Loss: 17.2036 Components: {'loss_classifier': 0.17449839413166046, 'loss_box_reg': 0.11581336706876755, 'loss_mask': 0.040934007614851, 'loss_objectness': 2.413834810256958, 'loss_rpn_box_reg': 14.45853328704834}
  Batch [1040/1526] Loss: 1.0133 Components: {'loss_classifier': 0.36600226163864136, 'loss_box_reg': 0.480535089969635, 'loss_mask': 0.05916205421090126, 'loss_objectness': 0.08594108372926712, 'loss_rpn_box_reg': 0.0217004232108593}
  Batch [1130/1526] Loss: 0.6847 Components: {'loss_classifier': 0.2453908771276474, 'loss_box_reg': 0.09695209562778473, 'loss_mask': 0.008766223676502705, 'loss_objectness': 0.16559262573719025, 'loss_rpn_box_reg': 0.16800633072853088}
  Batch [1210/1526] Loss: 0.3175 Components: {'loss_classifier': 0.1306791603565216, 'loss_box_reg': 0.14943183958530426, 'loss_mask': 0.0016957393381744623, 'loss_objectness': 0.02227688394486904, 'loss_rpn_box_reg': 0.013443047180771828}
  Batch [1340/1526] Loss: 1.6173 Components: {'loss_classifier': 0.5372503399848938, 'loss_box_reg': 0.6035715937614441, 'loss_mask': 0.0010895720915868878, 'loss_objectness': 0.1482923924922943, 'loss_rpn_box_reg': 0.32713931798934937}
  Batch [1390/1526] Loss: 0.8372 Components: {'loss_classifier': 0.2325475662946701, 'loss_box_reg': 0.3028591275215149, 'loss_mask': 0.257118821144104, 'loss_objectness': 0.03194066137075424, 'loss_rpn_box_reg': 0.012776232324540615}
  Batch [1480/1526] Loss: 0.6636 Components: {'loss_classifier': 0.2657429873943329, 'loss_box_reg': 0.2298053354024887, 'loss_mask': 0.0011757913744077086, 'loss_objectness': 0.07690625637769699, 'loss_rpn_box_reg': 0.08999142795801163}
  Batch [1500/1526] Loss: 0.5035 Components: {'loss_classifier': 0.23096340894699097, 'loss_box_reg': 0.17891307175159454, 'loss_mask': 0.0003090416139457375, 'loss_objectness': 0.06897225230932236, 'loss_rpn_box_reg': 0.0243705864995718}

Epoch 21 Summary:
  Train Loss: 0.9175
  Val Loss: 1.6014
  Learning Rate: 0.002000
  Epoch Time: 2536.3s
  EarlyStopping counter: 2 out of 15

Epoch 22/100
----------------------------------------
  Batch [20/1526] Loss: 0.2392 Components: {'loss_classifier': 0.0856684073805809, 'loss_box_reg': 0.0814957469701767, 'loss_mask': 0.03038177639245987, 'loss_objectness': 0.013485243543982506, 'loss_rpn_box_reg': 0.028202056884765625}
  Batch [210/1526] Loss: 0.4020 Components: {'loss_classifier': 0.16636957228183746, 'loss_box_reg': 0.178169384598732, 'loss_mask': 0.032003991305828094, 'loss_objectness': 0.014721913263201714, 'loss_rpn_box_reg': 0.010716329328715801}
  Batch [220/1526] Loss: 0.8733 Components: {'loss_classifier': 0.3583865165710449, 'loss_box_reg': 0.327384352684021, 'loss_mask': 0.012899688445031643, 'loss_objectness': 0.0619581937789917, 'loss_rpn_box_reg': 0.11263897269964218}
  Batch [260/1526] Loss: 0.6467 Components: {'loss_classifier': 0.2732396423816681, 'loss_box_reg': 0.31126669049263, 'loss_mask': 0.008204678073525429, 'loss_objectness': 0.032955363392829895, 'loss_rpn_box_reg': 0.021040162071585655}
  Batch [280/1526] Loss: 0.1758 Components: {'loss_classifier': 0.09854526817798615, 'loss_box_reg': 0.043808095157146454, 'loss_mask': 0.0015988543163985014, 'loss_objectness': 0.02443774603307247, 'loss_rpn_box_reg': 0.007395356893539429}
  Batch [290/1526] Loss: 0.6761 Components: {'loss_classifier': 0.20686359703540802, 'loss_box_reg': 0.10850463807582855, 'loss_mask': 0.0014646295458078384, 'loss_objectness': 0.26159265637397766, 'loss_rpn_box_reg': 0.09768180549144745}
  Batch [410/1526] Loss: 0.3066 Components: {'loss_classifier': 0.0800933912396431, 'loss_box_reg': 0.1008162572979927, 'loss_mask': 0.06878514587879181, 'loss_objectness': 0.022339949384331703, 'loss_rpn_box_reg': 0.03459963947534561}
  Batch [430/1526] Loss: 0.7938 Components: {'loss_classifier': 0.24266329407691956, 'loss_box_reg': 0.3148316442966461, 'loss_mask': 0.17752322554588318, 'loss_objectness': 0.03677145391702652, 'loss_rpn_box_reg': 0.022021818906068802}
  Batch [520/1526] Loss: 0.5598 Components: {'loss_classifier': 0.2805987000465393, 'loss_box_reg': 0.213779017329216, 'loss_mask': 0.01683185063302517, 'loss_objectness': 0.03229130804538727, 'loss_rpn_box_reg': 0.016293151304125786}
  Batch [610/1526] Loss: 0.1745 Components: {'loss_classifier': 0.07210304588079453, 'loss_box_reg': 0.03109245002269745, 'loss_mask': 0.00349314883351326, 'loss_objectness': 0.059628359973430634, 'loss_rpn_box_reg': 0.008201112039387226}
  Batch [640/1526] Loss: 0.3389 Components: {'loss_classifier': 0.14244255423545837, 'loss_box_reg': 0.11435933411121368, 'loss_mask': 8.164077007677406e-05, 'loss_objectness': 0.07303722202777863, 'loss_rpn_box_reg': 0.008938414044678211}
  Batch [650/1526] Loss: 0.5791 Components: {'loss_classifier': 0.12546363472938538, 'loss_box_reg': 0.05287725850939751, 'loss_mask': 0.03802192583680153, 'loss_objectness': 0.15347594022750854, 'loss_rpn_box_reg': 0.20924679934978485}
  Batch [750/1526] Loss: 0.3728 Components: {'loss_classifier': 0.14482754468917847, 'loss_box_reg': 0.10361029207706451, 'loss_mask': 0.0039876955561339855, 'loss_objectness': 0.1010906845331192, 'loss_rpn_box_reg': 0.019292496144771576}
  Batch [770/1526] Loss: 0.3566 Components: {'loss_classifier': 0.16329804062843323, 'loss_box_reg': 0.1440524160861969, 'loss_mask': 0.0006580166518688202, 'loss_objectness': 0.04707794636487961, 'loss_rpn_box_reg': 0.0015516960993409157}
  Batch [860/1526] Loss: 0.2660 Components: {'loss_classifier': 0.09069492667913437, 'loss_box_reg': 0.04471294954419136, 'loss_mask': 0.09139594435691833, 'loss_objectness': 0.03381577879190445, 'loss_rpn_box_reg': 0.005370699800550938}
  Batch [880/1526] Loss: 0.5675 Components: {'loss_classifier': 0.20376458764076233, 'loss_box_reg': 0.15030315518379211, 'loss_mask': 0.041340410709381104, 'loss_objectness': 0.0590914785861969, 'loss_rpn_box_reg': 0.11303689330816269}
  Batch [1030/1526] Loss: 0.6974 Components: {'loss_classifier': 0.20756372809410095, 'loss_box_reg': 0.20045876502990723, 'loss_mask': 0.09762570261955261, 'loss_objectness': 0.030002674087882042, 'loss_rpn_box_reg': 0.1617039442062378}
  Batch [1050/1526] Loss: 0.9230 Components: {'loss_classifier': 0.42034533619880676, 'loss_box_reg': 0.39014607667922974, 'loss_mask': 0.000363963539712131, 'loss_objectness': 0.05873991549015045, 'loss_rpn_box_reg': 0.0534205362200737}
  Batch [1060/1526] Loss: 0.6449 Components: {'loss_classifier': 0.22071877121925354, 'loss_box_reg': 0.3135102391242981, 'loss_mask': 0.0808110460639, 'loss_objectness': 0.013239415362477303, 'loss_rpn_box_reg': 0.016649041324853897}
  Batch [1080/1526] Loss: 0.3786 Components: {'loss_classifier': 0.12042445689439774, 'loss_box_reg': 0.1212826520204544, 'loss_mask': 0.11453530192375183, 'loss_objectness': 0.01876845955848694, 'loss_rpn_box_reg': 0.003607675898820162}
  Batch [1090/1526] Loss: 0.2430 Components: {'loss_classifier': 0.0985066145658493, 'loss_box_reg': 0.10183943808078766, 'loss_mask': 0.014592443592846394, 'loss_objectness': 0.018258187919855118, 'loss_rpn_box_reg': 0.009779063984751701}
  Batch [1160/1526] Loss: 0.6731 Components: {'loss_classifier': 0.2615286111831665, 'loss_box_reg': 0.13811653852462769, 'loss_mask': 0.00043826710316352546, 'loss_objectness': 0.12617191672325134, 'loss_rpn_box_reg': 0.14680643379688263}
  Batch [1200/1526] Loss: 0.4368 Components: {'loss_classifier': 0.17348958551883698, 'loss_box_reg': 0.2123648226261139, 'loss_mask': 0.018033945932984352, 'loss_objectness': 0.020862340927124023, 'loss_rpn_box_reg': 0.012032397091388702}
  Batch [1210/1526] Loss: 0.6790 Components: {'loss_classifier': 0.25774675607681274, 'loss_box_reg': 0.3647604286670685, 'loss_mask': 0.0013419648166745901, 'loss_objectness': 0.0396069660782814, 'loss_rpn_box_reg': 0.015567782334983349}
  Batch [1220/1526] Loss: 1.0915 Components: {'loss_classifier': 0.3946298360824585, 'loss_box_reg': 0.4732467532157898, 'loss_mask': 0.05163272097706795, 'loss_objectness': 0.10451824963092804, 'loss_rpn_box_reg': 0.06745151430368423}
  Batch [1240/1526] Loss: 0.6103 Components: {'loss_classifier': 0.19202564656734467, 'loss_box_reg': 0.19969995319843292, 'loss_mask': 0.10270567983388901, 'loss_objectness': 0.09273359179496765, 'loss_rpn_box_reg': 0.023105420172214508}
  Batch [1310/1526] Loss: 0.3096 Components: {'loss_classifier': 0.18204158544540405, 'loss_box_reg': 0.09111867100000381, 'loss_mask': 0.010371345095336437, 'loss_objectness': 0.023856064304709435, 'loss_rpn_box_reg': 0.002203932963311672}
  Batch [1340/1526] Loss: 1.3094 Components: {'loss_classifier': 0.4642239511013031, 'loss_box_reg': 0.20586314797401428, 'loss_mask': 0.007410238962620497, 'loss_objectness': 0.20737244188785553, 'loss_rpn_box_reg': 0.4245253801345825}
  Batch [1410/1526] Loss: 0.2631 Components: {'loss_classifier': 0.13334287703037262, 'loss_box_reg': 0.09586881846189499, 'loss_mask': 0.004635765217244625, 'loss_objectness': 0.02542107179760933, 'loss_rpn_box_reg': 0.003839536802843213}
  Batch [1440/1526] Loss: 1.0085 Components: {'loss_classifier': 0.40732184052467346, 'loss_box_reg': 0.4389830231666565, 'loss_mask': 0.002405632520094514, 'loss_objectness': 0.1000833809375763, 'loss_rpn_box_reg': 0.05971634387969971}
  Batch [1480/1526] Loss: 0.4621 Components: {'loss_classifier': 0.2211635708808899, 'loss_box_reg': 0.14936287701129913, 'loss_mask': 0.0009180086781270802, 'loss_objectness': 0.05057494714856148, 'loss_rpn_box_reg': 0.040073640644550323}

Epoch 22 Summary:
  Train Loss: 1.0428
  Val Loss: 1.5976
  Learning Rate: 0.002000
  Epoch Time: 2663.6s
  EarlyStopping counter: 3 out of 15

Epoch 23/100
----------------------------------------
  Batch [0/1526] Loss: 0.2695 Components: {'loss_classifier': 0.12090911716222763, 'loss_box_reg': 0.08437762409448624, 'loss_mask': 0.0002051336778094992, 'loss_objectness': 0.04697543755173683, 'loss_rpn_box_reg': 0.0170659888535738}
  Batch [10/1526] Loss: 0.6788 Components: {'loss_classifier': 0.286105215549469, 'loss_box_reg': 0.28507789969444275, 'loss_mask': 0.004968492314219475, 'loss_objectness': 0.057268328964710236, 'loss_rpn_box_reg': 0.04537779092788696}
  Batch [30/1526] Loss: 0.8367 Components: {'loss_classifier': 0.3328639566898346, 'loss_box_reg': 0.2552723288536072, 'loss_mask': 0.14317741990089417, 'loss_objectness': 0.05051258206367493, 'loss_rpn_box_reg': 0.054874978959560394}
  Batch [90/1526] Loss: 0.6346 Components: {'loss_classifier': 0.21442967653274536, 'loss_box_reg': 0.36842554807662964, 'loss_mask': 0.012792469002306461, 'loss_objectness': 0.020044999197125435, 'loss_rpn_box_reg': 0.018954629078507423}
  Batch [160/1526] Loss: 0.7548 Components: {'loss_classifier': 0.19288784265518188, 'loss_box_reg': 0.2865786552429199, 'loss_mask': 0.2472488135099411, 'loss_objectness': 0.017518237233161926, 'loss_rpn_box_reg': 0.010550345294177532}
  Batch [190/1526] Loss: 0.6749 Components: {'loss_classifier': 0.21738263964653015, 'loss_box_reg': 0.318109929561615, 'loss_mask': 0.0996377244591713, 'loss_objectness': 0.028054330497980118, 'loss_rpn_box_reg': 0.011733371764421463}
  Batch [240/1526] Loss: 1.4814 Components: {'loss_classifier': 0.5288286209106445, 'loss_box_reg': 0.466337114572525, 'loss_mask': 0.0005533376825042069, 'loss_objectness': 0.20238913595676422, 'loss_rpn_box_reg': 0.2833085060119629}
  Batch [250/1526] Loss: 0.6647 Components: {'loss_classifier': 0.1875375509262085, 'loss_box_reg': 0.2999207079410553, 'loss_mask': 0.12243570387363434, 'loss_objectness': 0.04185996577143669, 'loss_rpn_box_reg': 0.012923075817525387}
  Batch [260/1526] Loss: 0.1642 Components: {'loss_classifier': 0.05812236666679382, 'loss_box_reg': 0.0644068568944931, 'loss_mask': 0.010812086053192616, 'loss_objectness': 0.018705129623413086, 'loss_rpn_box_reg': 0.012153413146734238}
  Batch [270/1526] Loss: 0.3571 Components: {'loss_classifier': 0.12114502489566803, 'loss_box_reg': 0.12490268796682358, 'loss_mask': 0.030391842126846313, 'loss_objectness': 0.07409732043743134, 'loss_rpn_box_reg': 0.0065860440954566}
  Batch [410/1526] Loss: 0.4224 Components: {'loss_classifier': 0.20965994894504547, 'loss_box_reg': 0.12467780709266663, 'loss_mask': 0.04584818333387375, 'loss_objectness': 0.02031021937727928, 'loss_rpn_box_reg': 0.021903568878769875}
  Batch [470/1526] Loss: 0.2899 Components: {'loss_classifier': 0.10781004279851913, 'loss_box_reg': 0.06341029703617096, 'loss_mask': 0.010532194748520851, 'loss_objectness': 0.04750371351838112, 'loss_rpn_box_reg': 0.06065453961491585}
  Batch [520/1526] Loss: 0.7151 Components: {'loss_classifier': 0.19038183987140656, 'loss_box_reg': 0.3566564917564392, 'loss_mask': 0.144171804189682, 'loss_objectness': 0.009833315387368202, 'loss_rpn_box_reg': 0.014055050909519196}
  Batch [580/1526] Loss: 0.2153 Components: {'loss_classifier': 0.0893050953745842, 'loss_box_reg': 0.11672088503837585, 'loss_mask': 9.135940490523353e-05, 'loss_objectness': 0.007121667265892029, 'loss_rpn_box_reg': 0.0020607116166502237}
  Batch [590/1526] Loss: 1.4039 Components: {'loss_classifier': 0.36274412274360657, 'loss_box_reg': 0.46649789810180664, 'loss_mask': 0.43077757954597473, 'loss_objectness': 0.06903424859046936, 'loss_rpn_box_reg': 0.07488515973091125}
  Batch [640/1526] Loss: 0.3569 Components: {'loss_classifier': 0.030538953840732574, 'loss_box_reg': 0.0129921929910779, 'loss_mask': 9.108331869356334e-05, 'loss_objectness': 0.035644348710775375, 'loss_rpn_box_reg': 0.277665913105011}
  Batch [770/1526] Loss: 0.4860 Components: {'loss_classifier': 0.208526611328125, 'loss_box_reg': 0.2109045386314392, 'loss_mask': 0.002862843917682767, 'loss_objectness': 0.04984143376350403, 'loss_rpn_box_reg': 0.013824168592691422}
  Batch [840/1526] Loss: 10.0071 Components: {'loss_classifier': 0.24258461594581604, 'loss_box_reg': 0.043703071773052216, 'loss_mask': 0.0018694993341341615, 'loss_objectness': 0.8101392388343811, 'loss_rpn_box_reg': 8.90885066986084}
  Batch [920/1526] Loss: 0.3191 Components: {'loss_classifier': 0.15508228540420532, 'loss_box_reg': 0.13251204788684845, 'loss_mask': 0.0005118254339322448, 'loss_objectness': 0.025742920115590096, 'loss_rpn_box_reg': 0.005281792487949133}
  Batch [950/1526] Loss: 0.4146 Components: {'loss_classifier': 0.11610553413629532, 'loss_box_reg': 0.09482987970113754, 'loss_mask': 0.1326064169406891, 'loss_objectness': 0.05139055848121643, 'loss_rpn_box_reg': 0.019668204709887505}
  Batch [970/1526] Loss: 4.7286 Components: {'loss_classifier': 0.23537592589855194, 'loss_box_reg': 0.05945706367492676, 'loss_mask': 0.004302334040403366, 'loss_objectness': 0.7958934307098389, 'loss_rpn_box_reg': 3.6335642337799072}
  Batch [980/1526] Loss: 5.8395 Components: {'loss_classifier': 0.07582952082157135, 'loss_box_reg': 0.030937254428863525, 'loss_mask': 0.05098157376050949, 'loss_objectness': 0.46701955795288086, 'loss_rpn_box_reg': 5.21474027633667}
  Batch [990/1526] Loss: 1.2119 Components: {'loss_classifier': 0.24298028647899628, 'loss_box_reg': 0.22537624835968018, 'loss_mask': 0.05786633864045143, 'loss_objectness': 0.5660651326179504, 'loss_rpn_box_reg': 0.1195715144276619}
  Batch [1030/1526] Loss: 0.4756 Components: {'loss_classifier': 0.1876526176929474, 'loss_box_reg': 0.22895550727844238, 'loss_mask': 0.007137388456612825, 'loss_objectness': 0.029456274583935738, 'loss_rpn_box_reg': 0.02241402119398117}
  Batch [1200/1526] Loss: 0.9364 Components: {'loss_classifier': 0.4049414098262787, 'loss_box_reg': 0.2799919545650482, 'loss_mask': 0.00022089103003963828, 'loss_objectness': 0.07652077078819275, 'loss_rpn_box_reg': 0.17476090788841248}

Epoch 23 Summary:
  Train Loss: 1.1399
  Val Loss: 1.5169
  Learning Rate: 0.002000
  Epoch Time: 2673.3s
  EarlyStopping counter: 4 out of 15

Epoch 24/100
----------------------------------------
  Batch [10/1526] Loss: 0.5635 Components: {'loss_classifier': 0.28962036967277527, 'loss_box_reg': 0.1741444319486618, 'loss_mask': 0.0016487857792526484, 'loss_objectness': 0.06661859154701233, 'loss_rpn_box_reg': 0.031512301415205}
  Batch [80/1526] Loss: 1.1514 Components: {'loss_classifier': 0.43298211693763733, 'loss_box_reg': 0.47778114676475525, 'loss_mask': 0.06992018967866898, 'loss_objectness': 0.08857517689466476, 'loss_rpn_box_reg': 0.0821206271648407}
  Batch [180/1526] Loss: 0.4869 Components: {'loss_classifier': 0.08746124058961868, 'loss_box_reg': 0.16643638908863068, 'loss_mask': 0.08830489963293076, 'loss_objectness': 0.0646214634180069, 'loss_rpn_box_reg': 0.08005937933921814}
  Batch [190/1526] Loss: 0.4240 Components: {'loss_classifier': 0.16405799984931946, 'loss_box_reg': 0.1313357651233673, 'loss_mask': 0.0013530843425542116, 'loss_objectness': 0.039830103516578674, 'loss_rpn_box_reg': 0.08737857639789581}
  Batch [200/1526] Loss: 0.9123 Components: {'loss_classifier': 0.4058331251144409, 'loss_box_reg': 0.33228549361228943, 'loss_mask': 5.2857962145935744e-05, 'loss_objectness': 0.07907736301422119, 'loss_rpn_box_reg': 0.09501150250434875}
  Batch [350/1526] Loss: 0.4787 Components: {'loss_classifier': 0.16038788855075836, 'loss_box_reg': 0.2494198977947235, 'loss_mask': 0.0383242629468441, 'loss_objectness': 0.023952627554535866, 'loss_rpn_box_reg': 0.006629220210015774}
  Batch [410/1526] Loss: 0.5087 Components: {'loss_classifier': 0.24517199397087097, 'loss_box_reg': 0.18688130378723145, 'loss_mask': 0.007801079656928778, 'loss_objectness': 0.026373952627182007, 'loss_rpn_box_reg': 0.042490966618061066}
  Batch [470/1526] Loss: 0.2314 Components: {'loss_classifier': 0.08948207646608353, 'loss_box_reg': 0.10000744462013245, 'loss_mask': 0.010897224768996239, 'loss_objectness': 0.02757585607469082, 'loss_rpn_box_reg': 0.003417639061808586}
  Batch [500/1526] Loss: 0.8376 Components: {'loss_classifier': 0.30737417936325073, 'loss_box_reg': 0.3953727185726166, 'loss_mask': 0.0008379415376111865, 'loss_objectness': 0.07291078567504883, 'loss_rpn_box_reg': 0.06106265261769295}
  Batch [530/1526] Loss: 0.5195 Components: {'loss_classifier': 0.17808590829372406, 'loss_box_reg': 0.07929132878780365, 'loss_mask': 0.000416800903622061, 'loss_objectness': 0.09953305870294571, 'loss_rpn_box_reg': 0.16216202080249786}
  Batch [610/1526] Loss: 0.5680 Components: {'loss_classifier': 0.23807202279567719, 'loss_box_reg': 0.18350809812545776, 'loss_mask': 0.08673551678657532, 'loss_objectness': 0.048373378813266754, 'loss_rpn_box_reg': 0.011284047737717628}
  Batch [730/1526] Loss: 0.6502 Components: {'loss_classifier': 0.25065529346466064, 'loss_box_reg': 0.33340615034103394, 'loss_mask': 0.016842810437083244, 'loss_objectness': 0.032086193561553955, 'loss_rpn_box_reg': 0.017163772135972977}
  Batch [750/1526] Loss: 0.6535 Components: {'loss_classifier': 0.18235869705677032, 'loss_box_reg': 0.3312118947505951, 'loss_mask': 0.11110406368970871, 'loss_objectness': 0.01818707212805748, 'loss_rpn_box_reg': 0.01062145084142685}
  Batch [830/1526] Loss: 0.9122 Components: {'loss_classifier': 0.19112303853034973, 'loss_box_reg': 0.1507893204689026, 'loss_mask': 0.0011644228361546993, 'loss_objectness': 0.15418803691864014, 'loss_rpn_box_reg': 0.4149478077888489}
  Batch [840/1526] Loss: 0.2927 Components: {'loss_classifier': 0.12119793891906738, 'loss_box_reg': 0.13196982443332672, 'loss_mask': 0.0002458805975038558, 'loss_objectness': 0.019503388553857803, 'loss_rpn_box_reg': 0.01977192983031273}
  Batch [850/1526] Loss: 0.2515 Components: {'loss_classifier': 0.10514756292104721, 'loss_box_reg': 0.10586494952440262, 'loss_mask': 0.0002789379796013236, 'loss_objectness': 0.03650921955704689, 'loss_rpn_box_reg': 0.0037088680546730757}
  Batch [870/1526] Loss: 0.5928 Components: {'loss_classifier': 0.21201232075691223, 'loss_box_reg': 0.2564716935157776, 'loss_mask': 0.07181362062692642, 'loss_objectness': 0.026826435700058937, 'loss_rpn_box_reg': 0.02571733482182026}
  Batch [890/1526] Loss: 0.6670 Components: {'loss_classifier': 0.2478288859128952, 'loss_box_reg': 0.29538682103157043, 'loss_mask': 0.048863936215639114, 'loss_objectness': 0.044912002980709076, 'loss_rpn_box_reg': 0.030010223388671875}
  Batch [920/1526] Loss: 0.6083 Components: {'loss_classifier': 0.2164803296327591, 'loss_box_reg': 0.3256978690624237, 'loss_mask': 0.005279304925352335, 'loss_objectness': 0.039298173040151596, 'loss_rpn_box_reg': 0.02158549800515175}
  Batch [990/1526] Loss: 0.3435 Components: {'loss_classifier': 0.11901984363794327, 'loss_box_reg': 0.16037173569202423, 'loss_mask': 0.0012100297026336193, 'loss_objectness': 0.014539480209350586, 'loss_rpn_box_reg': 0.0483296774327755}
  Batch [1000/1526] Loss: 0.7374 Components: {'loss_classifier': 0.24907232820987701, 'loss_box_reg': 0.2845148742198944, 'loss_mask': 0.06896405667066574, 'loss_objectness': 0.042110320180654526, 'loss_rpn_box_reg': 0.09275393187999725}
  Batch [1180/1526] Loss: 0.4755 Components: {'loss_classifier': 0.13653485476970673, 'loss_box_reg': 0.07107561081647873, 'loss_mask': 0.023365654051303864, 'loss_objectness': 0.060539063066244125, 'loss_rpn_box_reg': 0.18401065468788147}
  Batch [1200/1526] Loss: 0.9848 Components: {'loss_classifier': 0.13168145716190338, 'loss_box_reg': 0.24367326498031616, 'loss_mask': 0.3550635278224945, 'loss_objectness': 0.011623797006905079, 'loss_rpn_box_reg': 0.24278047680854797}
  Batch [1340/1526] Loss: 0.3697 Components: {'loss_classifier': 0.09965893626213074, 'loss_box_reg': 0.1925550103187561, 'loss_mask': 0.054884735494852066, 'loss_objectness': 0.014185136184096336, 'loss_rpn_box_reg': 0.008428948000073433}
  Batch [1450/1526] Loss: 0.5687 Components: {'loss_classifier': 0.16977299749851227, 'loss_box_reg': 0.11628366261720657, 'loss_mask': 0.11992096155881882, 'loss_objectness': 0.13293933868408203, 'loss_rpn_box_reg': 0.029829582199454308}

Epoch 24 Summary:
  Train Loss: 1.0057
  Val Loss: 1.4403
  Learning Rate: 0.002000
  Epoch Time: 2623.6s
  EarlyStopping counter: 5 out of 15

Epoch 25/100
----------------------------------------
  Batch [10/1526] Loss: 0.5914 Components: {'loss_classifier': 0.21209140121936798, 'loss_box_reg': 0.10613417625427246, 'loss_mask': 4.5369666622718796e-05, 'loss_objectness': 0.0467311330139637, 'loss_rpn_box_reg': 0.22635555267333984}
  Batch [40/1526] Loss: 0.5125 Components: {'loss_classifier': 0.2100086808204651, 'loss_box_reg': 0.13468462228775024, 'loss_mask': 6.175564340082929e-05, 'loss_objectness': 0.08846800774335861, 'loss_rpn_box_reg': 0.07924826443195343}
  Batch [50/1526] Loss: 0.3564 Components: {'loss_classifier': 0.14041167497634888, 'loss_box_reg': 0.18119758367538452, 'loss_mask': 0.01696544513106346, 'loss_objectness': 0.009794730693101883, 'loss_rpn_box_reg': 0.008051603101193905}
  Batch [230/1526] Loss: 0.7691 Components: {'loss_classifier': 0.19727686047554016, 'loss_box_reg': 0.24013212323188782, 'loss_mask': 0.23789486289024353, 'loss_objectness': 0.0725070983171463, 'loss_rpn_box_reg': 0.02126176469027996}
  Batch [290/1526] Loss: 0.3594 Components: {'loss_classifier': 0.10420757532119751, 'loss_box_reg': 0.16396808624267578, 'loss_mask': 0.06737925112247467, 'loss_objectness': 0.020018525421619415, 'loss_rpn_box_reg': 0.0038625611923635006}
  Batch [300/1526] Loss: 0.6567 Components: {'loss_classifier': 0.1800166815519333, 'loss_box_reg': 0.3727278411388397, 'loss_mask': 0.07883084565401077, 'loss_objectness': 0.01824856549501419, 'loss_rpn_box_reg': 0.006877539679408073}
  Batch [350/1526] Loss: 0.9850 Components: {'loss_classifier': 0.32210832834243774, 'loss_box_reg': 0.22012531757354736, 'loss_mask': 0.00177067203912884, 'loss_objectness': 0.1911221444606781, 'loss_rpn_box_reg': 0.24982865154743195}
  Batch [390/1526] Loss: 0.8262 Components: {'loss_classifier': 0.2554505169391632, 'loss_box_reg': 0.292543888092041, 'loss_mask': 0.0010963288368657231, 'loss_objectness': 0.03398006036877632, 'loss_rpn_box_reg': 0.2431606948375702}
  Batch [470/1526] Loss: 0.8802 Components: {'loss_classifier': 0.1894921511411667, 'loss_box_reg': 0.11825846135616302, 'loss_mask': 0.0006958358571864665, 'loss_objectness': 0.1919161081314087, 'loss_rpn_box_reg': 0.37981757521629333}
  Batch [480/1526] Loss: 0.6102 Components: {'loss_classifier': 0.19920681416988373, 'loss_box_reg': 0.13755621016025543, 'loss_mask': 0.037261903285980225, 'loss_objectness': 0.08147736638784409, 'loss_rpn_box_reg': 0.15466177463531494}
  Batch [510/1526] Loss: 0.7256 Components: {'loss_classifier': 0.2171880602836609, 'loss_box_reg': 0.16270199418067932, 'loss_mask': 0.12315819412469864, 'loss_objectness': 0.03866881504654884, 'loss_rpn_box_reg': 0.18391376733779907}
  Batch [570/1526] Loss: 0.3109 Components: {'loss_classifier': 0.09844709932804108, 'loss_box_reg': 0.14831766486167908, 'loss_mask': 0.006808522157371044, 'loss_objectness': 0.043237585574388504, 'loss_rpn_box_reg': 0.014088219031691551}
  Batch [650/1526] Loss: 0.6074 Components: {'loss_classifier': 0.23664085566997528, 'loss_box_reg': 0.2162809669971466, 'loss_mask': 0.0011218752479180694, 'loss_objectness': 0.07168465107679367, 'loss_rpn_box_reg': 0.08170235902070999}
  Batch [670/1526] Loss: 0.7945 Components: {'loss_classifier': 0.26501819491386414, 'loss_box_reg': 0.24935023486614227, 'loss_mask': 0.1768478900194168, 'loss_objectness': 0.05918063223361969, 'loss_rpn_box_reg': 0.04414641857147217}
  Batch [730/1526] Loss: 1.0193 Components: {'loss_classifier': 0.39568978548049927, 'loss_box_reg': 0.4036305546760559, 'loss_mask': 0.027662863954901695, 'loss_objectness': 0.08675078302621841, 'loss_rpn_box_reg': 0.10555306822061539}
  Batch [760/1526] Loss: 0.6097 Components: {'loss_classifier': 0.14652861654758453, 'loss_box_reg': 0.08494255691766739, 'loss_mask': 0.0020143534056842327, 'loss_objectness': 0.20134758949279785, 'loss_rpn_box_reg': 0.17485104501247406}
  Batch [840/1526] Loss: 8.0910 Components: {'loss_classifier': 0.03403102234005928, 'loss_box_reg': 0.0007180880638770759, 'loss_mask': 0.00751197524368763, 'loss_objectness': 0.8409662246704102, 'loss_rpn_box_reg': 7.207765102386475}
  Batch [860/1526] Loss: 0.7858 Components: {'loss_classifier': 0.33449870347976685, 'loss_box_reg': 0.17366576194763184, 'loss_mask': 0.00012618975597433746, 'loss_objectness': 0.09408476203680038, 'loss_rpn_box_reg': 0.1833893060684204}
  Batch [890/1526] Loss: 1.0093 Components: {'loss_classifier': 0.4148714244365692, 'loss_box_reg': 0.20517215132713318, 'loss_mask': 0.0001110667799366638, 'loss_objectness': 0.1795966774225235, 'loss_rpn_box_reg': 0.20957909524440765}
  Batch [900/1526] Loss: 0.8943 Components: {'loss_classifier': 0.2806096076965332, 'loss_box_reg': 0.36384180188179016, 'loss_mask': 0.020017273724079132, 'loss_objectness': 0.10777497291564941, 'loss_rpn_box_reg': 0.12203232944011688}
  Batch [930/1526] Loss: 0.4507 Components: {'loss_classifier': 0.15243229269981384, 'loss_box_reg': 0.26463186740875244, 'loss_mask': 0.021544072777032852, 'loss_objectness': 0.004190134350210428, 'loss_rpn_box_reg': 0.007864282466471195}
  Batch [990/1526] Loss: 0.3190 Components: {'loss_classifier': 0.06768187880516052, 'loss_box_reg': 0.12310368567705154, 'loss_mask': 0.1086302399635315, 'loss_objectness': 0.0152083495631814, 'loss_rpn_box_reg': 0.004382582381367683}
  Batch [1060/1526] Loss: 5.6065 Components: {'loss_classifier': 0.1813705414533615, 'loss_box_reg': 0.06675901263952255, 'loss_mask': 0.007363935932517052, 'loss_objectness': 1.0770691633224487, 'loss_rpn_box_reg': 4.273963928222656}
  Batch [1120/1526] Loss: 0.6952 Components: {'loss_classifier': 0.2636568546295166, 'loss_box_reg': 0.2594669759273529, 'loss_mask': 0.1233525276184082, 'loss_objectness': 0.03415288031101227, 'loss_rpn_box_reg': 0.014554224908351898}
  Batch [1150/1526] Loss: 0.3162 Components: {'loss_classifier': 0.1072676032781601, 'loss_box_reg': 0.14562615752220154, 'loss_mask': 0.025123244151473045, 'loss_objectness': 0.024314582347869873, 'loss_rpn_box_reg': 0.013880077749490738}
  Batch [1160/1526] Loss: 0.2243 Components: {'loss_classifier': 0.049718793481588364, 'loss_box_reg': 0.06338930130004883, 'loss_mask': 0.05242127925157547, 'loss_objectness': 0.011774638667702675, 'loss_rpn_box_reg': 0.0469575896859169}
  Batch [1320/1526] Loss: 1.0274 Components: {'loss_classifier': 0.33154621720314026, 'loss_box_reg': 0.544198215007782, 'loss_mask': 0.06276721507310867, 'loss_objectness': 0.04240727797150612, 'loss_rpn_box_reg': 0.04650931805372238}
  Batch [1360/1526] Loss: 0.6028 Components: {'loss_classifier': 0.2742277681827545, 'loss_box_reg': 0.27589845657348633, 'loss_mask': 0.0005579196149483323, 'loss_objectness': 0.02867027372121811, 'loss_rpn_box_reg': 0.02342308685183525}
  Batch [1520/1526] Loss: 0.3115 Components: {'loss_classifier': 0.13785335421562195, 'loss_box_reg': 0.1286885142326355, 'loss_mask': 0.002582205692306161, 'loss_objectness': 0.021571611985564232, 'loss_rpn_box_reg': 0.020779965445399284}

Epoch 25 Summary:
  Train Loss: 1.0878
  Val Loss: 1.6691
  Learning Rate: 0.001000
  Epoch Time: 2622.5s
  EarlyStopping counter: 6 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 26/100
----------------------------------------
  Batch [80/1526] Loss: 0.6805 Components: {'loss_classifier': 0.22218133509159088, 'loss_box_reg': 0.09587599337100983, 'loss_mask': 0.0009105452918447554, 'loss_objectness': 0.17073148488998413, 'loss_rpn_box_reg': 0.19078542292118073}
  Batch [90/1526] Loss: 0.3372 Components: {'loss_classifier': 0.14339138567447662, 'loss_box_reg': 0.11922278255224228, 'loss_mask': 6.44736792310141e-05, 'loss_objectness': 0.06078827753663063, 'loss_rpn_box_reg': 0.013749725185334682}
  Batch [100/1526] Loss: 0.2163 Components: {'loss_classifier': 0.06087060272693634, 'loss_box_reg': 0.09347710758447647, 'loss_mask': 0.043021801859140396, 'loss_objectness': 0.010129867121577263, 'loss_rpn_box_reg': 0.008805513381958008}
  Batch [200/1526] Loss: 1.1660 Components: {'loss_classifier': 0.3350696861743927, 'loss_box_reg': 0.5232570767402649, 'loss_mask': 0.1690244972705841, 'loss_objectness': 0.05983363837003708, 'loss_rpn_box_reg': 0.07886315882205963}
  Batch [310/1526] Loss: 0.5442 Components: {'loss_classifier': 0.14725863933563232, 'loss_box_reg': 0.20018458366394043, 'loss_mask': 0.1615210473537445, 'loss_objectness': 0.026972539722919464, 'loss_rpn_box_reg': 0.008247453719377518}
  Batch [340/1526] Loss: 0.4636 Components: {'loss_classifier': 0.18436364829540253, 'loss_box_reg': 0.22123843431472778, 'loss_mask': 0.0002450830361340195, 'loss_objectness': 0.038011398166418076, 'loss_rpn_box_reg': 0.019784092903137207}
  Batch [370/1526] Loss: 0.7163 Components: {'loss_classifier': 0.2501535713672638, 'loss_box_reg': 0.2376355528831482, 'loss_mask': 0.0008779369527474046, 'loss_objectness': 0.09777091443538666, 'loss_rpn_box_reg': 0.12987665832042694}
  Batch [450/1526] Loss: 0.3277 Components: {'loss_classifier': 0.16875308752059937, 'loss_box_reg': 0.13742609322071075, 'loss_mask': 0.0008471913752146065, 'loss_objectness': 0.013806718401610851, 'loss_rpn_box_reg': 0.006842153146862984}
  Batch [480/1526] Loss: 0.2646 Components: {'loss_classifier': 0.07299966365098953, 'loss_box_reg': 0.1624147742986679, 'loss_mask': 0.007532208692282438, 'loss_objectness': 0.012629527598619461, 'loss_rpn_box_reg': 0.008983572944998741}
  Batch [490/1526] Loss: 0.6722 Components: {'loss_classifier': 0.2200392186641693, 'loss_box_reg': 0.30132386088371277, 'loss_mask': 0.05131365731358528, 'loss_objectness': 0.05155313014984131, 'loss_rpn_box_reg': 0.04799599200487137}
  Batch [620/1526] Loss: 0.4248 Components: {'loss_classifier': 0.11536435782909393, 'loss_box_reg': 0.2695281207561493, 'loss_mask': 0.017235606908798218, 'loss_objectness': 0.012433769181370735, 'loss_rpn_box_reg': 0.010198788717389107}
  Batch [630/1526] Loss: 0.7653 Components: {'loss_classifier': 0.27242976427078247, 'loss_box_reg': 0.27764439582824707, 'loss_mask': 0.02282486855983734, 'loss_objectness': 0.027633192017674446, 'loss_rpn_box_reg': 0.16474415361881256}
  Batch [680/1526] Loss: 0.7929 Components: {'loss_classifier': 0.2405700981616974, 'loss_box_reg': 0.4180702269077301, 'loss_mask': 0.06815984845161438, 'loss_objectness': 0.036747999489307404, 'loss_rpn_box_reg': 0.029398253187537193}
  Batch [710/1526] Loss: 0.4899 Components: {'loss_classifier': 0.16710646450519562, 'loss_box_reg': 0.16992652416229248, 'loss_mask': 0.0003208533162251115, 'loss_objectness': 0.03094654530286789, 'loss_rpn_box_reg': 0.12163320183753967}
  Batch [730/1526] Loss: 0.2519 Components: {'loss_classifier': 0.0674515813589096, 'loss_box_reg': 0.1251063048839569, 'loss_mask': 0.032963939011096954, 'loss_objectness': 0.02121187373995781, 'loss_rpn_box_reg': 0.005119627341628075}
  Batch [800/1526] Loss: 0.4432 Components: {'loss_classifier': 0.11107136309146881, 'loss_box_reg': 0.2835029661655426, 'loss_mask': 0.035714730620384216, 'loss_objectness': 0.007489901501685381, 'loss_rpn_box_reg': 0.005373143590986729}
  Batch [840/1526] Loss: 0.2639 Components: {'loss_classifier': 0.10587108135223389, 'loss_box_reg': 0.10468603670597076, 'loss_mask': 0.02129838429391384, 'loss_objectness': 0.01094648614525795, 'loss_rpn_box_reg': 0.021060187369585037}
  Batch [890/1526] Loss: 0.2018 Components: {'loss_classifier': 0.10719601064920425, 'loss_box_reg': 0.07349711656570435, 'loss_mask': 6.052181561244652e-05, 'loss_objectness': 0.008977572433650494, 'loss_rpn_box_reg': 0.012075427919626236}
  Batch [920/1526] Loss: 0.0719 Components: {'loss_classifier': 0.020737772807478905, 'loss_box_reg': 0.0004292951198294759, 'loss_mask': 0.034939754754304886, 'loss_objectness': 0.007667373865842819, 'loss_rpn_box_reg': 0.00810900330543518}
  Batch [960/1526] Loss: 0.2943 Components: {'loss_classifier': 0.11739115417003632, 'loss_box_reg': 0.15380418300628662, 'loss_mask': 0.001981180626899004, 'loss_objectness': 0.01532738097012043, 'loss_rpn_box_reg': 0.005809900350868702}
  Batch [990/1526] Loss: 0.4698 Components: {'loss_classifier': 0.16514864563941956, 'loss_box_reg': 0.23188205063343048, 'loss_mask': 0.021341243758797646, 'loss_objectness': 0.03054233454167843, 'loss_rpn_box_reg': 0.02088826522231102}
  Batch [1080/1526] Loss: 0.4003 Components: {'loss_classifier': 0.16078485548496246, 'loss_box_reg': 0.21412312984466553, 'loss_mask': 0.00012033170060021803, 'loss_objectness': 0.009809405542910099, 'loss_rpn_box_reg': 0.015428982675075531}
  Batch [1110/1526] Loss: 0.8009 Components: {'loss_classifier': 0.28865566849708557, 'loss_box_reg': 0.4258752763271332, 'loss_mask': 0.0008127365144900978, 'loss_objectness': 0.04621460288763046, 'loss_rpn_box_reg': 0.03933112695813179}
  Batch [1150/1526] Loss: 0.4222 Components: {'loss_classifier': 0.18668672442436218, 'loss_box_reg': 0.19208422303199768, 'loss_mask': 0.004507608246058226, 'loss_objectness': 0.02402620203793049, 'loss_rpn_box_reg': 0.014885996468365192}
  Batch [1190/1526] Loss: 0.3596 Components: {'loss_classifier': 0.10124816745519638, 'loss_box_reg': 0.1285044252872467, 'loss_mask': 0.03053186647593975, 'loss_objectness': 0.05368407815694809, 'loss_rpn_box_reg': 0.045658618211746216}
  Batch [1200/1526] Loss: 0.2832 Components: {'loss_classifier': 0.12890395522117615, 'loss_box_reg': 0.142799973487854, 'loss_mask': 0.0004608526942320168, 'loss_objectness': 0.00561545742675662, 'loss_rpn_box_reg': 0.005372953601181507}
  Batch [1220/1526] Loss: 0.3758 Components: {'loss_classifier': 0.1469811201095581, 'loss_box_reg': 0.11975917220115662, 'loss_mask': 0.00012295777560211718, 'loss_objectness': 0.03699564188718796, 'loss_rpn_box_reg': 0.07191945612430573}
  Batch [1260/1526] Loss: 0.5618 Components: {'loss_classifier': 0.18446330726146698, 'loss_box_reg': 0.19578129053115845, 'loss_mask': 6.759285315638408e-05, 'loss_objectness': 0.015268813818693161, 'loss_rpn_box_reg': 0.16622227430343628}
  Batch [1310/1526] Loss: 0.4274 Components: {'loss_classifier': 0.13162678480148315, 'loss_box_reg': 0.21926794946193695, 'loss_mask': 0.06062226742506027, 'loss_objectness': 0.011411551386117935, 'loss_rpn_box_reg': 0.0044391220435500145}
  Batch [1330/1526] Loss: 0.4712 Components: {'loss_classifier': 0.176597461104393, 'loss_box_reg': 0.1322445124387741, 'loss_mask': 0.0006175191956572235, 'loss_objectness': 0.03582318127155304, 'loss_rpn_box_reg': 0.1258932501077652}
  Batch [1370/1526] Loss: 0.6976 Components: {'loss_classifier': 0.2983357310295105, 'loss_box_reg': 0.25190111994743347, 'loss_mask': 0.012620999477803707, 'loss_objectness': 0.04837122932076454, 'loss_rpn_box_reg': 0.08640869706869125}
  Batch [1440/1526] Loss: 1.0994 Components: {'loss_classifier': 0.36373913288116455, 'loss_box_reg': 0.5558742880821228, 'loss_mask': 0.01452132873237133, 'loss_objectness': 0.08252406865358353, 'loss_rpn_box_reg': 0.08275923132896423}
  Batch [1470/1526] Loss: 0.4559 Components: {'loss_classifier': 0.1853276640176773, 'loss_box_reg': 0.24020124971866608, 'loss_mask': 0.0029953981284052134, 'loss_objectness': 0.017299098894000053, 'loss_rpn_box_reg': 0.010035248473286629}

Epoch 26 Summary:
  Train Loss: 0.8625
  Val Loss: 1.6684
  Learning Rate: 0.001000
  Epoch Time: 2528.6s
  EarlyStopping counter: 7 out of 15

Epoch 27/100
----------------------------------------
  Batch [10/1526] Loss: 0.6455 Components: {'loss_classifier': 0.2208513468503952, 'loss_box_reg': 0.25844860076904297, 'loss_mask': 0.0008982932777144015, 'loss_objectness': 0.04648140072822571, 'loss_rpn_box_reg': 0.11880519986152649}
  Batch [50/1526] Loss: 0.5541 Components: {'loss_classifier': 0.17510834336280823, 'loss_box_reg': 0.21332871913909912, 'loss_mask': 0.05876469984650612, 'loss_objectness': 0.022110776975750923, 'loss_rpn_box_reg': 0.0847957655787468}
  Batch [100/1526] Loss: 0.9995 Components: {'loss_classifier': 0.3440606892108917, 'loss_box_reg': 0.5137056708335876, 'loss_mask': 0.002448876155540347, 'loss_objectness': 0.05584241449832916, 'loss_rpn_box_reg': 0.0834592953324318}
  Batch [110/1526] Loss: 0.4787 Components: {'loss_classifier': 0.18628595769405365, 'loss_box_reg': 0.24871309101581573, 'loss_mask': 0.0001873484579846263, 'loss_objectness': 0.02123524807393551, 'loss_rpn_box_reg': 0.02229725383222103}
  Batch [160/1526] Loss: 0.9298 Components: {'loss_classifier': 0.29217448830604553, 'loss_box_reg': 0.2731848657131195, 'loss_mask': 0.0010431990958750248, 'loss_objectness': 0.20618143677711487, 'loss_rpn_box_reg': 0.15722385048866272}
  Batch [170/1526] Loss: 5.0038 Components: {'loss_classifier': 0.16628997027873993, 'loss_box_reg': 0.07661288976669312, 'loss_mask': 0.0013973506866022944, 'loss_objectness': 0.38265368342399597, 'loss_rpn_box_reg': 4.3768486976623535}
  Batch [230/1526] Loss: 6.3682 Components: {'loss_classifier': 0.0573459230363369, 'loss_box_reg': 0.013713594526052475, 'loss_mask': 0.009168705902993679, 'loss_objectness': 0.36240875720977783, 'loss_rpn_box_reg': 5.925558090209961}
  Batch [240/1526] Loss: 0.7293 Components: {'loss_classifier': 0.2422875314950943, 'loss_box_reg': 0.24956414103507996, 'loss_mask': 6.810409831814468e-05, 'loss_objectness': 0.04506126046180725, 'loss_rpn_box_reg': 0.19229859113693237}
  Batch [290/1526] Loss: 0.6205 Components: {'loss_classifier': 0.16582532227039337, 'loss_box_reg': 0.33101338148117065, 'loss_mask': 0.10675331205129623, 'loss_objectness': 0.012055952101945877, 'loss_rpn_box_reg': 0.004838997032493353}
  Batch [390/1526] Loss: 0.4447 Components: {'loss_classifier': 0.13916879892349243, 'loss_box_reg': 0.16270259022712708, 'loss_mask': 0.11892290413379669, 'loss_objectness': 0.012875007465481758, 'loss_rpn_box_reg': 0.011079414747655392}
  Batch [490/1526] Loss: 0.3557 Components: {'loss_classifier': 0.1410626918077469, 'loss_box_reg': 0.11935615539550781, 'loss_mask': 0.0013888961402699351, 'loss_objectness': 0.021182842552661896, 'loss_rpn_box_reg': 0.07266472280025482}
  Batch [520/1526] Loss: 0.5674 Components: {'loss_classifier': 0.1734912246465683, 'loss_box_reg': 0.2791834771633148, 'loss_mask': 0.06559287756681442, 'loss_objectness': 0.029357466846704483, 'loss_rpn_box_reg': 0.019741030409932137}
  Batch [540/1526] Loss: 0.6964 Components: {'loss_classifier': 0.18843013048171997, 'loss_box_reg': 0.2617628574371338, 'loss_mask': 0.03050943836569786, 'loss_objectness': 0.20102566480636597, 'loss_rpn_box_reg': 0.014632059261202812}
  Batch [650/1526] Loss: 3.9305 Components: {'loss_classifier': 0.17784607410430908, 'loss_box_reg': 0.29317134618759155, 'loss_mask': 0.004528447519987822, 'loss_objectness': 0.6457395553588867, 'loss_rpn_box_reg': 2.8092355728149414}
  Batch [660/1526] Loss: 0.6734 Components: {'loss_classifier': 0.2260437160730362, 'loss_box_reg': 0.21509766578674316, 'loss_mask': 6.667042907793075e-05, 'loss_objectness': 0.05118919536471367, 'loss_rpn_box_reg': 0.1809999644756317}
  Batch [790/1526] Loss: 0.1571 Components: {'loss_classifier': 0.07645710557699203, 'loss_box_reg': 0.05860630422830582, 'loss_mask': 0.009092089720070362, 'loss_objectness': 0.006697417236864567, 'loss_rpn_box_reg': 0.00622146250680089}
  Batch [800/1526] Loss: 0.4754 Components: {'loss_classifier': 0.17250634729862213, 'loss_box_reg': 0.16845513880252838, 'loss_mask': 0.006973600946366787, 'loss_objectness': 0.03546267747879028, 'loss_rpn_box_reg': 0.09196130931377411}
  Batch [820/1526] Loss: 0.2719 Components: {'loss_classifier': 0.06939374655485153, 'loss_box_reg': 0.039407484233379364, 'loss_mask': 0.0036848904564976692, 'loss_objectness': 0.019399354234337807, 'loss_rpn_box_reg': 0.14003531634807587}
  Batch [920/1526] Loss: 0.5682 Components: {'loss_classifier': 0.18787634372711182, 'loss_box_reg': 0.265056848526001, 'loss_mask': 0.017335476353764534, 'loss_objectness': 0.04392537847161293, 'loss_rpn_box_reg': 0.05400737375020981}
  Batch [970/1526] Loss: 0.5288 Components: {'loss_classifier': 0.15892146527767181, 'loss_box_reg': 0.33551204204559326, 'loss_mask': 5.578163109021261e-05, 'loss_objectness': 0.02140844240784645, 'loss_rpn_box_reg': 0.012935100123286247}
  Batch [980/1526] Loss: 0.8617 Components: {'loss_classifier': 0.24886009097099304, 'loss_box_reg': 0.323386013507843, 'loss_mask': 0.07265270501375198, 'loss_objectness': 0.08902589231729507, 'loss_rpn_box_reg': 0.12781579792499542}
  Batch [1060/1526] Loss: 0.5578 Components: {'loss_classifier': 0.15686900913715363, 'loss_box_reg': 0.34179699420928955, 'loss_mask': 0.04558298736810684, 'loss_objectness': 0.005848854314535856, 'loss_rpn_box_reg': 0.007739706430584192}
  Batch [1160/1526] Loss: 0.4236 Components: {'loss_classifier': 0.12174811214208603, 'loss_box_reg': 0.22577519714832306, 'loss_mask': 0.058618877083063126, 'loss_objectness': 0.010647363029420376, 'loss_rpn_box_reg': 0.006802530027925968}
  Batch [1170/1526] Loss: 0.5938 Components: {'loss_classifier': 0.1780526489019394, 'loss_box_reg': 0.22839759290218353, 'loss_mask': 0.0034370652865618467, 'loss_objectness': 0.06544162333011627, 'loss_rpn_box_reg': 0.11846984177827835}
  Batch [1230/1526] Loss: 0.1845 Components: {'loss_classifier': 0.060430847108364105, 'loss_box_reg': 0.11129322648048401, 'loss_mask': 0.0002642334147822112, 'loss_objectness': 0.009595729410648346, 'loss_rpn_box_reg': 0.002899682382121682}
  Batch [1250/1526] Loss: 0.3369 Components: {'loss_classifier': 0.11789239943027496, 'loss_box_reg': 0.20747047662734985, 'loss_mask': 0.00022732319484930485, 'loss_objectness': 0.0059012495912611485, 'loss_rpn_box_reg': 0.005365757271647453}
  Batch [1270/1526] Loss: 0.1658 Components: {'loss_classifier': 0.058305446058511734, 'loss_box_reg': 0.10311274230480194, 'loss_mask': 0.00015005718159954995, 'loss_objectness': 0.0035100416280329227, 'loss_rpn_box_reg': 0.000697439827490598}
  Batch [1280/1526] Loss: 0.2701 Components: {'loss_classifier': 0.08244287967681885, 'loss_box_reg': 0.09937751293182373, 'loss_mask': 0.01208785455673933, 'loss_objectness': 0.04085923731327057, 'loss_rpn_box_reg': 0.03533722087740898}
  Batch [1370/1526] Loss: 0.6089 Components: {'loss_classifier': 0.18347062170505524, 'loss_box_reg': 0.36811450123786926, 'loss_mask': 0.006642174907028675, 'loss_objectness': 0.02666972018778324, 'loss_rpn_box_reg': 0.024050366133451462}
  Batch [1400/1526] Loss: 0.8559 Components: {'loss_classifier': 0.29175007343292236, 'loss_box_reg': 0.47710108757019043, 'loss_mask': 0.004435518756508827, 'loss_objectness': 0.03556772693991661, 'loss_rpn_box_reg': 0.047086745500564575}
  Batch [1430/1526] Loss: 0.6898 Components: {'loss_classifier': 0.2472686469554901, 'loss_box_reg': 0.38574865460395813, 'loss_mask': 0.011791241355240345, 'loss_objectness': 0.03198336064815521, 'loss_rpn_box_reg': 0.013018807396292686}

Epoch 27 Summary:
  Train Loss: 0.9920
  Val Loss: 1.6007
  Learning Rate: 0.001000
  Epoch Time: 2581.3s
  EarlyStopping counter: 8 out of 15

Epoch 28/100
----------------------------------------
  Batch [0/1526] Loss: 0.2458 Components: {'loss_classifier': 0.09694495052099228, 'loss_box_reg': 0.1344926655292511, 'loss_mask': 0.0001355494896415621, 'loss_objectness': 0.011443205177783966, 'loss_rpn_box_reg': 0.0028161616064608097}
  Batch [60/1526] Loss: 0.3755 Components: {'loss_classifier': 0.09322409331798553, 'loss_box_reg': 0.11109386384487152, 'loss_mask': 6.519380985992029e-05, 'loss_objectness': 0.03661297261714935, 'loss_rpn_box_reg': 0.13445648550987244}
  Batch [70/1526] Loss: 0.2194 Components: {'loss_classifier': 0.08977954834699631, 'loss_box_reg': 0.12182299047708511, 'loss_mask': 5.0494385504862294e-05, 'loss_objectness': 0.006040794774889946, 'loss_rpn_box_reg': 0.0016776352422311902}
  Batch [130/1526] Loss: 0.9400 Components: {'loss_classifier': 0.39466431736946106, 'loss_box_reg': 0.4920605719089508, 'loss_mask': 0.00015611764683853835, 'loss_objectness': 0.0221610888838768, 'loss_rpn_box_reg': 0.03096793219447136}
  Batch [170/1526] Loss: 0.3454 Components: {'loss_classifier': 0.08940823376178741, 'loss_box_reg': 0.19081361591815948, 'loss_mask': 0.05969169735908508, 'loss_objectness': 0.002325110137462616, 'loss_rpn_box_reg': 0.003139019710943103}
  Batch [240/1526] Loss: 0.5340 Components: {'loss_classifier': 0.16898199915885925, 'loss_box_reg': 0.34814316034317017, 'loss_mask': 0.0012476573465391994, 'loss_objectness': 0.010076086968183517, 'loss_rpn_box_reg': 0.005568571854382753}
  Batch [340/1526] Loss: 0.8774 Components: {'loss_classifier': 0.2516184449195862, 'loss_box_reg': 0.5519658923149109, 'loss_mask': 0.02708081528544426, 'loss_objectness': 0.02956419251859188, 'loss_rpn_box_reg': 0.017138123512268066}
  Batch [360/1526] Loss: 0.5316 Components: {'loss_classifier': 0.16724759340286255, 'loss_box_reg': 0.3200797438621521, 'loss_mask': 0.033840760588645935, 'loss_objectness': 0.001515018055215478, 'loss_rpn_box_reg': 0.008960717357695103}
  Batch [420/1526] Loss: 0.6592 Components: {'loss_classifier': 0.29540571570396423, 'loss_box_reg': 0.20974554121494293, 'loss_mask': 0.010634674690663815, 'loss_objectness': 0.059044249355793, 'loss_rpn_box_reg': 0.08434156328439713}
  Batch [430/1526] Loss: 0.4292 Components: {'loss_classifier': 0.10804890096187592, 'loss_box_reg': 0.07824898511171341, 'loss_mask': 0.0003842083679046482, 'loss_objectness': 0.06536103039979935, 'loss_rpn_box_reg': 0.1771998405456543}
  Batch [530/1526] Loss: 0.5581 Components: {'loss_classifier': 0.1690341979265213, 'loss_box_reg': 0.13750633597373962, 'loss_mask': 0.018479134887456894, 'loss_objectness': 0.06503556668758392, 'loss_rpn_box_reg': 0.1679985225200653}
  Batch [630/1526] Loss: 0.5026 Components: {'loss_classifier': 0.1155710369348526, 'loss_box_reg': 0.05978638306260109, 'loss_mask': 0.0007340888842009008, 'loss_objectness': 0.07757216691970825, 'loss_rpn_box_reg': 0.2489784210920334}
  Batch [660/1526] Loss: 0.3042 Components: {'loss_classifier': 0.07138194888830185, 'loss_box_reg': 0.1011091098189354, 'loss_mask': 0.007511101197451353, 'loss_objectness': 0.003951648715883493, 'loss_rpn_box_reg': 0.12027165293693542}
  Batch [700/1526] Loss: 6.6196 Components: {'loss_classifier': 0.26729217171669006, 'loss_box_reg': 0.1332196593284607, 'loss_mask': 0.003973766695708036, 'loss_objectness': 0.21985895931720734, 'loss_rpn_box_reg': 5.995304107666016}
  Batch [710/1526] Loss: 0.1686 Components: {'loss_classifier': 0.06742915511131287, 'loss_box_reg': 0.04218606278300285, 'loss_mask': 0.004961520899087191, 'loss_objectness': 0.04808001592755318, 'loss_rpn_box_reg': 0.005919488612562418}
  Batch [720/1526] Loss: 0.4914 Components: {'loss_classifier': 0.1688080132007599, 'loss_box_reg': 0.29870256781578064, 'loss_mask': 0.0023928056471049786, 'loss_objectness': 0.011319367215037346, 'loss_rpn_box_reg': 0.01013012882322073}
  Batch [750/1526] Loss: 5.6387 Components: {'loss_classifier': 0.09767268598079681, 'loss_box_reg': 0.03601449728012085, 'loss_mask': 0.006130872759968042, 'loss_objectness': 0.33737680315971375, 'loss_rpn_box_reg': 5.161487579345703}
  Batch [820/1526] Loss: 0.4453 Components: {'loss_classifier': 0.24604465067386627, 'loss_box_reg': 0.16328339278697968, 'loss_mask': 0.005044815130531788, 'loss_objectness': 0.020106008276343346, 'loss_rpn_box_reg': 0.010798170231282711}
  Batch [930/1526] Loss: 0.6261 Components: {'loss_classifier': 0.2046472132205963, 'loss_box_reg': 0.2681677043437958, 'loss_mask': 0.12489296495914459, 'loss_objectness': 0.019166644662618637, 'loss_rpn_box_reg': 0.009266842156648636}
  Batch [960/1526] Loss: 0.4726 Components: {'loss_classifier': 0.15970465540885925, 'loss_box_reg': 0.1700083166360855, 'loss_mask': 1.3677731658390258e-05, 'loss_objectness': 0.018162870779633522, 'loss_rpn_box_reg': 0.1247568279504776}
  Batch [980/1526] Loss: 1.0724 Components: {'loss_classifier': 0.36089208722114563, 'loss_box_reg': 0.626075029373169, 'loss_mask': 0.007074402179569006, 'loss_objectness': 0.04423470422625542, 'loss_rpn_box_reg': 0.03412449359893799}
  Batch [1060/1526] Loss: 1.0555 Components: {'loss_classifier': 0.3611446022987366, 'loss_box_reg': 0.5697423815727234, 'loss_mask': 0.04837006703019142, 'loss_objectness': 0.04456857591867447, 'loss_rpn_box_reg': 0.03163008764386177}
  Batch [1140/1526] Loss: 0.4589 Components: {'loss_classifier': 0.1555074155330658, 'loss_box_reg': 0.258395254611969, 'loss_mask': 0.013868479058146477, 'loss_objectness': 0.01232618186622858, 'loss_rpn_box_reg': 0.01880672760307789}
  Batch [1160/1526] Loss: 0.9788 Components: {'loss_classifier': 0.32366231083869934, 'loss_box_reg': 0.5183871388435364, 'loss_mask': 0.05226185917854309, 'loss_objectness': 0.032141026109457016, 'loss_rpn_box_reg': 0.05235467478632927}
  Batch [1210/1526] Loss: 0.2267 Components: {'loss_classifier': 0.0666605606675148, 'loss_box_reg': 0.11443962901830673, 'loss_mask': 0.025914523750543594, 'loss_objectness': 0.013758037239313126, 'loss_rpn_box_reg': 0.005969801917672157}
  Batch [1280/1526] Loss: 5.4987 Components: {'loss_classifier': 0.1381443589925766, 'loss_box_reg': 0.05074033886194229, 'loss_mask': 0.001198373269289732, 'loss_objectness': 1.3406449556350708, 'loss_rpn_box_reg': 3.968019485473633}
  Batch [1430/1526] Loss: 0.5678 Components: {'loss_classifier': 0.1780349165201187, 'loss_box_reg': 0.32911786437034607, 'loss_mask': 0.02678157202899456, 'loss_objectness': 0.017009247094392776, 'loss_rpn_box_reg': 0.01683777943253517}
  Batch [1500/1526] Loss: 0.6328 Components: {'loss_classifier': 0.2726031541824341, 'loss_box_reg': 0.06777069717645645, 'loss_mask': 0.0001725679903756827, 'loss_objectness': 0.14778000116348267, 'loss_rpn_box_reg': 0.14447839558124542}

Epoch 28 Summary:
  Train Loss: 0.9142
  Val Loss: 1.5523
  Learning Rate: 0.001000
  Epoch Time: 2615.7s
  EarlyStopping counter: 9 out of 15

Epoch 29/100
----------------------------------------
  Batch [30/1526] Loss: 7.2627 Components: {'loss_classifier': 0.05279949679970741, 'loss_box_reg': 0.05229939520359039, 'loss_mask': 0.03254111856222153, 'loss_objectness': 1.7320351600646973, 'loss_rpn_box_reg': 5.3930487632751465}
  Batch [90/1526] Loss: 0.5616 Components: {'loss_classifier': 0.17146864533424377, 'loss_box_reg': 0.28558698296546936, 'loss_mask': 0.07751625776290894, 'loss_objectness': 0.019777348265051842, 'loss_rpn_box_reg': 0.007283315993845463}
  Batch [100/1526] Loss: 0.5533 Components: {'loss_classifier': 0.17467203736305237, 'loss_box_reg': 0.29198703169822693, 'loss_mask': 0.00035459015634842217, 'loss_objectness': 0.022555861622095108, 'loss_rpn_box_reg': 0.06368499249219894}
  Batch [110/1526] Loss: 0.4185 Components: {'loss_classifier': 0.1262076497077942, 'loss_box_reg': 0.2751164138317108, 'loss_mask': 7.690541679039598e-05, 'loss_objectness': 0.009904829785227776, 'loss_rpn_box_reg': 0.007240313105285168}
  Batch [220/1526] Loss: 0.8599 Components: {'loss_classifier': 0.20919664204120636, 'loss_box_reg': 0.5865154266357422, 'loss_mask': 0.034953463822603226, 'loss_objectness': 0.011040407232940197, 'loss_rpn_box_reg': 0.018216142430901527}
  Batch [240/1526] Loss: 0.6743 Components: {'loss_classifier': 0.26170799136161804, 'loss_box_reg': 0.2756146192550659, 'loss_mask': 0.0009695362532511353, 'loss_objectness': 0.041261106729507446, 'loss_rpn_box_reg': 0.09476209431886673}
  Batch [320/1526] Loss: 0.4284 Components: {'loss_classifier': 0.14391760528087616, 'loss_box_reg': 0.23158586025238037, 'loss_mask': 0.00010429900430608541, 'loss_objectness': 0.018323257565498352, 'loss_rpn_box_reg': 0.034516025334596634}
  Batch [360/1526] Loss: 0.5012 Components: {'loss_classifier': 0.1799054890871048, 'loss_box_reg': 0.26744288206100464, 'loss_mask': 0.00015228039410430938, 'loss_objectness': 0.03017405793070793, 'loss_rpn_box_reg': 0.023515164852142334}
  Batch [380/1526] Loss: 0.4496 Components: {'loss_classifier': 0.1578965038061142, 'loss_box_reg': 0.22128701210021973, 'loss_mask': 0.024016279727220535, 'loss_objectness': 0.026838788762688637, 'loss_rpn_box_reg': 0.019561998546123505}
  Batch [410/1526] Loss: 1.0638 Components: {'loss_classifier': 0.28361672163009644, 'loss_box_reg': 0.6224000453948975, 'loss_mask': 0.07514815032482147, 'loss_objectness': 0.052332259714603424, 'loss_rpn_box_reg': 0.03029942512512207}
  Batch [460/1526] Loss: 0.4039 Components: {'loss_classifier': 0.1217489093542099, 'loss_box_reg': 0.18171845376491547, 'loss_mask': 0.0008739481563679874, 'loss_objectness': 0.024850819259881973, 'loss_rpn_box_reg': 0.07468096166849136}
  Batch [530/1526] Loss: 0.5876 Components: {'loss_classifier': 0.23528049886226654, 'loss_box_reg': 0.2598690092563629, 'loss_mask': 0.021397441625595093, 'loss_objectness': 0.04600168764591217, 'loss_rpn_box_reg': 0.025086307898163795}
  Batch [550/1526] Loss: 0.3504 Components: {'loss_classifier': 0.0960724875330925, 'loss_box_reg': 0.07776836305856705, 'loss_mask': 0.01732727885246277, 'loss_objectness': 0.057716041803359985, 'loss_rpn_box_reg': 0.10153847187757492}
  Batch [660/1526] Loss: 0.3550 Components: {'loss_classifier': 0.10485076904296875, 'loss_box_reg': 0.14195816218852997, 'loss_mask': 0.0994202122092247, 'loss_objectness': 0.0060333614237606525, 'loss_rpn_box_reg': 0.0027851152699440718}
  Batch [710/1526] Loss: 0.3487 Components: {'loss_classifier': 0.09223078936338425, 'loss_box_reg': 0.22178298234939575, 'loss_mask': 0.014421235769987106, 'loss_objectness': 0.012056459672749043, 'loss_rpn_box_reg': 0.008229590021073818}
  Batch [750/1526] Loss: 1.0453 Components: {'loss_classifier': 0.41092002391815186, 'loss_box_reg': 0.33521196246147156, 'loss_mask': 2.7827358280774206e-05, 'loss_objectness': 0.12865471839904785, 'loss_rpn_box_reg': 0.1705160140991211}
  Batch [760/1526] Loss: 0.4459 Components: {'loss_classifier': 0.12763066589832306, 'loss_box_reg': 0.28356555104255676, 'loss_mask': 0.018236372619867325, 'loss_objectness': 0.011003630235791206, 'loss_rpn_box_reg': 0.005465969908982515}
  Batch [890/1526] Loss: 0.2953 Components: {'loss_classifier': 0.10509280860424042, 'loss_box_reg': 0.14407841861248016, 'loss_mask': 0.0008429844747297466, 'loss_objectness': 0.03135102987289429, 'loss_rpn_box_reg': 0.013966474682092667}
  Batch [910/1526] Loss: 0.2690 Components: {'loss_classifier': 0.1294153928756714, 'loss_box_reg': 0.09878159314393997, 'loss_mask': 0.00029973077471368015, 'loss_objectness': 0.018758093938231468, 'loss_rpn_box_reg': 0.021731877699494362}
  Batch [920/1526] Loss: 0.4018 Components: {'loss_classifier': 0.12373531609773636, 'loss_box_reg': 0.24004513025283813, 'loss_mask': 0.030581900849938393, 'loss_objectness': 0.003724374808371067, 'loss_rpn_box_reg': 0.003703364171087742}
  Batch [940/1526] Loss: 0.5648 Components: {'loss_classifier': 0.2264227420091629, 'loss_box_reg': 0.2519635260105133, 'loss_mask': 0.055365994572639465, 'loss_objectness': 0.004309644922614098, 'loss_rpn_box_reg': 0.02674005925655365}
  Batch [990/1526] Loss: 0.7010 Components: {'loss_classifier': 0.29974597692489624, 'loss_box_reg': 0.351163774728775, 'loss_mask': 0.0003513737756293267, 'loss_objectness': 0.03026087023317814, 'loss_rpn_box_reg': 0.019452570006251335}
  Batch [1040/1526] Loss: 0.5500 Components: {'loss_classifier': 0.22299538552761078, 'loss_box_reg': 0.16265277564525604, 'loss_mask': 0.0002201974712079391, 'loss_objectness': 0.05708937346935272, 'loss_rpn_box_reg': 0.10707935690879822}
  Batch [1110/1526] Loss: 0.7650 Components: {'loss_classifier': 0.2151002436876297, 'loss_box_reg': 0.45265984535217285, 'loss_mask': 0.05023738369345665, 'loss_objectness': 0.02297022007405758, 'loss_rpn_box_reg': 0.02404206246137619}
  Batch [1150/1526] Loss: 0.3523 Components: {'loss_classifier': 0.12752193212509155, 'loss_box_reg': 0.19911828637123108, 'loss_mask': 0.0039247809909284115, 'loss_objectness': 0.0037360135465860367, 'loss_rpn_box_reg': 0.017970729619264603}
  Batch [1200/1526] Loss: 0.5548 Components: {'loss_classifier': 0.2347908318042755, 'loss_box_reg': 0.2606222629547119, 'loss_mask': 0.0005164605099707842, 'loss_objectness': 0.04004763439297676, 'loss_rpn_box_reg': 0.01882249116897583}
  Batch [1230/1526] Loss: 0.4060 Components: {'loss_classifier': 0.1672971397638321, 'loss_box_reg': 0.20302124321460724, 'loss_mask': 0.0001418172469129786, 'loss_objectness': 0.0268339142203331, 'loss_rpn_box_reg': 0.008721097372472286}
  Batch [1260/1526] Loss: 0.8982 Components: {'loss_classifier': 0.3858904540538788, 'loss_box_reg': 0.4176502823829651, 'loss_mask': 0.0013144504046067595, 'loss_objectness': 0.05679026246070862, 'loss_rpn_box_reg': 0.03658929094672203}
  Batch [1330/1526] Loss: 0.9905 Components: {'loss_classifier': 0.3075177073478699, 'loss_box_reg': 0.4326010048389435, 'loss_mask': 0.027772996574640274, 'loss_objectness': 0.08858809620141983, 'loss_rpn_box_reg': 0.13401329517364502}
  Batch [1340/1526] Loss: 0.5794 Components: {'loss_classifier': 0.23563379049301147, 'loss_box_reg': 0.2604965269565582, 'loss_mask': 0.0013813754776492715, 'loss_objectness': 0.025360118597745895, 'loss_rpn_box_reg': 0.056574463844299316}

Epoch 29 Summary:
  Train Loss: 0.9456
  Val Loss: 1.6914
  Learning Rate: 0.001000
  Epoch Time: 2554.3s
  EarlyStopping counter: 10 out of 15

Epoch 30/100
----------------------------------------
  Batch [10/1526] Loss: 0.6705 Components: {'loss_classifier': 0.21364367008209229, 'loss_box_reg': 0.3809339106082916, 'loss_mask': 0.02835182100534439, 'loss_objectness': 0.029551981016993523, 'loss_rpn_box_reg': 0.017988713458180428}
  Batch [60/1526] Loss: 0.7527 Components: {'loss_classifier': 0.2135210484266281, 'loss_box_reg': 0.4724728465080261, 'loss_mask': 0.0019061617786064744, 'loss_objectness': 0.02723192609846592, 'loss_rpn_box_reg': 0.03752413019537926}
  Batch [80/1526] Loss: 1.0175 Components: {'loss_classifier': 0.2941924035549164, 'loss_box_reg': 0.644370436668396, 'loss_mask': 0.05367400497198105, 'loss_objectness': 0.009077836759388447, 'loss_rpn_box_reg': 0.016149889677762985}
  Batch [180/1526] Loss: 0.6312 Components: {'loss_classifier': 0.1561288684606552, 'loss_box_reg': 0.1079821065068245, 'loss_mask': 0.024907903745770454, 'loss_objectness': 0.23801304399967194, 'loss_rpn_box_reg': 0.10415120422840118}
  Batch [190/1526] Loss: 0.9996 Components: {'loss_classifier': 0.3337317407131195, 'loss_box_reg': 0.6035127639770508, 'loss_mask': 0.014361795037984848, 'loss_objectness': 0.015062753111124039, 'loss_rpn_box_reg': 0.0328841432929039}
  Batch [210/1526] Loss: 0.3874 Components: {'loss_classifier': 0.11463319510221481, 'loss_box_reg': 0.22867120802402496, 'loss_mask': 0.038850877434015274, 'loss_objectness': 0.0037086212541908026, 'loss_rpn_box_reg': 0.001549051026813686}
  Batch [250/1526] Loss: 0.8580 Components: {'loss_classifier': 0.224373921751976, 'loss_box_reg': 0.5085128545761108, 'loss_mask': 0.05730303376913071, 'loss_objectness': 0.03916768729686737, 'loss_rpn_box_reg': 0.028643323108553886}
  Batch [260/1526] Loss: 0.7693 Components: {'loss_classifier': 0.23903249204158783, 'loss_box_reg': 0.4620128273963928, 'loss_mask': 0.008677216246724129, 'loss_objectness': 0.0159857627004385, 'loss_rpn_box_reg': 0.043548934161663055}
  Batch [270/1526] Loss: 0.3711 Components: {'loss_classifier': 0.10665915906429291, 'loss_box_reg': 0.20772436261177063, 'loss_mask': 0.03904814273118973, 'loss_objectness': 0.005655345041304827, 'loss_rpn_box_reg': 0.011979008093476295}
  Batch [300/1526] Loss: 0.4452 Components: {'loss_classifier': 0.15237364172935486, 'loss_box_reg': 0.17893396317958832, 'loss_mask': 0.07513004541397095, 'loss_objectness': 0.017719227820634842, 'loss_rpn_box_reg': 0.021020036190748215}
  Batch [330/1526] Loss: 0.2852 Components: {'loss_classifier': 0.11126399785280228, 'loss_box_reg': 0.1541237086057663, 'loss_mask': 0.015501781366765499, 'loss_objectness': 0.001573100220412016, 'loss_rpn_box_reg': 0.0027727275155484676}
  Batch [350/1526] Loss: 0.9066 Components: {'loss_classifier': 0.2884911596775055, 'loss_box_reg': 0.507931113243103, 'loss_mask': 0.020147373899817467, 'loss_objectness': 0.029073726385831833, 'loss_rpn_box_reg': 0.06090801954269409}
  Batch [400/1526] Loss: 0.7110 Components: {'loss_classifier': 0.23325791954994202, 'loss_box_reg': 0.44014865159988403, 'loss_mask': 0.00029128792812116444, 'loss_objectness': 0.016396699473261833, 'loss_rpn_box_reg': 0.020913753658533096}
  Batch [470/1526] Loss: 0.3758 Components: {'loss_classifier': 0.10695872455835342, 'loss_box_reg': 0.24707594513893127, 'loss_mask': 0.0005256098229438066, 'loss_objectness': 0.013293227180838585, 'loss_rpn_box_reg': 0.007946289144456387}
  Batch [570/1526] Loss: 0.4615 Components: {'loss_classifier': 0.18249396979808807, 'loss_box_reg': 0.20227187871932983, 'loss_mask': 0.0002297984465258196, 'loss_objectness': 0.0583684965968132, 'loss_rpn_box_reg': 0.018140068277716637}
  Batch [720/1526] Loss: 0.2601 Components: {'loss_classifier': 0.08402848988771439, 'loss_box_reg': 0.11822403222322464, 'loss_mask': 0.03474549204111099, 'loss_objectness': 0.01658901944756508, 'loss_rpn_box_reg': 0.006524078082293272}
  Batch [730/1526] Loss: 0.2690 Components: {'loss_classifier': 0.04780115187168121, 'loss_box_reg': 0.06027577072381973, 'loss_mask': 0.007200509775429964, 'loss_objectness': 0.02181912027299404, 'loss_rpn_box_reg': 0.1319405436515808}
  Batch [840/1526] Loss: 0.2216 Components: {'loss_classifier': 0.0825142115354538, 'loss_box_reg': 0.07925578206777573, 'loss_mask': 0.0009562806226313114, 'loss_objectness': 0.016529185697436333, 'loss_rpn_box_reg': 0.042346205562353134}
  Batch [860/1526] Loss: 3.9241 Components: {'loss_classifier': 0.16449640691280365, 'loss_box_reg': 0.11837877333164215, 'loss_mask': 0.07690555602312088, 'loss_objectness': 0.29044851660728455, 'loss_rpn_box_reg': 3.2738592624664307}
  Batch [880/1526] Loss: 0.4973 Components: {'loss_classifier': 0.16421423852443695, 'loss_box_reg': 0.19727203249931335, 'loss_mask': 0.00013039648183621466, 'loss_objectness': 0.011083798483014107, 'loss_rpn_box_reg': 0.12456081807613373}
  Batch [900/1526] Loss: 0.7043 Components: {'loss_classifier': 0.23846781253814697, 'loss_box_reg': 0.309781014919281, 'loss_mask': 0.031870272010564804, 'loss_objectness': 0.020329635590314865, 'loss_rpn_box_reg': 0.10383304953575134}
  Batch [910/1526] Loss: 0.7081 Components: {'loss_classifier': 0.20323853194713593, 'loss_box_reg': 0.4449676275253296, 'loss_mask': 0.029773227870464325, 'loss_objectness': 0.016431733965873718, 'loss_rpn_box_reg': 0.013732357881963253}
  Batch [970/1526] Loss: 0.4946 Components: {'loss_classifier': 0.1697312444448471, 'loss_box_reg': 0.27477478981018066, 'loss_mask': 0.019358430057764053, 'loss_objectness': 0.02393105998635292, 'loss_rpn_box_reg': 0.006837157998234034}
  Batch [980/1526] Loss: 0.6830 Components: {'loss_classifier': 0.20907287299633026, 'loss_box_reg': 0.25446122884750366, 'loss_mask': 0.026674892753362656, 'loss_objectness': 0.028347019106149673, 'loss_rpn_box_reg': 0.1644192487001419}
  Batch [1010/1526] Loss: 0.4573 Components: {'loss_classifier': 0.13916340470314026, 'loss_box_reg': 0.24164614081382751, 'loss_mask': 0.053482070565223694, 'loss_objectness': 0.01529552973806858, 'loss_rpn_box_reg': 0.007664075121283531}
  Batch [1020/1526] Loss: 0.8128 Components: {'loss_classifier': 0.24238023161888123, 'loss_box_reg': 0.42486482858657837, 'loss_mask': 0.12136482447385788, 'loss_objectness': 0.007355291396379471, 'loss_rpn_box_reg': 0.01683218404650688}
  Batch [1040/1526] Loss: 0.9602 Components: {'loss_classifier': 0.2890051305294037, 'loss_box_reg': 0.6143706440925598, 'loss_mask': 0.015787512063980103, 'loss_objectness': 0.012619967572391033, 'loss_rpn_box_reg': 0.02842429094016552}
  Batch [1070/1526] Loss: 0.2888 Components: {'loss_classifier': 0.069226935505867, 'loss_box_reg': 0.14229105412960052, 'loss_mask': 0.0216798335313797, 'loss_objectness': 0.006887853145599365, 'loss_rpn_box_reg': 0.0486685186624527}
  Batch [1110/1526] Loss: 7.7815 Components: {'loss_classifier': 0.04665546491742134, 'loss_box_reg': 0.044234924018383026, 'loss_mask': 0.019598256796598434, 'loss_objectness': 0.7887484431266785, 'loss_rpn_box_reg': 6.882241725921631}
  Batch [1120/1526] Loss: 0.5268 Components: {'loss_classifier': 0.21535511314868927, 'loss_box_reg': 0.19956660270690918, 'loss_mask': 0.00020728132221847773, 'loss_objectness': 0.03947685286402702, 'loss_rpn_box_reg': 0.07215035706758499}
  Batch [1240/1526] Loss: 0.4447 Components: {'loss_classifier': 0.15351517498493195, 'loss_box_reg': 0.18688058853149414, 'loss_mask': 0.009549114853143692, 'loss_objectness': 0.023796020075678825, 'loss_rpn_box_reg': 0.07093491405248642}
  Batch [1250/1526] Loss: 5.3052 Components: {'loss_classifier': 0.022556347772479057, 'loss_box_reg': 0.0004989160224795341, 'loss_mask': 0.02041599713265896, 'loss_objectness': 0.4800613224506378, 'loss_rpn_box_reg': 4.781698226928711}
  Batch [1280/1526] Loss: 0.7677 Components: {'loss_classifier': 0.3280034065246582, 'loss_box_reg': 0.3651832640171051, 'loss_mask': 0.0005120601854287088, 'loss_objectness': 0.03890702873468399, 'loss_rpn_box_reg': 0.03505900502204895}
  Batch [1320/1526] Loss: 0.2532 Components: {'loss_classifier': 0.06443680077791214, 'loss_box_reg': 0.11499641090631485, 'loss_mask': 0.029791662469506264, 'loss_objectness': 0.02122405171394348, 'loss_rpn_box_reg': 0.02277265302836895}
  Batch [1500/1526] Loss: 0.9773 Components: {'loss_classifier': 0.3441039025783539, 'loss_box_reg': 0.4674868583679199, 'loss_mask': 0.0020768907852470875, 'loss_objectness': 0.08175057917833328, 'loss_rpn_box_reg': 0.0818479061126709}

Epoch 30 Summary:
  Train Loss: 0.8281
  Val Loss: 1.6289
  Learning Rate: 0.001000
  Epoch Time: 2716.5s
  EarlyStopping counter: 11 out of 15
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Epoch 31/100
----------------------------------------
  Batch [0/1526] Loss: 0.8461 Components: {'loss_classifier': 0.27653050422668457, 'loss_box_reg': 0.4892995357513428, 'loss_mask': 0.00022236298536881804, 'loss_objectness': 0.030598577111959457, 'loss_rpn_box_reg': 0.04942235350608826}
  Batch [180/1526] Loss: 0.6418 Components: {'loss_classifier': 0.16514427959918976, 'loss_box_reg': 0.4340443015098572, 'loss_mask': 0.017104439437389374, 'loss_objectness': 0.006786965765058994, 'loss_rpn_box_reg': 0.018713463097810745}
  Batch [210/1526] Loss: 5.7534 Components: {'loss_classifier': 0.23072120547294617, 'loss_box_reg': 0.3340471386909485, 'loss_mask': 0.015270997770130634, 'loss_objectness': 1.1734271049499512, 'loss_rpn_box_reg': 3.9999377727508545}
  Batch [220/1526] Loss: 0.6162 Components: {'loss_classifier': 0.16848038136959076, 'loss_box_reg': 0.4007149338722229, 'loss_mask': 0.0029734750278294086, 'loss_objectness': 0.02234136126935482, 'loss_rpn_box_reg': 0.021656306460499763}
  Batch [270/1526] Loss: 1.0385 Components: {'loss_classifier': 0.3487424850463867, 'loss_box_reg': 0.6389130353927612, 'loss_mask': 0.000999331590719521, 'loss_objectness': 0.02591768093407154, 'loss_rpn_box_reg': 0.023912213742733}
  Batch [290/1526] Loss: 0.2651 Components: {'loss_classifier': 0.10051317512989044, 'loss_box_reg': 0.14720147848129272, 'loss_mask': 5.784241875517182e-05, 'loss_objectness': 0.009866273030638695, 'loss_rpn_box_reg': 0.007486150600016117}
  Batch [310/1526] Loss: 0.4723 Components: {'loss_classifier': 0.15027669072151184, 'loss_box_reg': 0.23614878952503204, 'loss_mask': 0.0595330148935318, 'loss_objectness': 0.02164563536643982, 'loss_rpn_box_reg': 0.004715754650533199}
  Batch [370/1526] Loss: 0.3222 Components: {'loss_classifier': 0.11544649302959442, 'loss_box_reg': 0.1771479845046997, 'loss_mask': 0.012459983117878437, 'loss_objectness': 0.0070623354986310005, 'loss_rpn_box_reg': 0.010123196989297867}
  Batch [450/1526] Loss: 0.9197 Components: {'loss_classifier': 0.30274471640586853, 'loss_box_reg': 0.42222943902015686, 'loss_mask': 0.0002872876648325473, 'loss_objectness': 0.04354506731033325, 'loss_rpn_box_reg': 0.15085065364837646}
  Batch [480/1526] Loss: 0.3542 Components: {'loss_classifier': 0.11543005704879761, 'loss_box_reg': 0.20215769112110138, 'loss_mask': 0.01294776238501072, 'loss_objectness': 0.016503356397151947, 'loss_rpn_box_reg': 0.007157075684517622}
  Batch [530/1526] Loss: 0.6238 Components: {'loss_classifier': 0.18817435204982758, 'loss_box_reg': 0.40385866165161133, 'loss_mask': 0.0008093168144114316, 'loss_objectness': 0.017786314710974693, 'loss_rpn_box_reg': 0.013200590386986732}
  Batch [580/1526] Loss: 0.4617 Components: {'loss_classifier': 0.11829175800085068, 'loss_box_reg': 0.07994332909584045, 'loss_mask': 0.09492040425539017, 'loss_objectness': 0.026738794520497322, 'loss_rpn_box_reg': 0.1418074518442154}
  Batch [630/1526] Loss: 0.6062 Components: {'loss_classifier': 0.17004641890525818, 'loss_box_reg': 0.30522584915161133, 'loss_mask': 0.09382198005914688, 'loss_objectness': 0.013123740442097187, 'loss_rpn_box_reg': 0.023965999484062195}
  Batch [740/1526] Loss: 0.1853 Components: {'loss_classifier': 0.04181574657559395, 'loss_box_reg': 0.08481031656265259, 'loss_mask': 0.0020865253172814846, 'loss_objectness': 0.0036954861134290695, 'loss_rpn_box_reg': 0.052859827876091}
  Batch [760/1526] Loss: 0.6600 Components: {'loss_classifier': 0.19376158714294434, 'loss_box_reg': 0.29344823956489563, 'loss_mask': 0.0004275871906429529, 'loss_objectness': 0.02787373960018158, 'loss_rpn_box_reg': 0.14453577995300293}
  Batch [770/1526] Loss: 0.3835 Components: {'loss_classifier': 0.15594767034053802, 'loss_box_reg': 0.17418275773525238, 'loss_mask': 0.03357544541358948, 'loss_objectness': 0.01218567043542862, 'loss_rpn_box_reg': 0.0075631411746144295}
  Batch [840/1526] Loss: 0.1511 Components: {'loss_classifier': 0.06830096244812012, 'loss_box_reg': 0.07633697986602783, 'loss_mask': 0.0009018287528306246, 'loss_objectness': 0.002341322600841522, 'loss_rpn_box_reg': 0.0031748425681144}
  Batch [920/1526] Loss: 0.6302 Components: {'loss_classifier': 0.18184952437877655, 'loss_box_reg': 0.2159958928823471, 'loss_mask': 0.014597801491618156, 'loss_objectness': 0.03815601021051407, 'loss_rpn_box_reg': 0.17959462106227875}
  Batch [940/1526] Loss: 0.6770 Components: {'loss_classifier': 0.1990623027086258, 'loss_box_reg': 0.38207441568374634, 'loss_mask': 4.2104555177502334e-05, 'loss_objectness': 0.017583895474672318, 'loss_rpn_box_reg': 0.07826972007751465}
  Batch [1030/1526] Loss: 0.9046 Components: {'loss_classifier': 0.27615436911582947, 'loss_box_reg': 0.5225279331207275, 'loss_mask': 0.012516211718320847, 'loss_objectness': 0.05447526276111603, 'loss_rpn_box_reg': 0.03895152360200882}
  Batch [1060/1526] Loss: 0.2277 Components: {'loss_classifier': 0.08934572339057922, 'loss_box_reg': 0.0895674005150795, 'loss_mask': 0.031450122594833374, 'loss_objectness': 0.014346671290695667, 'loss_rpn_box_reg': 0.002985443454235792}
  Batch [1120/1526] Loss: 0.5421 Components: {'loss_classifier': 0.19777195155620575, 'loss_box_reg': 0.24544046819210052, 'loss_mask': 0.00045632023829966784, 'loss_objectness': 0.04676913842558861, 'loss_rpn_box_reg': 0.05165504664182663}
  Batch [1150/1526] Loss: 0.4724 Components: {'loss_classifier': 0.16092072427272797, 'loss_box_reg': 0.2883419990539551, 'loss_mask': 0.013280008919537067, 'loss_objectness': 0.002483797026798129, 'loss_rpn_box_reg': 0.007397918961942196}
  Batch [1170/1526] Loss: 3.5846 Components: {'loss_classifier': 0.08676964789628983, 'loss_box_reg': 0.03199820592999458, 'loss_mask': 0.05364376679062843, 'loss_objectness': 0.11736045032739639, 'loss_rpn_box_reg': 3.294780731201172}
  Batch [1350/1526] Loss: 1.3740 Components: {'loss_classifier': 0.18462099134922028, 'loss_box_reg': 0.0846848338842392, 'loss_mask': 0.00031508534448221326, 'loss_objectness': 0.3956523537635803, 'loss_rpn_box_reg': 0.7087636590003967}

Epoch 31 Summary:
  Train Loss: 0.9067
  Val Loss: 1.7899
  Learning Rate: 0.001000
  Epoch Time: 2633.7s
  EarlyStopping counter: 12 out of 15

Epoch 32/100
----------------------------------------
  Batch [70/1526] Loss: 0.4699 Components: {'loss_classifier': 0.1631966233253479, 'loss_box_reg': 0.25675883889198303, 'loss_mask': 0.00550449313595891, 'loss_objectness': 0.02239787019789219, 'loss_rpn_box_reg': 0.022043727338314056}
  Batch [150/1526] Loss: 0.3197 Components: {'loss_classifier': 0.11237519979476929, 'loss_box_reg': 0.19631150364875793, 'loss_mask': 0.00012553395936265588, 'loss_objectness': 0.0033502262085676193, 'loss_rpn_box_reg': 0.007575499825179577}
  Batch [210/1526] Loss: 0.4776 Components: {'loss_classifier': 0.14479826390743256, 'loss_box_reg': 0.30695873498916626, 'loss_mask': 0.002600353676825762, 'loss_objectness': 0.0077267601154744625, 'loss_rpn_box_reg': 0.015471136197447777}
  Batch [230/1526] Loss: 0.1853 Components: {'loss_classifier': 0.02505560964345932, 'loss_box_reg': 0.0294623002409935, 'loss_mask': 0.0002635254932101816, 'loss_objectness': 0.007005276624113321, 'loss_rpn_box_reg': 0.12351273000240326}
  Batch [300/1526] Loss: 0.3997 Components: {'loss_classifier': 0.13158012926578522, 'loss_box_reg': 0.2519720792770386, 'loss_mask': 2.3890872398624197e-05, 'loss_objectness': 0.008983353152871132, 'loss_rpn_box_reg': 0.007165183313190937}
  Batch [310/1526] Loss: 0.6721 Components: {'loss_classifier': 0.21433083713054657, 'loss_box_reg': 0.24994595348834991, 'loss_mask': 0.004985195584595203, 'loss_objectness': 0.015344155952334404, 'loss_rpn_box_reg': 0.18744860589504242}
  Batch [340/1526] Loss: 0.5748 Components: {'loss_classifier': 0.1364302635192871, 'loss_box_reg': 0.3340533375740051, 'loss_mask': 0.09386438876390457, 'loss_objectness': 0.001762146595865488, 'loss_rpn_box_reg': 0.008720038458704948}
  Batch [350/1526] Loss: 0.4142 Components: {'loss_classifier': 0.1408219337463379, 'loss_box_reg': 0.2512267529964447, 'loss_mask': 0.00024647824466228485, 'loss_objectness': 0.004343641921877861, 'loss_rpn_box_reg': 0.017599692568182945}
  Batch [380/1526] Loss: 0.5290 Components: {'loss_classifier': 0.18836024403572083, 'loss_box_reg': 0.27629250288009644, 'loss_mask': 0.02195795439183712, 'loss_objectness': 0.023191161453723907, 'loss_rpn_box_reg': 0.019235948100686073}
  Batch [470/1526] Loss: 0.0963 Components: {'loss_classifier': 0.01639503799378872, 'loss_box_reg': 0.0578937903046608, 'loss_mask': 0.014105250127613544, 'loss_objectness': 0.0029380505438894033, 'loss_rpn_box_reg': 0.004955565091222525}
  Batch [510/1526] Loss: 1.1506 Components: {'loss_classifier': 0.4269923269748688, 'loss_box_reg': 0.4914078712463379, 'loss_mask': 0.00018520522280596197, 'loss_objectness': 0.08696062862873077, 'loss_rpn_box_reg': 0.14509975910186768}
  Batch [680/1526] Loss: 0.2202 Components: {'loss_classifier': 0.08594752848148346, 'loss_box_reg': 0.10984375327825546, 'loss_mask': 7.443525828421116e-05, 'loss_objectness': 0.009913177229464054, 'loss_rpn_box_reg': 0.014467726461589336}
  Batch [690/1526] Loss: 0.6791 Components: {'loss_classifier': 0.2231779843568802, 'loss_box_reg': 0.22974951565265656, 'loss_mask': 5.5594831792404875e-05, 'loss_objectness': 0.07782887667417526, 'loss_rpn_box_reg': 0.14828723669052124}
  Batch [750/1526] Loss: 0.4677 Components: {'loss_classifier': 0.12318065762519836, 'loss_box_reg': 0.3211170434951782, 'loss_mask': 0.013610401190817356, 'loss_objectness': 0.0045357560738921165, 'loss_rpn_box_reg': 0.005226601846516132}
  Batch [780/1526] Loss: 0.2946 Components: {'loss_classifier': 0.11602659523487091, 'loss_box_reg': 0.14959028363227844, 'loss_mask': 0.010082580149173737, 'loss_objectness': 0.017204098403453827, 'loss_rpn_box_reg': 0.001710414420813322}
  Batch [880/1526] Loss: 0.3701 Components: {'loss_classifier': 0.1010926142334938, 'loss_box_reg': 0.2363322228193283, 'loss_mask': 0.024816760793328285, 'loss_objectness': 0.0019067088142037392, 'loss_rpn_box_reg': 0.005997109226882458}
  Batch [900/1526] Loss: 0.4320 Components: {'loss_classifier': 0.17210620641708374, 'loss_box_reg': 0.24148017168045044, 'loss_mask': 2.9041329980827868e-05, 'loss_objectness': 0.009857447817921638, 'loss_rpn_box_reg': 0.00852410588413477}
  Batch [1010/1526] Loss: 0.3733 Components: {'loss_classifier': 0.112058125436306, 'loss_box_reg': 0.22011882066726685, 'loss_mask': 0.028539292514324188, 'loss_objectness': 0.006797301582992077, 'loss_rpn_box_reg': 0.005743257701396942}
  Batch [1040/1526] Loss: 0.5048 Components: {'loss_classifier': 0.1854178011417389, 'loss_box_reg': 0.246617391705513, 'loss_mask': 0.04139788821339607, 'loss_objectness': 0.018638260662555695, 'loss_rpn_box_reg': 0.012726129963994026}
  Batch [1070/1526] Loss: 0.6905 Components: {'loss_classifier': 0.23638835549354553, 'loss_box_reg': 0.4159398078918457, 'loss_mask': 0.014064369723200798, 'loss_objectness': 0.008686761371791363, 'loss_rpn_box_reg': 0.015443122945725918}
  Batch [1250/1526] Loss: 0.2692 Components: {'loss_classifier': 0.05187654867768288, 'loss_box_reg': 0.12732277810573578, 'loss_mask': 0.07168105989694595, 'loss_objectness': 0.005583704449236393, 'loss_rpn_box_reg': 0.012750457040965557}
  Batch [1300/1526] Loss: 0.2939 Components: {'loss_classifier': 0.10984329134225845, 'loss_box_reg': 0.17416566610336304, 'loss_mask': 8.450602763332427e-05, 'loss_objectness': 0.005812748335301876, 'loss_rpn_box_reg': 0.003958276938647032}
  Batch [1340/1526] Loss: 0.3315 Components: {'loss_classifier': 0.0836251974105835, 'loss_box_reg': 0.19686520099639893, 'loss_mask': 0.023673785850405693, 'loss_objectness': 0.008208047598600388, 'loss_rpn_box_reg': 0.019080976024270058}
  Batch [1370/1526] Loss: 0.7287 Components: {'loss_classifier': 0.20641174912452698, 'loss_box_reg': 0.3926158547401428, 'loss_mask': 0.03203931450843811, 'loss_objectness': 0.025529569014906883, 'loss_rpn_box_reg': 0.07208701223134995}
  Batch [1420/1526] Loss: 0.4840 Components: {'loss_classifier': 0.19486770033836365, 'loss_box_reg': 0.23490001261234283, 'loss_mask': 0.009667910635471344, 'loss_objectness': 0.018795736134052277, 'loss_rpn_box_reg': 0.025790011510252953}
  Batch [1430/1526] Loss: 0.4518 Components: {'loss_classifier': 0.12652160227298737, 'loss_box_reg': 0.2526457607746124, 'loss_mask': 0.003156121587380767, 'loss_objectness': 0.007087640464305878, 'loss_rpn_box_reg': 0.062429945915937424}
  Batch [1450/1526] Loss: 0.4289 Components: {'loss_classifier': 0.17095723748207092, 'loss_box_reg': 0.22238023579120636, 'loss_mask': 0.0007126835989765823, 'loss_objectness': 0.010776182636618614, 'loss_rpn_box_reg': 0.02404853329062462}
  Batch [1480/1526] Loss: 0.4520 Components: {'loss_classifier': 0.13444221019744873, 'loss_box_reg': 0.25967782735824585, 'loss_mask': 0.039668694138526917, 'loss_objectness': 0.01289884839206934, 'loss_rpn_box_reg': 0.005285126622766256}

Epoch 32 Summary:
  Train Loss: 0.7052
  Val Loss: 1.7078
  Learning Rate: 0.001000
  Epoch Time: 2755.6s
  EarlyStopping counter: 13 out of 15

Epoch 33/100
----------------------------------------
  Batch [10/1526] Loss: 0.2552 Components: {'loss_classifier': 0.08198229223489761, 'loss_box_reg': 0.13325032591819763, 'loss_mask': 0.005432369187474251, 'loss_objectness': 0.011752278544008732, 'loss_rpn_box_reg': 0.022769909352064133}
  Batch [60/1526] Loss: 0.2737 Components: {'loss_classifier': 0.0753982737660408, 'loss_box_reg': 0.14932267367839813, 'loss_mask': 0.04085640236735344, 'loss_objectness': 0.005806023720651865, 'loss_rpn_box_reg': 0.002298431470990181}
  Batch [140/1526] Loss: 0.8727 Components: {'loss_classifier': 0.25579264760017395, 'loss_box_reg': 0.5631872415542603, 'loss_mask': 0.01777321845293045, 'loss_objectness': 0.013047431595623493, 'loss_rpn_box_reg': 0.022870849817991257}
  Batch [210/1526] Loss: 0.2682 Components: {'loss_classifier': 0.07190920412540436, 'loss_box_reg': 0.09537828713655472, 'loss_mask': 0.047915540635585785, 'loss_objectness': 0.006164081394672394, 'loss_rpn_box_reg': 0.04679305478930473}
  Batch [240/1526] Loss: 0.3847 Components: {'loss_classifier': 0.12382812052965164, 'loss_box_reg': 0.2237783819437027, 'loss_mask': 0.0021016125101596117, 'loss_objectness': 0.013840435072779655, 'loss_rpn_box_reg': 0.021181343123316765}
  Batch [250/1526] Loss: 0.5738 Components: {'loss_classifier': 0.1820385903120041, 'loss_box_reg': 0.20628789067268372, 'loss_mask': 2.1861595087102614e-05, 'loss_objectness': 0.011452426202595234, 'loss_rpn_box_reg': 0.17403927445411682}
  Batch [340/1526] Loss: 1.0460 Components: {'loss_classifier': 0.31246432662010193, 'loss_box_reg': 0.5724462270736694, 'loss_mask': 0.08915942162275314, 'loss_objectness': 0.033565130084753036, 'loss_rpn_box_reg': 0.038344286382198334}
  Batch [380/1526] Loss: 7.4108 Components: {'loss_classifier': 0.2393278032541275, 'loss_box_reg': 0.14601999521255493, 'loss_mask': 0.012431173585355282, 'loss_objectness': 0.1955174058675766, 'loss_rpn_box_reg': 6.817463397979736}
  Batch [390/1526] Loss: 0.4771 Components: {'loss_classifier': 0.11049675196409225, 'loss_box_reg': 0.31565722823143005, 'loss_mask': 0.03311944007873535, 'loss_objectness': 0.006327875889837742, 'loss_rpn_box_reg': 0.011507600545883179}
  Batch [440/1526] Loss: 0.8970 Components: {'loss_classifier': 0.27016812562942505, 'loss_box_reg': 0.3723547160625458, 'loss_mask': 0.03649825602769852, 'loss_objectness': 0.0614858977496624, 'loss_rpn_box_reg': 0.1564757525920868}
  Batch [450/1526] Loss: 0.7018 Components: {'loss_classifier': 0.24266283214092255, 'loss_box_reg': 0.4289432466030121, 'loss_mask': 0.00039563141763210297, 'loss_objectness': 0.017339425161480904, 'loss_rpn_box_reg': 0.012414343655109406}
  Batch [470/1526] Loss: 0.4403 Components: {'loss_classifier': 0.12193427979946136, 'loss_box_reg': 0.29685336351394653, 'loss_mask': 0.0032349559478461742, 'loss_objectness': 0.009660867042839527, 'loss_rpn_box_reg': 0.008602584712207317}
  Batch [610/1526] Loss: 0.3198 Components: {'loss_classifier': 0.10085278004407883, 'loss_box_reg': 0.19818992912769318, 'loss_mask': 0.005090396385639906, 'loss_objectness': 0.008048320189118385, 'loss_rpn_box_reg': 0.007604823913425207}
  Batch [620/1526] Loss: 0.8619 Components: {'loss_classifier': 0.32091283798217773, 'loss_box_reg': 0.477236270904541, 'loss_mask': 0.00015251418517436832, 'loss_objectness': 0.02960394136607647, 'loss_rpn_box_reg': 0.034035857766866684}
  Batch [650/1526] Loss: 0.7042 Components: {'loss_classifier': 0.16452519595623016, 'loss_box_reg': 0.4449422359466553, 'loss_mask': 0.079458087682724, 'loss_objectness': 0.006475953850895166, 'loss_rpn_box_reg': 0.008793085813522339}
  Batch [730/1526] Loss: 0.8922 Components: {'loss_classifier': 0.3584478795528412, 'loss_box_reg': 0.3887842893600464, 'loss_mask': 0.03646020218729973, 'loss_objectness': 0.05080287903547287, 'loss_rpn_box_reg': 0.05768677964806557}
  Batch [750/1526] Loss: 0.8503 Components: {'loss_classifier': 0.255668580532074, 'loss_box_reg': 0.5256845355033875, 'loss_mask': 0.028032738715410233, 'loss_objectness': 0.009691650047898293, 'loss_rpn_box_reg': 0.03120725229382515}
  Batch [790/1526] Loss: 0.2382 Components: {'loss_classifier': 0.07974829524755478, 'loss_box_reg': 0.12611840665340424, 'loss_mask': 0.022255629301071167, 'loss_objectness': 0.007875866256654263, 'loss_rpn_box_reg': 0.002185062738135457}
  Batch [930/1526] Loss: 0.4682 Components: {'loss_classifier': 0.13207359611988068, 'loss_box_reg': 0.2806527316570282, 'loss_mask': 0.042241815477609634, 'loss_objectness': 0.00739668682217598, 'loss_rpn_box_reg': 0.0058414819650352}
  Batch [1000/1526] Loss: 0.8507 Components: {'loss_classifier': 0.2902887463569641, 'loss_box_reg': 0.10445774346590042, 'loss_mask': 0.012431872077286243, 'loss_objectness': 0.1922970563173294, 'loss_rpn_box_reg': 0.2512245774269104}
  Batch [1050/1526] Loss: 0.3604 Components: {'loss_classifier': 0.12633052468299866, 'loss_box_reg': 0.1783253401517868, 'loss_mask': 0.042432304471731186, 'loss_objectness': 0.0043970998376607895, 'loss_rpn_box_reg': 0.008937456645071507}
  Batch [1060/1526] Loss: 0.4539 Components: {'loss_classifier': 0.1526523381471634, 'loss_box_reg': 0.2648938298225403, 'loss_mask': 0.013661714270710945, 'loss_objectness': 0.005627887789160013, 'loss_rpn_box_reg': 0.017035074532032013}
  Batch [1170/1526] Loss: 0.3753 Components: {'loss_classifier': 0.11775270849466324, 'loss_box_reg': 0.21315184235572815, 'loss_mask': 0.001792183262296021, 'loss_objectness': 0.01998293213546276, 'loss_rpn_box_reg': 0.02260284684598446}
  Batch [1190/1526] Loss: 6.6560 Components: {'loss_classifier': 0.2578083574771881, 'loss_box_reg': 0.26554250717163086, 'loss_mask': 0.026308082044124603, 'loss_objectness': 1.4668292999267578, 'loss_rpn_box_reg': 4.639476776123047}
  Batch [1210/1526] Loss: 0.1723 Components: {'loss_classifier': 0.07623323053121567, 'loss_box_reg': 0.06803682446479797, 'loss_mask': 0.0008445302373729646, 'loss_objectness': 0.012628834694623947, 'loss_rpn_box_reg': 0.014513632282614708}
  Batch [1280/1526] Loss: 0.5429 Components: {'loss_classifier': 0.15855184197425842, 'loss_box_reg': 0.2900944650173187, 'loss_mask': 0.0711202546954155, 'loss_objectness': 0.015891611576080322, 'loss_rpn_box_reg': 0.007207056041806936}
  Batch [1370/1526] Loss: 1.0596 Components: {'loss_classifier': 0.3011152148246765, 'loss_box_reg': 0.44713401794433594, 'loss_mask': 0.060758888721466064, 'loss_objectness': 0.043665144592523575, 'loss_rpn_box_reg': 0.20691993832588196}
  Batch [1400/1526] Loss: 3.6934 Components: {'loss_classifier': 0.10767320543527603, 'loss_box_reg': 0.059651993215084076, 'loss_mask': 0.015636270865797997, 'loss_objectness': 0.48650631308555603, 'loss_rpn_box_reg': 3.023928642272949}
  Batch [1420/1526] Loss: 0.1998 Components: {'loss_classifier': 0.08683180063962936, 'loss_box_reg': 0.09849977493286133, 'loss_mask': 0.006127777509391308, 'loss_objectness': 0.004009189549833536, 'loss_rpn_box_reg': 0.0042893365025520325}
  Batch [1430/1526] Loss: 0.7256 Components: {'loss_classifier': 0.22825129330158234, 'loss_box_reg': 0.30383867025375366, 'loss_mask': 0.007489331066608429, 'loss_objectness': 0.06962145119905472, 'loss_rpn_box_reg': 0.11641450226306915}
  Batch [1440/1526] Loss: 0.3408 Components: {'loss_classifier': 0.10524505376815796, 'loss_box_reg': 0.2021091729402542, 'loss_mask': 0.02282700687646866, 'loss_objectness': 0.002285418100655079, 'loss_rpn_box_reg': 0.008287986740469933}
  Batch [1490/1526] Loss: 0.6681 Components: {'loss_classifier': 0.1933264285326004, 'loss_box_reg': 0.26792922616004944, 'loss_mask': 0.011762237176299095, 'loss_objectness': 0.028067266568541527, 'loss_rpn_box_reg': 0.16701450943946838}

Epoch 33 Summary:
  Train Loss: 0.8093
  Val Loss: 1.7449
  Learning Rate: 0.001000
  Epoch Time: 2690.2s
  EarlyStopping counter: 14 out of 15

Epoch 34/100
----------------------------------------
  Batch [80/1526] Loss: 0.7423 Components: {'loss_classifier': 0.17148515582084656, 'loss_box_reg': 0.3726230263710022, 'loss_mask': 0.18704237043857574, 'loss_objectness': 0.002800838788971305, 'loss_rpn_box_reg': 0.008317267522215843}
  Batch [90/1526] Loss: 0.2837 Components: {'loss_classifier': 0.07915377616882324, 'loss_box_reg': 0.1784830093383789, 'loss_mask': 0.014238182455301285, 'loss_objectness': 0.005934146232903004, 'loss_rpn_box_reg': 0.005939727183431387}
  Batch [110/1526] Loss: 0.1952 Components: {'loss_classifier': 0.051776766777038574, 'loss_box_reg': 0.07717615365982056, 'loss_mask': 0.03698787838220596, 'loss_objectness': 0.012207040563225746, 'loss_rpn_box_reg': 0.01704196259379387}
  Batch [160/1526] Loss: 1.0302 Components: {'loss_classifier': 0.3555680513381958, 'loss_box_reg': 0.5474181771278381, 'loss_mask': 0.0003791252092923969, 'loss_objectness': 0.055609747767448425, 'loss_rpn_box_reg': 0.07127287238836288}
  Batch [180/1526] Loss: 0.5266 Components: {'loss_classifier': 0.19866830110549927, 'loss_box_reg': 0.2753741145133972, 'loss_mask': 0.00174054189119488, 'loss_objectness': 0.020730052143335342, 'loss_rpn_box_reg': 0.03012152574956417}
  Batch [190/1526] Loss: 0.3991 Components: {'loss_classifier': 0.12987540662288666, 'loss_box_reg': 0.20663753151893616, 'loss_mask': 0.047554295510053635, 'loss_objectness': 0.004675391595810652, 'loss_rpn_box_reg': 0.010404951870441437}
  Batch [200/1526] Loss: 0.5380 Components: {'loss_classifier': 0.16376163065433502, 'loss_box_reg': 0.34165215492248535, 'loss_mask': 0.014771278016269207, 'loss_objectness': 0.006929231341928244, 'loss_rpn_box_reg': 0.010921278968453407}
  Batch [290/1526] Loss: 0.4674 Components: {'loss_classifier': 0.13608621060848236, 'loss_box_reg': 0.3174547851085663, 'loss_mask': 8.355508907698095e-05, 'loss_objectness': 0.008718354627490044, 'loss_rpn_box_reg': 0.005054401699453592}
  Batch [300/1526] Loss: 0.3982 Components: {'loss_classifier': 0.14205864071846008, 'loss_box_reg': 0.20086577534675598, 'loss_mask': 4.3765627196989954e-05, 'loss_objectness': 0.029132599011063576, 'loss_rpn_box_reg': 0.026103129610419273}
  Batch [340/1526] Loss: 0.3596 Components: {'loss_classifier': 0.13909298181533813, 'loss_box_reg': 0.1736864149570465, 'loss_mask': 0.000980783486738801, 'loss_objectness': 0.014902063645422459, 'loss_rpn_box_reg': 0.03089076466858387}
  Batch [350/1526] Loss: 0.4436 Components: {'loss_classifier': 0.17408661544322968, 'loss_box_reg': 0.24808940291404724, 'loss_mask': 3.121590270893648e-05, 'loss_objectness': 0.003391399048268795, 'loss_rpn_box_reg': 0.01802343688905239}
  Batch [440/1526] Loss: 0.5206 Components: {'loss_classifier': 0.18095722794532776, 'loss_box_reg': 0.2114320993423462, 'loss_mask': 8.356995749636553e-06, 'loss_objectness': 0.017041897401213646, 'loss_rpn_box_reg': 0.11113128066062927}
  Batch [500/1526] Loss: 1.0664 Components: {'loss_classifier': 0.3403800427913666, 'loss_box_reg': 0.540378212928772, 'loss_mask': 0.1123221293091774, 'loss_objectness': 0.04121430963277817, 'loss_rpn_box_reg': 0.03207731992006302}
  Batch [550/1526] Loss: 5.9525 Components: {'loss_classifier': 0.27239400148391724, 'loss_box_reg': 0.20437689125537872, 'loss_mask': 0.0030372466426342726, 'loss_objectness': 0.11178114265203476, 'loss_rpn_box_reg': 5.360876083374023}
  Batch [570/1526] Loss: 0.4131 Components: {'loss_classifier': 0.13878092169761658, 'loss_box_reg': 0.24252836406230927, 'loss_mask': 0.0010749840876087546, 'loss_objectness': 0.01615840196609497, 'loss_rpn_box_reg': 0.014588780701160431}
  Batch [710/1526] Loss: 1.0437 Components: {'loss_classifier': 0.3407100439071655, 'loss_box_reg': 0.5827658176422119, 'loss_mask': 0.003949684556573629, 'loss_objectness': 0.05479402095079422, 'loss_rpn_box_reg': 0.06145129352807999}
  Batch [730/1526] Loss: 9.2191 Components: {'loss_classifier': 0.2218107432126999, 'loss_box_reg': 0.10457690805196762, 'loss_mask': 0.0045881737023591995, 'loss_objectness': 0.0888892188668251, 'loss_rpn_box_reg': 8.799215316772461}
  Batch [740/1526] Loss: 0.6335 Components: {'loss_classifier': 0.16005443036556244, 'loss_box_reg': 0.3980347216129303, 'loss_mask': 0.051845960319042206, 'loss_objectness': 0.012422580271959305, 'loss_rpn_box_reg': 0.011106961406767368}
  Batch [760/1526] Loss: 0.3322 Components: {'loss_classifier': 0.10388333350419998, 'loss_box_reg': 0.1978970170021057, 'loss_mask': 0.00011796277249231935, 'loss_objectness': 0.02092643454670906, 'loss_rpn_box_reg': 0.009376334957778454}
  Batch [830/1526] Loss: 0.5663 Components: {'loss_classifier': 0.21087296307086945, 'loss_box_reg': 0.2261311560869217, 'loss_mask': 6.535241118399426e-05, 'loss_objectness': 0.014244863763451576, 'loss_rpn_box_reg': 0.11495393514633179}
  Batch [870/1526] Loss: 0.7205 Components: {'loss_classifier': 0.22901688516139984, 'loss_box_reg': 0.4451199173927307, 'loss_mask': 0.0003150115953758359, 'loss_objectness': 0.02799081802368164, 'loss_rpn_box_reg': 0.01805369183421135}
  Batch [890/1526] Loss: 0.5725 Components: {'loss_classifier': 0.1515924483537674, 'loss_box_reg': 0.376936137676239, 'loss_mask': 0.02538038231432438, 'loss_objectness': 0.00983340386301279, 'loss_rpn_box_reg': 0.00875471718609333}
  Batch [940/1526] Loss: 0.5262 Components: {'loss_classifier': 0.16348066926002502, 'loss_box_reg': 0.14196990430355072, 'loss_mask': 0.0001642276329221204, 'loss_objectness': 0.06919588893651962, 'loss_rpn_box_reg': 0.1513873189687729}
  Batch [970/1526] Loss: 0.7083 Components: {'loss_classifier': 0.22005601227283478, 'loss_box_reg': 0.4067983031272888, 'loss_mask': 0.02892002835869789, 'loss_objectness': 0.016569415107369423, 'loss_rpn_box_reg': 0.035928141325712204}
  Batch [1020/1526] Loss: 1.0986 Components: {'loss_classifier': 0.3976660966873169, 'loss_box_reg': 0.3711507320404053, 'loss_mask': 0.024234429001808167, 'loss_objectness': 0.14271391928195953, 'loss_rpn_box_reg': 0.16280865669250488}
  Batch [1030/1526] Loss: 0.1946 Components: {'loss_classifier': 0.06398754566907883, 'loss_box_reg': 0.12160094827413559, 'loss_mask': 0.00022249353060033172, 'loss_objectness': 0.0030954480171203613, 'loss_rpn_box_reg': 0.005728948395699263}
  Batch [1070/1526] Loss: 0.6138 Components: {'loss_classifier': 0.24972602725028992, 'loss_box_reg': 0.23126471042633057, 'loss_mask': 0.0017349309055134654, 'loss_objectness': 0.07446831464767456, 'loss_rpn_box_reg': 0.05665122717618942}
  Batch [1110/1526] Loss: 0.4959 Components: {'loss_classifier': 0.16381962597370148, 'loss_box_reg': 0.28279903531074524, 'loss_mask': 0.00596267357468605, 'loss_objectness': 0.02866422012448311, 'loss_rpn_box_reg': 0.01466822437942028}
  Batch [1240/1526] Loss: 0.4518 Components: {'loss_classifier': 0.1517244577407837, 'loss_box_reg': 0.20019418001174927, 'loss_mask': 0.017815621569752693, 'loss_objectness': 0.00846854131668806, 'loss_rpn_box_reg': 0.07360826432704926}
  Batch [1250/1526] Loss: 0.7092 Components: {'loss_classifier': 0.24849700927734375, 'loss_box_reg': 0.3589625656604767, 'loss_mask': 0.0005075369263067842, 'loss_objectness': 0.0077719660475850105, 'loss_rpn_box_reg': 0.09349754452705383}
  Batch [1260/1526] Loss: 0.6882 Components: {'loss_classifier': 0.1665123999118805, 'loss_box_reg': 0.33924710750579834, 'loss_mask': 0.16039322316646576, 'loss_objectness': 0.008186954073607922, 'loss_rpn_box_reg': 0.013819166459143162}
  Batch [1270/1526] Loss: 0.4923 Components: {'loss_classifier': 0.13486604392528534, 'loss_box_reg': 0.2737855017185211, 'loss_mask': 0.061556924134492874, 'loss_objectness': 0.007257698103785515, 'loss_rpn_box_reg': 0.014819430187344551}
  Batch [1290/1526] Loss: 0.3178 Components: {'loss_classifier': 0.097811758518219, 'loss_box_reg': 0.2022513747215271, 'loss_mask': 0.013640188612043858, 'loss_objectness': 0.0016398761654272676, 'loss_rpn_box_reg': 0.0024370632600039244}
  Batch [1320/1526] Loss: 1.1061 Components: {'loss_classifier': 0.3299412429332733, 'loss_box_reg': 0.6087280511856079, 'loss_mask': 0.047426268458366394, 'loss_objectness': 0.043418947607278824, 'loss_rpn_box_reg': 0.07654763758182526}
  Batch [1360/1526] Loss: 0.5717 Components: {'loss_classifier': 0.18520459532737732, 'loss_box_reg': 0.3365953862667084, 'loss_mask': 0.006162507459521294, 'loss_objectness': 0.01709328405559063, 'loss_rpn_box_reg': 0.026633894070982933}
  Batch [1420/1526] Loss: 0.6759 Components: {'loss_classifier': 0.18892288208007812, 'loss_box_reg': 0.36853867769241333, 'loss_mask': 0.07314089685678482, 'loss_objectness': 0.01843545213341713, 'loss_rpn_box_reg': 0.02681465819478035}
  Batch [1460/1526] Loss: 0.3990 Components: {'loss_classifier': 0.11455187201499939, 'loss_box_reg': 0.19960568845272064, 'loss_mask': 0.0663050040602684, 'loss_objectness': 0.00972004234790802, 'loss_rpn_box_reg': 0.008786117658019066}
  Batch [1470/1526] Loss: 0.7330 Components: {'loss_classifier': 0.23284472525119781, 'loss_box_reg': 0.46234917640686035, 'loss_mask': 7.100181392161176e-05, 'loss_objectness': 0.0184425450861454, 'loss_rpn_box_reg': 0.019320163875818253}
  Batch [1490/1526] Loss: 0.3172 Components: {'loss_classifier': 0.09348292648792267, 'loss_box_reg': 0.1548251509666443, 'loss_mask': 0.0001180480103357695, 'loss_objectness': 0.023621583357453346, 'loss_rpn_box_reg': 0.0451616607606411}

Epoch 34 Summary:
  Train Loss: 0.7398
  Val Loss: 1.7296
  Learning Rate: 0.001000
  Epoch Time: 2634.3s
  EarlyStopping counter: 15 out of 15

 Early stopping triggered!
Best validation loss: 1.2654

 Training completed in 24.61 hours!
 Final model saved to: fruit_detection_model_enhanced/final_model.pth
   Training curves saved to: fruit_detection_model_enhanced/training_curves.png

Training completed successfully!

Testing on 5 sample images...

Testing: image (28)_original.jpg

Testing model on image...
Loaded model from epoch 18
Detected 0 objects with confidence > 0.5
Result saved to: AugmentedDataset/images/cucumber/image (28)_original_result.jpg

Testing: image (20)_original.jpg

Testing model on image...
Loaded model from epoch 18
Detected 0 objects with confidence > 0.5
Result saved to: AugmentedDataset/images/cucumber/image (20)_original_result.jpg

Testing: il_570xN.3563808196_dwqp_original.jpg

Testing model on image...
Loaded model from epoch 18
Detected 0 objects with confidence > 0.5
Result saved to: AugmentedDataset/images/cucumber/il_570xN_result.3563808196_dwqp_original_result.jpg
